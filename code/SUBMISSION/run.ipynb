{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# imports\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from implementations import *\n",
    "from costs import *\n",
    "from optimize_hyperparams import *\n",
    "from cross_validation import *\n",
    "from step_wise import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from proj1_helpers import load_csv_data \n",
    "\n",
    "# load raw data\n",
    "y_raw, input_data_raw, ids = load_csv_data('train.csv', sub_sample=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load raw data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from outliers import handle_outliers\n",
    "\n",
    "# handle outliers: all the -999 values are put to the mean value taken from the rest of the sample\n",
    "X_raw, y = handle_outliers(input_data_raw, y_raw, -999, 'mean')\n",
    "\n",
    "# set y in {0,1} instead of {-1,1}\n",
    "y[np.where(y==-1)]=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features generation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get feature names \n",
    "all_features_raw = list(np.genfromtxt('train.csv', delimiter=\",\", dtype=str, max_rows = 1)[2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from extend_features import extend_features\n",
    "\n",
    "\n",
    "# extend feature set adding log transformations and momentum features\n",
    "all_candidates, features = extend_features(X_raw, all_features_raw, degree = 1, is_add_log = True)\n",
    "print(all_candidates.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training (time demanding - see bellow to only load the trained weights) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selection of features from stepwise results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# feature selection (best feature indices from the step wise with logistic regression)\n",
    "indx = [1, 13, 4, 46, 0, 11, 44, 43, 7, 2, 16, 48, 10, 6, 49, 22, 45, 12, 19, 23, 32, 24, 17, 14, 39, 42, 30, 31, 47, 38, 20]\n",
    "\n",
    "# thresholding to lower the number of feature\n",
    "indx = indx[:17]\n",
    "\n",
    "# training set\n",
    "X = all_candidates[:, indx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Raising features up to the tuned degree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# optimal degree obtained from degree optimization that uses cross validation with different degrees in [1,10]  \n",
    "degree_opt = 5\n",
    "\n",
    "# build polynomial basis function\n",
    "phi = build_poly(X, degree_opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardize:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# standardization\n",
    "phi_tmp,_,_ =  standardize(phi[:,1:]) \n",
    "phi[:,1:] = phi_tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute the model (otherwise load the weights from the next line):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model parameters (tuned manually to insure convergence)\n",
    "gamma = 1e-5\n",
    "threshold = 1e-3\n",
    "max_iters = 10000\n",
    "initial_w = np.zeros(phi.shape[1])\n",
    "\n",
    "# logistic regression\n",
    "w_tot, loss_tot = logistic_regression(y, phi, initial_w, max_iters, gamma)\n",
    "\n",
    "print(loss_tot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the optimal trained weights "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w_opt = np.load('w_opt_lr.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build testing dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### loading test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from proj1_helpers import load_csv_data \n",
    "\n",
    "# load testing set\n",
    "y_raw_te, input_data_raw_te, ids_te = load_csv_data('test.csv', sub_sample=False)\n",
    "\n",
    "# handle outliers: all the -999 values are put to the mean value taken from the rest of the sample\n",
    "input_data_raw_te, _ = handle_outliers(input_data_raw_te, y_raw_te, -999, 'mean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features generation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get feature names \n",
    "all_features_raw = list(np.genfromtxt('test.csv', delimiter=\",\", dtype=str, max_rows = 1)[2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from extend_features import extend_features\n",
    "\n",
    "# feature degree\n",
    "degree = 1\n",
    "\n",
    "# extend feature set\n",
    "X_te, _ = extend_features(input_data_raw_te, all_features_raw, degree, is_add_log = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature selection (best feature indices from the step wise with logistic regression)\n",
    "indx = [1, 13, 4, 46, 0, 11, 44, 43, 7, 2, 16, 48, 10, 6, 49, 22, 45, 12, 19, 23, 32, 24, 17, 14, 39, 42, 30, 31, 47, 38, 20]\n",
    "\n",
    "# thresholding to lower the number of feature\n",
    "indx = indx[:17]\n",
    "\n",
    "# feature selection (same as for the training set: see above)\n",
    "print(X_te.shape)\n",
    "X_te = X_te[:, indx]\n",
    "print(X_te.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# build polynomial basis function\n",
    "degree_opt = 5\n",
    "phi = build_poly(X_te, degree_opt)\n",
    "        \n",
    "# standardization\n",
    "phi_tmp,_,_ =  standardize(phi[:,1:]) \n",
    "phi[:,1:] = phi_tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Predict labels in testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from proj1_helpers import predict_labels_log\n",
    "\n",
    "# predict labels\n",
    "y_pred = predict_labels_log(w_opt,phi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a submission csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# replace 0 in labels per -1\n",
    "y_pred[np.where(y_pred==0)] = -1\n",
    "\n",
    "# create the csv file\n",
    "create_csv_submission(ids_te, y_pred, \"submission_30_10\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

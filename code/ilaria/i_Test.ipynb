{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Least Square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "my_path = r'/home/ilaria/Scrivania/Machine_Learning/Project_1/Project1_ML'\n",
    "sys.path.insert(0,my_path + r'/code/COMMON')\n",
    "\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from proj1_helpers import * \n",
    "from implementations import *\n",
    "from outliers import handle_outliers\n",
    "from labels import idx_2labels\n",
    "from standard import standardize\n",
    "from costs import compute_loglikelihood_reg\n",
    "from sigmoid import * \n",
    "from extend_features import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded!\n",
      "(250000, 30)\n"
     ]
    }
   ],
   "source": [
    "yb, input_data, ids = load_csv_data(my_path + r'/data/train.csv', sub_sample=False)\n",
    "print('Data loaded!')\n",
    "print(input_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handle -999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-999 are replaced by the mean value of the feature\n",
      "---------------------------\n",
      "Features have been set to the power(s): [1]\n",
      "16 Features of the momentum have been added\n",
      "4 logarithmic features have been added.\n",
      "Data have been standardized.\n",
      "---------------------------\n"
     ]
    }
   ],
   "source": [
    "input_data, Y = handle_outliers(input_data,yb,-999, 'mean') # substiution with mean because the standardization\n",
    "                                                           #can be affected, otherwise we should delete the whole row\n",
    "ind_back, ind_sig = idx_2labels(Y, [-1,1])\n",
    "Y[ind_back] = 0\n",
    "\n",
    "# get feature names \n",
    "names = list(np.genfromtxt(my_path + r'/data/train.csv', delimiter=\",\", dtype=str, max_rows = 1)[2:])\n",
    "log = True\n",
    "degree = 1\n",
    "X0, features = extend_features(input_data, names, degree, log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(250000, 50)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X0.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(250000, 30)\n"
     ]
    }
   ],
   "source": [
    "idx =  [1, 13, 4, 11, 46, 0, 44, 7, 12, 42, 49, 2, 16, 10, 43, 47, 45, 22, 6, 23, 19, 48, 21, 8, 5, 9, 32, 31, 30, 33]\n",
    "X = X0[:,idx]\n",
    "print(X.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(250000, 121)\n",
      "(250000, 121)\n"
     ]
    }
   ],
   "source": [
    "Xp = build_poly(X,4)\n",
    "print(Xp.shape)\n",
    "\n",
    "Xtmp, _,_ = standardize(Xp[:,1:])\n",
    "Xp[:,1:] = Xtmp \n",
    "print(Xp.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "initial_w = np.ones(Xp.shape[1])\n",
    "max_iters = 500\n",
    "gamma = 1e-1\n",
    "maxiters = 2000\n",
    "method = 'gd'\n",
    "\n",
    "w, loss = least_squares_GD(Y,Xp,initial_w, maxiters, gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = predict_labels(w[-1],Xp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(250000,)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "193665\n",
      "56335\n",
      "0.77466\n"
     ]
    }
   ],
   "source": [
    "pos = 0\n",
    "neg = 0\n",
    "for i in range (len(Y)):\n",
    "    if Y[i] == y[i]:\n",
    "        pos += 1\n",
    "    else:\n",
    "        neg += 1\n",
    "print(pos)\n",
    "print(neg)\n",
    "\n",
    "success_rate = pos/(pos+neg)\n",
    "print(success_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded! Shape: \n",
      "(568238, 30)\n"
     ]
    }
   ],
   "source": [
    "y, test_data, ids = load_csv_data(r'/home/ilaria/Scrivania/Machine_Learning/Project_1/test.csv', sub_sample=False)\n",
    "\n",
    "print(\"Data loaded! Shape: \")\n",
    "print(np.shape(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-999 are replaced by the mean value of the feature\n",
      "---------------------------\n",
      "Features have been set to the power(s): [1]\n",
      "16 Features of the momentum have been added\n",
      "4 logarithmic features have been added.\n",
      "Data have been standardized.\n",
      "---------------------------\n"
     ]
    }
   ],
   "source": [
    "input_data, Y = handle_outliers(test_data,y,-999,'mean')\n",
    "\n",
    "# get feature names \n",
    "names = list(np.genfromtxt(my_path + r'/data/train.csv', delimiter=\",\", dtype=str, max_rows = 1)[2:])\n",
    "log = True\n",
    "degree = 1\n",
    "X0, features = extend_features(input_data, names, degree, log)\n",
    "idx = [1, 13, 4, 11, 46, 0, 44, 7, 12, 42, 49, 2, 16, 10, 43, 47, 45, 22, 6, 23, 19, 48, 21, 8, 5, 9, 32, 31, 30, 33]\n",
    "X = X0[:,idx]\n",
    "Xp = build_poly(X,4)\n",
    "Xtmp, _,_ = standardize(Xp[:,1:])\n",
    "Xp[:,1:] = Xtmp \n",
    "\n",
    "y_pred = predict_labels(w[-1],Xp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(568238,)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred[np.where(y_pred==0)] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "create_csv_submission(ids, y_pred, \"boh_sub\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

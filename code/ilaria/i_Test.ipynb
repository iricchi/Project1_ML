{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Least Square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "my_path = r'/home/ilaria/Scrivania/Machine_Learning/Project_1/Project1_ML'\n",
    "sys.path.insert(0,my_path + r'/code/COMMON')\n",
    "\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from proj1_helpers import * \n",
    "from implementations import *\n",
    "from outliers import handle_outliers\n",
    "from labels import idx_2labels\n",
    "from standard import standardize\n",
    "from costs import compute_loglikelihood_reg\n",
    "from sigmoid import * \n",
    "from extend_features import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded!\n",
      "(250000, 30)\n"
     ]
    }
   ],
   "source": [
    "yb, input_data, ids = load_csv_data(my_path + r'/data/train.csv', sub_sample=False)\n",
    "print('Data loaded!')\n",
    "print(input_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handle -999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-999 are replaced by 0\n",
      "---------------------------\n",
      "Features have been set to the power(s): [1, 2, 3]\n",
      "4 logarithmic features have been added.\n",
      "Data have been standardized.\n",
      "---------------------------\n"
     ]
    }
   ],
   "source": [
    "input_data, Y = handle_outliers(input_data,yb,-999,0) # substiution with mean because the standardization\n",
    "                                                           #can be affected, otherwise we should delete the whole row\n",
    "ind_back, ind_sig = idx_2labels(Y, [-1,1])\n",
    "Y[ind_back] = 0\n",
    "\n",
    "# get feature names \n",
    "names = list(np.genfromtxt(my_path + r'/data/train.csv', delimiter=\",\", dtype=str, max_rows = 1)[2:])\n",
    "log = True\n",
    "degree = 3\n",
    "X0, features = extend_features(input_data, names, degree, log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(250000, 94)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X0.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "idx = [3, 13, 39, 4, 40, 52, 21, 22, 33, 68, 57, 73, 6, 48, 38, 41, 23, 50, 43, 91, 5, 66, 82, 9, 64, 78, 18, 0, 1, 2, 90, 34, 12, 14, 67, 93, 69, 92, 79, 29, 88, 87, 35, 37, 15, 31, 30, 28, 32, 16, 36, 63, 24, 70, 19, 20] \n",
    "X = X0[:,idx]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "initial_w = np.ones(X.shape[1])\n",
    "max_iters = 50\n",
    "gamma = 10e-6\n",
    "method = 'gd'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w, loss = least_squares(Y,X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = predict_labels(w,X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(250000,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172165\n",
      "77835\n",
      "0.68866\n"
     ]
    }
   ],
   "source": [
    "pos = 0\n",
    "neg = 0\n",
    "for i in range (len(Y)):\n",
    "    if Y[i] == y[i]:\n",
    "        pos += 1\n",
    "    else:\n",
    "        neg += 1\n",
    "print(pos)\n",
    "print(neg)\n",
    "\n",
    "success_rate = pos/(pos+neg)\n",
    "print(success_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded! Shape: \n",
      "(568238, 30)\n"
     ]
    }
   ],
   "source": [
    "nope, test_data, ids = load_csv_data(r'/home/ilaria/Scrivania/Machine_Learning/Project_1/test.csv', sub_sample=False)\n",
    "\n",
    "print(\"Data loaded! Shape: \")\n",
    "print(np.shape(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-999 are replaced by 0\n",
      "---------------------------\n",
      "Features have been set to the power(s): [1, 2, 3]\n",
      "4 logarithmic features have been added.\n",
      "Data have been standardized.\n",
      "---------------------------\n"
     ]
    }
   ],
   "source": [
    "input_data, Y = handle_outliers(test_data,nope,-999,0)\n",
    "ind_back, ind_sig = idx_2labels(Y, [-1,1])\n",
    "Y[ind_back] = 0\n",
    "\n",
    "# get feature names \n",
    "names = list(np.genfromtxt(my_path + r'/data/train.csv', delimiter=\",\", dtype=str, max_rows = 1)[2:])\n",
    "log = True\n",
    "degree = 3\n",
    "X0, features = extend_features(input_data, names, degree, log)\n",
    "idx = [3, 13, 39, 4, 40, 52, 21, 22, 33, 68, 57, 73, 6, 48, 38, 41, 23, 50, 43, 91, 5, 66, 82, 9, 64, 78, 18, 0, 1, 2, 90, 34, 12, 14, 67, 93, 69, 92, 79, 29, 88, 87, 35, 37, 15, 31, 30, 28, 32, 16, 36, 63, 24, 70, 19, 20] \n",
    "X = X0[:,idx]\n",
    "\n",
    "y_pred = predict_labels(w,X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(568238,)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred[np.where(y_pred==0)] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "create_csv_submission(ids, y_pred, \"third_sub\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

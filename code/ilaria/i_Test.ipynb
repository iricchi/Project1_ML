{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Least Square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "my_path = r'/home/ilaria/Scrivania/Machine_Learning/Project_1/Project1_ML'\n",
    "sys.path.insert(0,my_path + r'/code/COMMON')\n",
    "\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from proj1_helpers import * \n",
    "from implementations import *\n",
    "from outliers import handle_outliers\n",
    "from labels import idx_2labels\n",
    "from standard import standardize\n",
    "from costs import compute_loglikelihood_reg\n",
    "from sigmoid import * \n",
    "from extend_features import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded!\n",
      "(250000, 30)\n"
     ]
    }
   ],
   "source": [
    "yb, input_data, ids = load_csv_data(my_path + r'/data/train.csv', sub_sample=False)\n",
    "print('Data loaded!')\n",
    "print(input_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handle -999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-999 are replaced by the mean value of the feature\n",
      "---------------------------\n",
      "Features have been set to the power(s): [1]\n",
      "16 Features of the momentum have been added\n",
      "4 logarithmic features have been added.\n",
      "Data have been standardized.\n",
      "---------------------------\n"
     ]
    }
   ],
   "source": [
    "input_data, Y = handle_outliers(input_data,yb,-999, 'mean') # substiution with mean because the standardization\n",
    "                                                           #can be affected, otherwise we should delete the whole row\n",
    "ind_back, ind_sig = idx_2labels(Y, [-1,1])\n",
    "Y[ind_back] = 0\n",
    "\n",
    "# get feature names \n",
    "names = list(np.genfromtxt(my_path + r'/data/train.csv', delimiter=\",\", dtype=str, max_rows = 1)[2:])\n",
    "log = True\n",
    "degree = 1\n",
    "X0, features = extend_features(input_data, names, degree, log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(250000, 50)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 'DER_mass_MMC_power_1'),\n",
       " (1, 'DER_mass_transverse_met_lep_power_1'),\n",
       " (2, 'DER_mass_vis_power_1'),\n",
       " (3, 'DER_pt_h_power_1'),\n",
       " (4, 'DER_deltaeta_jet_jet_power_1'),\n",
       " (5, 'DER_mass_jet_jet_power_1'),\n",
       " (6, 'DER_prodeta_jet_jet_power_1'),\n",
       " (7, 'DER_deltar_tau_lep_power_1'),\n",
       " (8, 'DER_pt_tot_power_1'),\n",
       " (9, 'DER_sum_pt_power_1'),\n",
       " (10, 'DER_pt_ratio_lep_tau_power_1'),\n",
       " (11, 'DER_met_phi_centrality_power_1'),\n",
       " (12, 'DER_lep_eta_centrality_power_1'),\n",
       " (13, 'PRI_tau_pt_power_1'),\n",
       " (14, 'PRI_tau_eta_power_1'),\n",
       " (15, 'PRI_tau_phi_power_1'),\n",
       " (16, 'PRI_lep_pt_power_1'),\n",
       " (17, 'PRI_lep_eta_power_1'),\n",
       " (18, 'PRI_lep_phi_power_1'),\n",
       " (19, 'PRI_met_power_1'),\n",
       " (20, 'PRI_met_phi_power_1'),\n",
       " (21, 'PRI_met_sumet_power_1'),\n",
       " (22, 'PRI_jet_num_power_1'),\n",
       " (23, 'PRI_jet_leading_pt_power_1'),\n",
       " (24, 'PRI_jet_leading_eta_power_1'),\n",
       " (25, 'PRI_jet_leading_phi_power_1'),\n",
       " (26, 'PRI_jet_subleading_pt_power_1'),\n",
       " (27, 'PRI_jet_subleading_eta_power_1'),\n",
       " (28, 'PRI_jet_subleading_phi_power_1'),\n",
       " (29, 'PRI_jet_all_pt_power_1'),\n",
       " (30, 'PRI_tau_pt_mom_comp1'),\n",
       " (31, 'PRI_lep_pt_mom_comp1'),\n",
       " (32, 'PRI_jet_leading_pt_mom_comp1'),\n",
       " (33, 'PRI_jet_subleading_pt_mom_comp1'),\n",
       " (34, 'PRI_tau_pt_mom_comp2'),\n",
       " (35, 'PRI_lep_pt_mom_comp2'),\n",
       " (36, 'PRI_jet_leading_pt_mom_comp2'),\n",
       " (37, 'PRI_jet_subleading_pt_mom_comp2'),\n",
       " (38, 'PRI_tau_pt_mom_comp3'),\n",
       " (39, 'PRI_lep_pt_mom_comp3'),\n",
       " (40, 'PRI_jet_leading_pt_mom_comp3'),\n",
       " (41, 'PRI_jet_subleading_pt_mom_comp3'),\n",
       " (42, 'PRI_tau_pt_mom_module'),\n",
       " (43, 'PRI_lep_pt_mom_module'),\n",
       " (44, 'PRI_jet_leading_pt_mom_module'),\n",
       " (45, 'PRI_jet_subleading_pt_mom_module'),\n",
       " (46, 'log(DER_mass_MMC)'),\n",
       " (47, 'log(DER_mass_MMC)'),\n",
       " (48, 'log(DER_mass_transverse_met_lep)'),\n",
       " (49, 'log(DER_mass_vis)')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(250000, 30)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx =  [1, 13, 4, 11, 46, 0, 44, 7, 12, 42, 49, 2, 16, 10, 43, 47, 45, 22, 6, 23, 19, 48, 21, 5, 8, 29, 32, 31, 30, 33]\n",
    "X = X0[:,idx]\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "initial_w = np.zeros(X.shape[1])\n",
    "max_iters = 3000\n",
    "gamma = 1e-1\n",
    "t = 1e-4\n",
    "w, loss = least_squares(Y,X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = predict_labels(w,X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(250000,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170575\n",
      "79425\n",
      "0.6823\n"
     ]
    }
   ],
   "source": [
    "pos = 0\n",
    "neg = 0\n",
    "for i in range (len(Y)):\n",
    "    if Y[i] == y[i]:\n",
    "        pos += 1\n",
    "    else:\n",
    "        neg += 1\n",
    "print(pos)\n",
    "print(neg)\n",
    "\n",
    "success_rate = pos/(pos+neg)\n",
    "print(success_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded! Shape: \n",
      "(568238, 30)\n"
     ]
    }
   ],
   "source": [
    "nope, test_data, ids = load_csv_data(r'/home/ilaria/Scrivania/Machine_Learning/Project_1/test.csv', sub_sample=False)\n",
    "\n",
    "print(\"Data loaded! Shape: \")\n",
    "print(np.shape(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-999 are replaced by the mean value of the feature\n",
      "---------------------------\n",
      "Features have been set to the power(s): [1]\n",
      "16 Features of the momentum have been added\n",
      "4 logarithmic features have been added.\n",
      "Data have been standardized.\n",
      "---------------------------\n"
     ]
    }
   ],
   "source": [
    "input_data, Y = handle_outliers(test_data,nope,-999,'mean')\n",
    "ind_back, ind_sig = idx_2labels(Y, [-1,1])\n",
    "Y[ind_back] = 0\n",
    "\n",
    "# get feature names \n",
    "names = list(np.genfromtxt(my_path + r'/data/train.csv', delimiter=\",\", dtype=str, max_rows = 1)[2:])\n",
    "log = True\n",
    "degree = 1\n",
    "X0, features = extend_features(input_data, names, degree, log)\n",
    "idx =  [1, 13, 4, 11, 46, 0, 44, 7, 12, 42, 49, 2, 16, 10, 43, 47, 45, 22, 6, 23, 19, 48, 21, 5, 8, 29, 32, 31, 30, 33]\n",
    "X = X0[:,idx]\n",
    "\n",
    "y_pred = predict_labels(w,X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(568238,)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred[np.where(y_pred==0)] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "create_csv_submission(ids, y_pred, \"a_sub\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features selection with STEPWISE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "my_path = r'/home/ilaria/Scrivania/Machine_Learning/Project_1/Project1_ML'\n",
    "sys.path.insert(0,my_path + r'/code/COMMON')\n",
    "\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from proj1_helpers import load_csv_data, predict_labels \n",
    "from implementations import least_squares\n",
    "from outliers import handle_outliers\n",
    "from labels import idx_2labels\n",
    "from standard import standardize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "yb, input_data, ids = load_csv_data(my_path + r'/data/train.csv', sub_sample=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(250000, 30)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-999 are replaced by 0\n"
     ]
    }
   ],
   "source": [
    "input_data, Y = handle_outliers(input_data,yb,-999,0) # substiution with zeros\n",
    "ind_back, ind_sig = idx_2labels(Y, [-1,1])\n",
    "\n",
    "input_data, mean_X, std_X = standardize(input_data)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Subdived the X features space in single features\n",
    "all_features = np.genfromtxt(my_path + r'/data/train.csv', delimiter=\",\", dtype=str, max_rows = 1)[2:]\n",
    "\n",
    "features = []\n",
    "for i in range(len(all_features)):\n",
    "    features.append((i,all_features[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## R^2  as stopping criteria : R2 of Tjur or R2 of McFadden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The only way to use the stepwise is using R2 of Tjur or Cox and Snell or McFadden because of the binary values of the indipendent variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def results_r2_stepwise(list_r2_adj,indices_features):\n",
    "    print(\"R2 asjusted values:\")\n",
    "    \n",
    "    for i in range(len(list_r2_adj)):\n",
    "        print(list_r2_adj[i])\n",
    "    print(\"-------------------------------------------------------\")\n",
    "    print(\"Number of features chosen:\", len(indices_features))\n",
    "    print(\"\\n\")\n",
    "    print(\"Indices of features chosen: \", indices_features)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Least square model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use of the error before binarization (R2 with loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------\n",
      "Feature chosen:  DER_mass_transverse_met_lep (index : 1 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  PRI_tau_pt (index : 13 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  DER_prodeta_jet_jet (index : 6 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  DER_met_phi_centrality (index : 11 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  DER_deltar_tau_lep (index : 7 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  DER_mass_vis (index : 2 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  PRI_lep_pt (index : 16 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  DER_pt_ratio_lep_tau (index : 10 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  DER_lep_eta_centrality (index : 12 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  PRI_met_sumet (index : 21 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  PRI_met (index : 19 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  DER_mass_jet_jet (index : 5 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  DER_sum_pt (index : 9 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  PRI_jet_leading_pt (index : 23 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  DER_mass_MMC (index : 0 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  PRI_jet_subleading_pt (index : 26 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  DER_pt_h (index : 3 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  PRI_jet_num (index : 22 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  DER_deltaeta_jet_jet (index : 4 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  PRI_lep_phi (index : 18 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  PRI_jet_subleading_phi (index : 28 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  PRI_jet_all_pt (index : 29 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  DER_pt_tot (index : 8 )\n"
     ]
    }
   ],
   "source": [
    "# Start of STEP-WISE algorithm \n",
    "all_candidates = input_data\n",
    "\n",
    "n = all_candidates.shape[0] #needed for the R^2 adjusted\n",
    "num = all_candidates.shape[1]\n",
    "H = np.ones((n,1)) #offset\n",
    "\n",
    "#Initialization only with offsets (lack of info)\n",
    "X = H\n",
    "k = 0 #needed for the R^2 adjusted\n",
    "\n",
    "w0, loss = least_squares(Y,X)  # The loss cannot be used as a measure for the feature selection because it's a \n",
    "y = predict_labels(w0, X)\n",
    "\n",
    "sse = loss\n",
    "sst = np.sum((Y - Y.mean())**2)  #lack of information\n",
    "R2 = np.abs((sst-sse)/sst)\n",
    "R2adj_0 = R2 - (k/(n-k-1)*(1-R2))\n",
    "\n",
    "#fix the R2adj_max\n",
    "\n",
    "R2adj_max = R2adj_0\n",
    "ind_max = 0  # this index will show us which is the best feature chosen\n",
    "del(X)\n",
    "idx_features = []\n",
    "best_R2adj = []\n",
    "\n",
    "for j in range(num):\n",
    "    R2_adj = []\n",
    "    for i in range(all_candidates.shape[1]):\n",
    "        \n",
    "        X = np.concatenate((H,all_candidates[:,i].reshape(n,1)), axis=1)\n",
    "        ws , loss = least_squares(Y,X)\n",
    "        k = len(ws) -1 # k is the number of regressor I use -> -1 because I don't consider the offset\n",
    "        \n",
    "        #y = predict_labels(ws,X)   #***** NO USE OF PREDICTION\n",
    "        SSE = np.sum(loss**2)\n",
    "        SST = np.sum((Y- Y.mean())**2)\n",
    "        R2 = np.abs((SST-SSE)/SST)\n",
    "        R2_adj.append(R2 - (k/(n-k-1)*(1-R2)))\n",
    "        \n",
    "    R2adj_chosen = np.max(R2_adj)\n",
    "    best_R2adj.append(R2adj_chosen)\n",
    "    idx_chosen = np.argmax(R2_adj)\n",
    "    \n",
    "    if R2adj_chosen > R2adj_max:\n",
    "        R2adj_max = R2adj_chosen\n",
    "        ind_max = idx_chosen\n",
    "        \n",
    "        H = np.concatenate((H, all_candidates[:,ind_max].reshape(n,1)), axis = 1)\n",
    "        \n",
    "        all_candidates = np.delete(all_candidates,ind_max,1)\n",
    "        print('-------------------------------------------------')\n",
    "        print('Feature chosen: ', features[ind_max][1], '(index :', features[ind_max][0], ')')\n",
    "        idx_features.append(features[ind_max][0])\n",
    "        del(features[ind_max])\n",
    "        \n",
    "        del(X)\n",
    "        \n",
    "    else:\n",
    "        break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 asjusted values:\n",
      "0.999999307815\n",
      "0.999999361431\n",
      "0.999999393469\n",
      "0.999999410989\n",
      "0.999999424199\n",
      "0.999999436876\n",
      "0.999999448652\n",
      "0.999999460313\n",
      "0.999999468887\n",
      "0.99999947284\n",
      "0.999999480841\n",
      "0.999999483392\n",
      "0.999999486397\n",
      "0.999999488787\n",
      "0.999999489339\n",
      "0.999999489535\n",
      "0.999999489627\n",
      "0.999999489656\n",
      "0.999999489683\n",
      "0.999999489692\n",
      "0.999999489696\n",
      "0.999999489697\n",
      "0.999999489698\n",
      "-------------------------------------------------------\n",
      "Number of features chosen: 23\n",
      "\n",
      "\n",
      "Indices of features chosen:  [1, 13, 6, 11, 7, 2, 16, 10, 12, 21, 19, 5, 9, 23, 0, 26, 3, 22, 4, 18, 28, 29, 8]\n"
     ]
    }
   ],
   "source": [
    "results_r2_stepwise(best_R2adj[:len(best_R2adj)-1], idx_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use of the probability of the 2 events (R2 Tjur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Realloc FEATURES\n",
    "features = []\n",
    "for i in range(len(all_features)):\n",
    "    features.append((i,all_features[i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No signal detected\n",
      "No signal detected\n",
      "No signal detected\n",
      "No signal detected\n",
      "No signal detected\n",
      "No signal detected\n",
      "No signal detected\n",
      "No signal detected\n",
      "No signal detected\n",
      "No signal detected\n",
      "No signal detected\n",
      "No signal detected\n",
      "No signal detected\n",
      "No signal detected\n",
      "No signal detected\n",
      "-------------------------------------------------\n",
      "Feature chosen:  DER_mass_jet_jet (index : 5 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  PRI_jet_subleading_pt (index : 26 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  PRI_tau_pt (index : 13 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  DER_mass_vis (index : 2 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  DER_pt_h (index : 3 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  DER_sum_pt (index : 9 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  DER_pt_tot (index : 8 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  PRI_met (index : 19 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  PRI_met_sumet (index : 21 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  PRI_lep_eta (index : 17 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  DER_prodeta_jet_jet (index : 6 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  PRI_jet_subleading_phi (index : 28 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  PRI_jet_subleading_eta (index : 27 )\n"
     ]
    }
   ],
   "source": [
    "# Start of STEP-WISE algorithm \n",
    "all_candidates = input_data\n",
    "\n",
    "n = all_candidates.shape[0] #needed for the R^2 adjusted\n",
    "num = all_candidates.shape[1]\n",
    "H = np.ones((n,1)) #offset\n",
    "\n",
    "#Initialization only with offsets (lack of info)\n",
    "X = H\n",
    "k = 0 #needed for the R^2 adjusted\n",
    "\n",
    "w0, loss = least_squares(Y,X)  # The loss cannot be used as a measure for the feature selection because it's a \n",
    "y = predict_labels(w0, X)\n",
    "ind_back, ind_sig = idx_2labels(y, [-1,1])\n",
    "\n",
    "y_ = X.dot(w0)\n",
    "R2 = 0\n",
    "R2adj_0 = R2 - (k/(n-k-1)*(1-R2))\n",
    "\n",
    "#fix the R2adj_max\n",
    "R2adj_max = R2adj_0\n",
    "ind_max = 0  # this index will show us which is the best feature chosen\n",
    "del(X)\n",
    "idx_features = []\n",
    "best_R2adj = []\n",
    "\n",
    "for j in range(num):\n",
    "    R2_adj = []\n",
    "    for i in range(all_candidates.shape[1]):\n",
    "        \n",
    "        X = np.concatenate((H,all_candidates[:,i].reshape(n,1)), axis=1)\n",
    "        ws , loss = least_squares(Y,X)\n",
    "        k = len(ws) -1 # k is the number of regressor I use -> -1 because I don't consider the offset\n",
    "        \n",
    "        y = predict_labels(ws,X)          \n",
    "        ind_back, ind_sig = idx_2labels(y, [-1,1])\n",
    "        \n",
    "        if len(ind_sig) == 0 or len(ind_back) ==0:\n",
    "            print('No signal detected')\n",
    "            R2_adj.append(0)\n",
    "            \n",
    "        else: \n",
    "            \n",
    "            y_ = X.dot(ws)\n",
    "\n",
    "            R2 = np.abs((np.mean(y_[ind_sig]) - np.mean(y_[ind_back])))\n",
    "            R2_adj.append(R2 - (k/(n-k-1)*(1-R2)))\n",
    "            \n",
    "        \n",
    "    R2adj_chosen = np.max(R2_adj)\n",
    "    best_R2adj.append(R2adj_chosen)\n",
    "    idx_chosen = np.argmax(R2_adj)\n",
    "\n",
    "    if R2adj_chosen > R2adj_max:\n",
    "        R2adj_max = R2adj_chosen\n",
    "        ind_max = idx_chosen\n",
    "\n",
    "        #idx_features.append(np.where(all_candidates[:,ind_max] == input_data))\n",
    "        H = np.concatenate((H, all_candidates[:,ind_max].reshape(n,1)), axis = 1)\n",
    "\n",
    "        all_candidates = np.delete(all_candidates,ind_max,1)\n",
    "        print('-------------------------------------------------')\n",
    "        print('Feature chosen: ', features[ind_max][1], '(index :', features[ind_max][0], ')')\n",
    "        idx_features.append(features[ind_max][0])\n",
    "        del(features[ind_max])\n",
    "\n",
    "        del(X)\n",
    "\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 asjusted values:\n",
      "0.711215098858\n",
      "0.756230955966\n",
      "0.790123036777\n",
      "0.798853243572\n",
      "0.806262623179\n",
      "0.813879481569\n",
      "0.817098685794\n",
      "0.819705555408\n",
      "0.820983332372\n",
      "0.820994170371\n",
      "0.821105661642\n",
      "0.821410734028\n",
      "0.821524182295\n",
      "-------------------------------------------------------\n",
      "Number of features chosen: 13\n",
      "\n",
      "\n",
      "Indices of features chosen:  [5, 26, 13, 2, 3, 9, 8, 19, 21, 17, 6, 28, 27]\n"
     ]
    }
   ],
   "source": [
    "results_r2_stepwise(best_R2adj[:len(best_R2adj)-1], idx_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use the likelihood (McFadden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Realloc FEATURES\n",
    "features = []\n",
    "for i in range(len(all_features)):\n",
    "    features.append((i,all_features[i]))\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------\n",
      "Feature chosen:  DER_lep_eta_centrality (index : 12 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  PRI_tau_pt (index : 13 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  DER_mass_transverse_met_lep (index : 1 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  DER_met_phi_centrality (index : 11 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  PRI_jet_num (index : 22 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  DER_deltaeta_jet_jet (index : 4 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  PRI_met (index : 19 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  PRI_jet_all_pt (index : 29 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  PRI_lep_pt (index : 16 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  DER_pt_h (index : 3 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  PRI_jet_leading_pt (index : 23 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  DER_mass_vis (index : 2 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  DER_deltar_tau_lep (index : 7 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  DER_prodeta_jet_jet (index : 6 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  PRI_met_sumet (index : 21 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  PRI_jet_subleading_pt (index : 26 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  PRI_lep_phi (index : 18 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  PRI_jet_subleading_phi (index : 28 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  DER_sum_pt (index : 9 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  PRI_met_phi (index : 20 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  PRI_tau_eta (index : 14 )\n"
     ]
    }
   ],
   "source": [
    "# Start of STEP-WISE algorithm \n",
    "all_candidates = input_data\n",
    "\n",
    "n = all_candidates.shape[0] #needed for the R^2 adjusted\n",
    "num = all_candidates.shape[1]\n",
    "H = np.ones((n,1)) #offset\n",
    "\n",
    "#Initialization only with offsets (lack of info)\n",
    "X = H\n",
    "k = 0 #needed for the R^2 adjusted\n",
    "\n",
    "w0, loss = least_squares(Y,X)  # The loss cannot be used as a measure for the feature selection because it's a \n",
    "y = predict_labels(w0, X)\n",
    "loglike0 = np.sum(np.log(1+np.exp(X.dot(w0))) - y*(X.dot(w0)))\n",
    "\n",
    "R2 = 0        # For the definition of McFadden 1-1 = 0\n",
    "R2adj_0 = 0\n",
    "\n",
    "#fix the R2adj_max\n",
    "\n",
    "R2adj_max = R2adj_0\n",
    "ind_max = 0  # this index will show us which is the best feature chosen\n",
    "del(X)\n",
    "idx_features = []\n",
    "best_R2adj = []\n",
    "\n",
    "for j in range(num):\n",
    "    R2_adj = []\n",
    "    for i in range(all_candidates.shape[1]):\n",
    "        \n",
    "        X = np.concatenate((H,all_candidates[:,i].reshape(n,1)), axis=1)\n",
    "        ws , loss = least_squares(Y,X)\n",
    "        k = len(ws) -1 # k is the number of regressor I use -> -1 because I don't consider the offset\n",
    "        \n",
    "        y = predict_labels(ws,X)   \n",
    "        \n",
    "        loglike = np.sum(np.log(1+np.exp(X.dot(ws))) - y*(X.dot(ws)))\n",
    "        \n",
    "        R2 = 1-(loglike/loglike0)\n",
    "        R2_adj.append(R2 - (k/(n-k-1)*(1-R2)))\n",
    "        \n",
    "    R2adj_chosen = np.max(R2_adj)\n",
    "    best_R2adj.append(R2adj_chosen)\n",
    "    idx_chosen = np.argmax(R2_adj)\n",
    "    \n",
    "    if R2adj_chosen > R2adj_max:\n",
    "        R2adj_max = R2adj_chosen\n",
    "        ind_max = idx_chosen\n",
    "        \n",
    "        H = np.concatenate((H, all_candidates[:,ind_max].reshape(n,1)), axis = 1)\n",
    "        \n",
    "        all_candidates = np.delete(all_candidates,ind_max,1)\n",
    "        print('-------------------------------------------------')\n",
    "        print('Feature chosen: ', features[ind_max][1], '(index :', features[ind_max][0], ')')\n",
    "        idx_features.append(features[ind_max][0])\n",
    "        del(features[ind_max])\n",
    "        \n",
    "        del(X)\n",
    "        \n",
    "    else:\n",
    "        break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 asjusted values:\n",
      "0.203851601605\n",
      "0.27452708355\n",
      "0.357446393184\n",
      "0.380909496275\n",
      "0.417104747923\n",
      "0.43666269786\n",
      "0.442044547266\n",
      "0.451721146776\n",
      "0.464825449641\n",
      "0.481022035899\n",
      "0.486482185259\n",
      "0.490548112727\n",
      "0.499888932078\n",
      "0.501641602113\n",
      "0.502906336464\n",
      "0.503627050593\n",
      "0.503659349183\n",
      "0.503682188862\n",
      "0.503699246926\n",
      "0.503711380935\n",
      "0.503714720944\n",
      "-------------------------------------------------------\n",
      "Number of features chosen: 21\n",
      "\n",
      "\n",
      "Indices of features chosen:  [12, 13, 1, 11, 22, 4, 19, 29, 16, 3, 23, 2, 7, 6, 21, 26, 18, 28, 9, 20, 14]\n"
     ]
    }
   ],
   "source": [
    "results_r2_stepwise(best_R2adj[:len(best_R2adj)-1], idx_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Least square model using cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am not sure that cross validation can be used we don't have to estimate any hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### R2 with likelihood (McFadden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from split_data import split_data\n",
    "\n",
    "sys.path.insert(0,my_path + r'/code/ilaria')\n",
    "from i_cross_validation_methods import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Realloc FEATURES\n",
    "features = []\n",
    "for i in range(len(all_features)):\n",
    "    features.append((i,all_features[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------\n",
      "Feature chosen:  DER_lep_eta_centrality (index : 12 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  PRI_tau_pt (index : 13 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  DER_mass_transverse_met_lep (index : 1 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  DER_met_phi_centrality (index : 11 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  PRI_jet_num (index : 22 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  DER_deltaeta_jet_jet (index : 4 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  PRI_met (index : 19 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  PRI_jet_all_pt (index : 29 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  PRI_lep_pt (index : 16 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  DER_pt_h (index : 3 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  PRI_jet_leading_pt (index : 23 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  DER_mass_vis (index : 2 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  DER_deltar_tau_lep (index : 7 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  DER_prodeta_jet_jet (index : 6 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  PRI_met_sumet (index : 21 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  PRI_jet_subleading_pt (index : 26 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  PRI_lep_phi (index : 18 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  PRI_met_phi (index : 20 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  DER_sum_pt (index : 9 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  PRI_jet_subleading_phi (index : 28 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  PRI_tau_phi (index : 15 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  PRI_jet_leading_eta (index : 24 )\n"
     ]
    }
   ],
   "source": [
    "# Start of STEP-WISE algorithm \n",
    "all_candidates = input_data\n",
    "\n",
    "n = all_candidates.shape[0] #needed for the R^2 adjusted\n",
    "num = all_candidates.shape[1]\n",
    "H = np.ones((n,1)) #offset\n",
    "\n",
    "#Initialization only with offsets (lack of info)\n",
    "X = H\n",
    "k = 0 #needed for the R^2 adjusted\n",
    "\n",
    "w0, loss = least_squares(Y,X)  # The loss cannot be used as a measure for the feature selection because it's a \n",
    "y = predict_labels(w0, X)\n",
    "loglike0 = np.sum(np.log(1+np.exp(X.dot(w0))) - y*(X.dot(w0)))\n",
    "\n",
    "R2 = 0        # For the definition of McFadden 1-1 = 0\n",
    "R2adj_0 = 0\n",
    "\n",
    "#fix the R2adj_max\n",
    "\n",
    "R2adj_max = R2adj_0\n",
    "ind_max = 0  # this index will show us which is the best feature chosen\n",
    "del(X)\n",
    "idx_features = []\n",
    "best_R2adj = []\n",
    "\n",
    "for j in range(num):\n",
    "    R2_adj = []\n",
    "    for i in range(all_candidates.shape[1]):\n",
    "        \n",
    "        X = np.concatenate((H,all_candidates[:,i].reshape(n,1)), axis=1)\n",
    "        \n",
    "        # CROSS-VALIDATION\n",
    "        \n",
    "        w_tr_tot, loss_tr_tot, loss_te_tot = cross_validation_ls(Y,X)\n",
    "        ws = w_tr_tot[np.argmin(loss_te_tot)]\n",
    "        \n",
    "        k = len(ws) -1 # k is the number of regressor I use -> -1 because I don't consider the offset\n",
    "        \n",
    "        y = predict_labels(ws,X)   \n",
    "        \n",
    "        loglike = np.sum(np.log(1+np.exp(X.dot(ws))) - y*(X.dot(ws)))\n",
    "        \n",
    "        R2 = 1-(loglike/loglike0)\n",
    "        R2_adj.append(R2 - (k/(n-k-1)*(1-R2)))\n",
    "        \n",
    "    R2adj_chosen = np.max(R2_adj)\n",
    "    best_R2adj.append(R2adj_chosen)\n",
    "    idx_chosen = np.argmax(R2_adj)\n",
    "    \n",
    "    if R2adj_chosen > R2adj_max:\n",
    "        R2adj_max = R2adj_chosen\n",
    "        ind_max = idx_chosen\n",
    "        \n",
    "        H = np.concatenate((H, all_candidates[:,ind_max].reshape(n,1)), axis = 1)\n",
    "        \n",
    "        all_candidates = np.delete(all_candidates,ind_max,1)\n",
    "        print('-------------------------------------------------')\n",
    "        print('Feature chosen: ', features[ind_max][1], '(index :', features[ind_max][0], ')')\n",
    "        idx_features.append(features[ind_max][0])\n",
    "        del(features[ind_max])\n",
    "        \n",
    "        del(X)\n",
    "        \n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 asjusted values:\n",
      "0.19737696412\n",
      "0.269403358329\n",
      "0.353843302574\n",
      "0.377653976523\n",
      "0.413845668945\n",
      "0.433729784756\n",
      "0.438987198133\n",
      "0.449027452605\n",
      "0.462165599802\n",
      "0.477094977648\n",
      "0.482883945115\n",
      "0.48696066974\n",
      "0.498932606922\n",
      "0.500747961218\n",
      "0.502078522523\n",
      "0.502863518365\n",
      "0.502913791686\n",
      "0.502954234765\n",
      "0.50298559172\n",
      "0.502998809377\n",
      "0.503001618212\n",
      "0.50300410961\n",
      "-------------------------------------------------------\n",
      "Number of features chosen: 22\n",
      "\n",
      "\n",
      "Indices of features chosen:  [12, 13, 1, 11, 22, 4, 19, 29, 16, 3, 23, 2, 7, 6, 21, 26, 18, 20, 9, 28, 15, 24]\n"
     ]
    }
   ],
   "source": [
    "results_r2_stepwise(best_R2adj[:len(best_R2adj)-1], idx_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Ridge regression with cross validation (needed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I used only lambda as hyperparameter because I am not building a polynomial model. But I added different features transformation (square or log or power), so maybe we can test the polynomial after the best features are selected "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using the loss of ridge regression as the error of R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Realloc FEATURES\n",
    "features = []\n",
    "for i in range(len(all_features)):\n",
    "    features.append((i,all_features[i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-2a1f0915b327>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mH\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mall_candidates\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;31m#CROSS VALIDATION\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0mw_tr_tot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_tr_tot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_te_tot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_validation_rr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mws\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mw_tr_tot\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_te_tot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ilaria/Scrivania/Machine_Learning/Project_1/Project1_ML/code/ilaria/i_cross_validation_methods.py\u001b[0m in \u001b[0;36mcross_validation_rr\u001b[0;34m(y, x)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m             \u001b[0;31m# compute losses for the k'th fold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m             \u001b[0mw_tr_tmp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrmse_tr_tmp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrmse_te_tmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_validation_r\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0;31m# store losses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ilaria/Scrivania/Machine_Learning/Project_1/Project1_ML/code/ilaria/i_cross_validation_methods.py\u001b[0m in \u001b[0;36mcross_validation_r\u001b[0;34m(y, x, k_indices, k, lambda_)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m    \u001b[0;31m# calculate the loss for train and test data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m     \u001b[0mrmse_tr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mcompute_mse_reg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_tr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m     \u001b[0mrmse_te\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mcompute_mse_reg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_te\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_te\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_tr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ilaria/Scrivania/Machine_Learning/Project_1/Project1_ML/code/COMMON/costs.py\u001b[0m in \u001b[0;36mcompute_mse_reg\u001b[0;34m(y, tx, w, lambda_)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m# compute the error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0me\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mtx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;31m# mean squared error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "# Start of STEP-WISE algorithm \n",
    "all_candidates = input_data\n",
    "\n",
    "n = all_candidates.shape[0] #needed for the R^2 adjusted\n",
    "num = all_candidates.shape[1]\n",
    "H = np.ones((n,1)) #offset\n",
    "\n",
    "#Initialization only with offsets (lack of info)\n",
    "X = H\n",
    "k = 0 #needed for the R^2 adjusted\n",
    "\n",
    "w0, loss = ridge_regression(Y,X,0)  # start with lambda = 0  \n",
    "y = predict_labels(w0, X)\n",
    "\n",
    "sse = loss\n",
    "sst = np.sum((Y - Y.mean())**2)  #lack of information\n",
    "R2 = np.abs((sst-sse)/sst)\n",
    "R2adj_0 = R2 - (k/(n-k-1)*(1-R2))\n",
    "\n",
    "#fix the R2adj_max\n",
    "\n",
    "R2adj_max = R2adj_0\n",
    "ind_max = 0  # this index will show us which is the best feature chosen\n",
    "del(X)\n",
    "idx_features = []\n",
    "best_R2adj = []\n",
    "\n",
    "for j in range(num):\n",
    "    R2_adj = []\n",
    "    for i in range(all_candidates.shape[1]):\n",
    "        \n",
    "        X = np.concatenate((H,all_candidates[:,i].reshape(n,1)), axis=1)\n",
    "        #CROSS VALIDATION\n",
    "        w_tr_tot, loss_tr_tot, loss_te_tot = cross_validation_rr(Y,X)\n",
    "        \n",
    "        ws = w_tr_tot[np.argmin(loss_te_tot)]\n",
    "        loss = np.min(loss_te_tot)\n",
    "        k = len(ws) -1 # k is the number of regressor I use -> -1 because I don't consider the offset\n",
    "        \n",
    "        #y = predict_labels(ws,X)   #***** NO USE OF PREDICTION\n",
    "        SSE = np.sum(loss**2)\n",
    "        SST = np.sum((Y- Y.mean())**2)\n",
    "        R2 = np.abs((SST-SSE)/SST)\n",
    "        R2_adj.append(R2 - (k/(n-k-1)*(1-R2)))\n",
    "        \n",
    "    R2adj_chosen = np.max(R2_adj)\n",
    "    best_R2adj.append(R2adj_chosen)\n",
    "    idx_chosen = np.argmax(R2_adj)\n",
    "    \n",
    "    if R2adj_chosen > R2adj_max:\n",
    "        R2adj_max = R2adj_chosen\n",
    "        ind_max = idx_chosen\n",
    "        \n",
    "        H = np.concatenate((H, all_candidates[:,ind_max].reshape(n,1)), axis = 1)\n",
    "        \n",
    "        all_candidates = np.delete(all_candidates,ind_max,1)\n",
    "        print('-------------------------------------------------')\n",
    "        print('Feature chosen: ', features[ind_max][1], '(index :', features[ind_max][0], ')')\n",
    "        idx_features.append(features[ind_max][0])\n",
    "        del(features[ind_max])\n",
    "        \n",
    "        del(X)\n",
    "        \n",
    "    else:\n",
    "        break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

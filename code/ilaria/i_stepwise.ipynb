{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features selection with STEPWISE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "my_path = r'/home/ilaria/Scrivania/Machine_Learning/Project_1/Project1_ML'\n",
    "sys.path.insert(0,my_path + r'/code/COMMON')\n",
    "\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from proj1_helpers import load_csv_data, predict_labels \n",
    "from implementations import least_squares\n",
    "from outliers import handle_outliers\n",
    "from labels import idx_2labels\n",
    "from standard import standardize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "yb, input_data, ids = load_csv_data(my_path + r'/data/train.csv', sub_sample=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(250000, 30)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-999 are replaced by 0\n"
     ]
    }
   ],
   "source": [
    "input_data, Y = handle_outliers(input_data,yb,-999,0) # substiution with zeros\n",
    "ind_back, ind_sig = idx_2labels(Y, [-1,1])\n",
    "\n",
    "input_data, mean_X, std_X = standardize(input_data)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Subdived the X features space in single features\n",
    "all_features = np.genfromtxt(my_path + r'/data/train.csv', delimiter=\",\", dtype=str, max_rows = 1)[2:]\n",
    "\n",
    "features = []\n",
    "for i in range(len(all_features)):\n",
    "    features.append((i,all_features[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## R^2  as stopping criteria : R2 of Tjur or R2 of McFadden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The only way to use the stepwise is using R2 of Tjur or Cox and Snell or McFadden because of the binary values of the indipendent variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Least square model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use of the error before binarization (R2 with loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------\n",
      "Feature chosen:  DER_mass_transverse_met_lep\n",
      "-------------------------------------------------\n",
      "Feature chosen:  PRI_tau_pt\n",
      "-------------------------------------------------\n",
      "Feature chosen:  DER_prodeta_jet_jet\n",
      "-------------------------------------------------\n",
      "Feature chosen:  DER_met_phi_centrality\n",
      "-------------------------------------------------\n",
      "Feature chosen:  DER_deltar_tau_lep\n",
      "-------------------------------------------------\n",
      "Feature chosen:  DER_mass_vis\n",
      "-------------------------------------------------\n",
      "Feature chosen:  PRI_lep_pt\n",
      "-------------------------------------------------\n",
      "Feature chosen:  DER_pt_ratio_lep_tau\n",
      "-------------------------------------------------\n",
      "Feature chosen:  DER_lep_eta_centrality\n",
      "-------------------------------------------------\n",
      "Feature chosen:  PRI_met_sumet\n",
      "-------------------------------------------------\n",
      "Feature chosen:  PRI_met\n",
      "-------------------------------------------------\n",
      "Feature chosen:  DER_mass_jet_jet\n",
      "-------------------------------------------------\n",
      "Feature chosen:  DER_sum_pt\n",
      "-------------------------------------------------\n",
      "Feature chosen:  PRI_jet_leading_pt\n",
      "-------------------------------------------------\n",
      "Feature chosen:  DER_mass_MMC\n",
      "-------------------------------------------------\n",
      "Feature chosen:  PRI_jet_subleading_pt\n",
      "-------------------------------------------------\n",
      "Feature chosen:  DER_pt_h\n",
      "-------------------------------------------------\n",
      "Feature chosen:  PRI_jet_num\n",
      "-------------------------------------------------\n",
      "Feature chosen:  DER_deltaeta_jet_jet\n",
      "-------------------------------------------------\n",
      "Feature chosen:  PRI_lep_phi\n",
      "-------------------------------------------------\n",
      "Feature chosen:  PRI_jet_subleading_phi\n",
      "-------------------------------------------------\n",
      "Feature chosen:  PRI_jet_all_pt\n",
      "-------------------------------------------------\n",
      "Feature chosen:  DER_pt_tot\n"
     ]
    }
   ],
   "source": [
    "# Start of STEP-WISE algorithm \n",
    "all_candidates = input_data\n",
    "\n",
    "n = all_candidates.shape[0] #needed for the R^2 adjusted\n",
    "num = all_candidates.shape[1]\n",
    "H = np.ones((n,1)) #offset\n",
    "\n",
    "#Initialization only with offsets (lack of info)\n",
    "X = H\n",
    "K = 0 #needed for the R^2 adjusted\n",
    "\n",
    "w0, loss = least_squares(Y,X)  # The loss cannot be used as a measure for the feature selection because it's a \n",
    "y = predict_labels(w0, X)\n",
    "\n",
    "sse = loss\n",
    "sst = np.sum((Y - Y.mean())**2)  #lack of information\n",
    "R2 = np.abs((sst-sse)/sst)\n",
    "R2adj_0 = R2 - (K/(n-K-1)*(1-R2))\n",
    "\n",
    "#fix the R2adj_max\n",
    "\n",
    "R2adj_max = R2adj_0\n",
    "ind_max = 0  # this index will show us which is the best feature chosen\n",
    "del(X)\n",
    "idx_features = []\n",
    "best_R2adj = []\n",
    "\n",
    "for j in range(num):\n",
    "    R2_adj = []\n",
    "    for i in range(all_candidates.shape[1]):\n",
    "        \n",
    "        X = np.concatenate((H,all_candidates[:,i].reshape(n,1)), axis=1)\n",
    "        ws , loss = least_squares(Y,X)\n",
    "        k = len(ws) -1 # k is the number of regressor I use -> -1 because I don't consider the offset\n",
    "        \n",
    "        #y = predict_labels(ws,X)   #***** NO USE OF PREDICTION\n",
    "        SSE = np.sum(loss**2)\n",
    "        SST = np.sum((Y- Y.mean())**2)\n",
    "        R2 = np.abs((SST-SSE)/SST)\n",
    "        R2_adj.append(R2 - (k/(n-k-1)*(1-R2)))\n",
    "        \n",
    "    R2adj_chosen = np.max(R2_adj)\n",
    "    best_R2adj.append(R2adj_chosen)\n",
    "    idx_chosen = np.argmax(R2_adj)\n",
    "    \n",
    "    if R2adj_chosen > R2adj_max:\n",
    "        R2adj_max = R2adj_chosen\n",
    "        ind_max = idx_chosen\n",
    "        \n",
    "        H = np.concatenate((H, all_candidates[:,ind_max].reshape(n,1)), axis = 1)\n",
    "        \n",
    "        all_candidates = np.delete(all_candidates,ind_max,1)\n",
    "        print('-------------------------------------------------')\n",
    "        print('Feature chosen: ', features[ind_max][1])\n",
    "        idx_features.append(features[ind_max][0])\n",
    "        del(features[ind_max])\n",
    "        \n",
    "        del(X)\n",
    "        \n",
    "    else:\n",
    "        break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.99999948969730612,\n",
       " 0.99999948969692165,\n",
       " 0.99999948969636787,\n",
       " 0.99999948969669772,\n",
       " 0.99999948969569463,\n",
       " 0.99999948969568886,\n",
       " 0.99999948969751906]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R2_adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features chosen: 23\n",
      "[1, 13, 6, 11, 7, 2, 16, 10, 12, 21, 19, 5, 9, 23, 0, 26, 3, 22, 4, 18, 28, 29, 8]\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of features chosen:\", len(idx_features))\n",
    "print(idx_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use of the probability of the 2 events (R2 Tjur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Realloc FEATURES\n",
    "features = []\n",
    "for i in range(len(all_features)):\n",
    "    features.append((i,all_features[i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No signal detected\n",
      "No signal detected\n",
      "No signal detected\n",
      "No signal detected\n",
      "No signal detected\n",
      "No signal detected\n",
      "No signal detected\n",
      "No signal detected\n",
      "No signal detected\n",
      "No signal detected\n",
      "No signal detected\n",
      "No signal detected\n",
      "No signal detected\n",
      "No signal detected\n",
      "No signal detected\n",
      "-------------------------------------------------\n",
      "Feature chosen:  DER_mass_jet_jet\n",
      "-------------------------------------------------\n",
      "Feature chosen:  PRI_jet_subleading_pt\n",
      "-------------------------------------------------\n",
      "Feature chosen:  PRI_tau_pt\n",
      "-------------------------------------------------\n",
      "Feature chosen:  DER_mass_vis\n",
      "-------------------------------------------------\n",
      "Feature chosen:  DER_pt_h\n",
      "-------------------------------------------------\n",
      "Feature chosen:  DER_sum_pt\n",
      "-------------------------------------------------\n",
      "Feature chosen:  DER_pt_tot\n",
      "-------------------------------------------------\n",
      "Feature chosen:  PRI_met\n",
      "-------------------------------------------------\n",
      "Feature chosen:  PRI_met_sumet\n",
      "-------------------------------------------------\n",
      "Feature chosen:  PRI_lep_eta\n",
      "-------------------------------------------------\n",
      "Feature chosen:  DER_prodeta_jet_jet\n",
      "-------------------------------------------------\n",
      "Feature chosen:  PRI_jet_subleading_phi\n",
      "-------------------------------------------------\n",
      "Feature chosen:  PRI_jet_subleading_eta\n"
     ]
    }
   ],
   "source": [
    "# Start of STEP-WISE algorithm \n",
    "all_candidates = input_data\n",
    "\n",
    "n = all_candidates.shape[0] #needed for the R^2 adjusted\n",
    "num = all_candidates.shape[1]\n",
    "H = np.ones((n,1)) #offset\n",
    "\n",
    "#Initialization only with offsets (lack of info)\n",
    "X = H\n",
    "K = 0 #needed for the R^2 adjusted\n",
    "\n",
    "w0, loss = least_squares(Y,X)  # The loss cannot be used as a measure for the feature selection because it's a \n",
    "#y = predict_labels(w0, X)\n",
    "ind_back, ind_sig = idx_2labels(y, [0,1])\n",
    "\n",
    "y_ = X.dot(w0)\n",
    "R2 = 0\n",
    "R2adj_0 = R2 - (K/(n-K-1)*(1-R2))\n",
    "\n",
    "#fix the R2adj_max\n",
    "R2adj_max = R2adj_0\n",
    "ind_max = 0  # this index will show us which is the best feature chosen\n",
    "del(X)\n",
    "idx_features = []\n",
    "best_R2adj = []\n",
    "\n",
    "for j in range(num):\n",
    "    R2_adj = []\n",
    "    for i in range(all_candidates.shape[1]):\n",
    "        \n",
    "        X = np.concatenate((H,all_candidates[:,i].reshape(n,1)), axis=1)\n",
    "        ws , loss = least_squares(Y,X)\n",
    "        k = len(ws) -1 # k is the number of regressor I use -> -1 because I don't consider the offset\n",
    "        \n",
    "        y = predict_labels(ws,X)          \n",
    "        ind_back, ind_sig = idx_2labels(y, [-1,1])\n",
    "        \n",
    "        if len(ind_sig) == 0 or len(ind_back) ==0:\n",
    "            print('No signal detected')\n",
    "            R2_adj.append(0)\n",
    "            \n",
    "        else: \n",
    "            \n",
    "            y_ = X.dot(ws)\n",
    "\n",
    "            R2 = np.abs((np.mean(y_[ind_sig]) - np.mean(y_[ind_back])))\n",
    "            R2_adj.append(R2 - (k/(n-k-1)*(1-R2)))\n",
    "            \n",
    "        \n",
    "    R2adj_chosen = np.max(R2_adj)\n",
    "    best_R2adj.append(R2adj_chosen)\n",
    "    idx_chosen = np.argmax(R2_adj)\n",
    "\n",
    "    if R2adj_chosen > R2adj_max:\n",
    "        R2adj_max = R2adj_chosen\n",
    "        ind_max = idx_chosen\n",
    "\n",
    "        #idx_features.append(np.where(all_candidates[:,ind_max] == input_data))\n",
    "        H = np.concatenate((H, all_candidates[:,ind_max].reshape(n,1)), axis = 1)\n",
    "\n",
    "        all_candidates = np.delete(all_candidates,ind_max,1)\n",
    "        print('-------------------------------------------------')\n",
    "        print('Feature chosen: ', features[ind_max][1])\n",
    "        idx_features.append(features[ind_max][0])\n",
    "        del(features[ind_max])\n",
    "\n",
    "        del(X)\n",
    "\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.79932954505553233,\n",
       " 0.73814002387044686,\n",
       " 0.81078963226025014,\n",
       " 0.8167394283129078,\n",
       " 0.7834495977228878,\n",
       " 0.75618167933603697,\n",
       " 0.81110238707071369,\n",
       " 0.82140638806704502,\n",
       " 0.82068400833700905,\n",
       " 0.81451288049716175,\n",
       " 0.82087527683274886,\n",
       " 0.82083313346174369,\n",
       " 0.81195590681577445,\n",
       " 0.80959831329100285,\n",
       " 0.82134458520180198,\n",
       " 0.82151163207493982,\n",
       " 0.81451290130685072]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R2_adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features chosen: 13\n",
      "[5, 26, 13, 2, 3, 9, 8, 19, 21, 17, 6, 28, 27]\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of features chosen:\", len(idx_features))\n",
    "print(idx_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use the likelihood (McFadden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Realloc FEATURES\n",
    "features = []\n",
    "for i in range(len(all_features)):\n",
    "    features.append((i,all_features[i]))\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------\n",
      "Feature chosen:  DER_lep_eta_centrality\n",
      "-------------------------------------------------\n",
      "Feature chosen:  PRI_tau_pt\n",
      "-------------------------------------------------\n",
      "Feature chosen:  DER_mass_transverse_met_lep\n",
      "-------------------------------------------------\n",
      "Feature chosen:  DER_met_phi_centrality\n",
      "-------------------------------------------------\n",
      "Feature chosen:  PRI_jet_num\n",
      "-------------------------------------------------\n",
      "Feature chosen:  DER_deltaeta_jet_jet\n",
      "-------------------------------------------------\n",
      "Feature chosen:  PRI_met\n",
      "-------------------------------------------------\n",
      "Feature chosen:  PRI_jet_all_pt\n",
      "-------------------------------------------------\n",
      "Feature chosen:  PRI_lep_pt\n",
      "-------------------------------------------------\n",
      "Feature chosen:  DER_pt_h\n",
      "-------------------------------------------------\n",
      "Feature chosen:  PRI_jet_leading_pt\n",
      "-------------------------------------------------\n",
      "Feature chosen:  DER_mass_vis\n",
      "-------------------------------------------------\n",
      "Feature chosen:  DER_deltar_tau_lep\n",
      "-------------------------------------------------\n",
      "Feature chosen:  DER_prodeta_jet_jet\n",
      "-------------------------------------------------\n",
      "Feature chosen:  PRI_met_sumet\n",
      "-------------------------------------------------\n",
      "Feature chosen:  PRI_jet_subleading_pt\n",
      "-------------------------------------------------\n",
      "Feature chosen:  PRI_lep_phi\n",
      "-------------------------------------------------\n",
      "Feature chosen:  PRI_jet_subleading_phi\n",
      "-------------------------------------------------\n",
      "Feature chosen:  DER_sum_pt\n",
      "-------------------------------------------------\n",
      "Feature chosen:  PRI_met_phi\n",
      "-------------------------------------------------\n",
      "Feature chosen:  PRI_tau_eta\n"
     ]
    }
   ],
   "source": [
    "# Start of STEP-WISE algorithm \n",
    "all_candidates = input_data\n",
    "\n",
    "n = all_candidates.shape[0] #needed for the R^2 adjusted\n",
    "num = all_candidates.shape[1]\n",
    "H = np.ones((n,1)) #offset\n",
    "\n",
    "#Initialization only with offsets (lack of info)\n",
    "X = H\n",
    "K = 0 #needed for the R^2 adjusted\n",
    "\n",
    "w0, loss = least_squares(Y,X)  # The loss cannot be used as a measure for the feature selection because it's a \n",
    "y = predict_labels(w0, X)\n",
    "loglike0 = np.sum(np.log(1+np.exp(X.dot(w0))) - y*(X.dot(w0)))\n",
    "\n",
    "R2 = 0        # For the definition of Cox and snell 1-1 = 0\n",
    "R2adj_0 = 0\n",
    "\n",
    "#fix the R2adj_max\n",
    "\n",
    "R2adj_max = R2adj_0\n",
    "ind_max = 0  # this index will show us which is the best feature chosen\n",
    "del(X)\n",
    "idx_features = []\n",
    "best_R2adj = []\n",
    "\n",
    "for j in range(num):\n",
    "    R2_adj = []\n",
    "    for i in range(all_candidates.shape[1]):\n",
    "        \n",
    "        X = np.concatenate((H,all_candidates[:,i].reshape(n,1)), axis=1)\n",
    "        ws , loss = least_squares(Y,X)\n",
    "        k = len(ws) -1 # k is the number of regressor I use -> -1 because I don't consider the offset\n",
    "        \n",
    "        y = predict_labels(ws,X)   \n",
    "        \n",
    "        loglike = np.sum(np.log(1+np.exp(X.dot(ws))) - y*(X.dot(ws)))\n",
    "        \n",
    "        R2 = 1-(loglike/loglike0)\n",
    "        R2_adj.append(R2 - (k/(n-k-1)*(1-R2)))\n",
    "        \n",
    "    R2adj_chosen = np.max(R2_adj)\n",
    "    best_R2adj.append(R2adj_chosen)\n",
    "    idx_chosen = np.argmax(R2_adj)\n",
    "    \n",
    "    if R2adj_chosen > R2adj_max:\n",
    "        R2adj_max = R2adj_chosen\n",
    "        ind_max = idx_chosen\n",
    "        \n",
    "        H = np.concatenate((H, all_candidates[:,ind_max].reshape(n,1)), axis = 1)\n",
    "        \n",
    "        all_candidates = np.delete(all_candidates,ind_max,1)\n",
    "        print('-------------------------------------------------')\n",
    "        print('Feature chosen: ', features[ind_max][1])\n",
    "        idx_features.append(features[ind_max][0])\n",
    "        del(features[ind_max])\n",
    "        \n",
    "        del(X)\n",
    "        \n",
    "    else:\n",
    "        break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.50113697844029692,\n",
       " 0.50251753116391462,\n",
       " 0.50368664230321181,\n",
       " 0.4996807773808416,\n",
       " 0.50371421645983028,\n",
       " 0.50371273971310371,\n",
       " 0.50371296716950276,\n",
       " 0.5037141726137806,\n",
       " 0.50371071437142145]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R2_adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features chosen: 21\n",
      "[12, 13, 1, 11, 22, 4, 19, 29, 16, 3, 23, 2, 7, 6, 21, 26, 18, 28, 9, 20, 14]\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of features chosen:\", len(idx_features))\n",
    "print(idx_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Least square model using cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### R2 with likelihood (McFadden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from split_data import split_data\n",
    "from build_poly import build_poly\n",
    "\n",
    "ratio = 0.7\n",
    "seed = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Realloc FEATURES\n",
    "features = []\n",
    "for i in range(len(all_features)):\n",
    "    features.append((i,all_features[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Start of STEP-WISE algorithm \n",
    "all_candidates = input_data\n",
    "\n",
    "n = all_candidates.shape[0] #needed for the R^2 adjusted\n",
    "num = all_candidates.shape[1]\n",
    "H = np.ones((n,1)) #offset\n",
    "\n",
    "#Initialization only with offsets (lack of info)\n",
    "X = H\n",
    "K = 0 #needed for the R^2 adjusted\n",
    "\n",
    "w0, loss = least_squares(Y,X)  # The loss cannot be used as a measure for the feature selection because it's a \n",
    "y = predict_labels(w0, X)\n",
    "loglike0 = np.sum(np.log(1+np.exp(X.dot(w0))) - y*(X.dot(w0)))\n",
    "\n",
    "R2 = 0        # For the definition of Cox and snell 1-1 = 0\n",
    "R2adj_0 = 0\n",
    "\n",
    "#fix the R2adj_max\n",
    "\n",
    "R2adj_max = R2adj_0\n",
    "ind_max = 0  # this index will show us which is the best feature chosen\n",
    "del(X)\n",
    "idx_features = []\n",
    "best_R2adj = []\n",
    "\n",
    "for j in range(num):\n",
    "    R2_adj = []\n",
    "    for i in range(all_candidates.shape[1]):\n",
    "        \n",
    "        X = np.concatenate((H,all_candidates[:,i].reshape(n,1)), axis=1)\n",
    "        ws , loss = least_squares(Y,X)\n",
    "        k = len(ws) -1 # k is the number of regressor I use -> -1 because I don't consider the offset\n",
    "        \n",
    "        y = predict_labels(ws,X)   \n",
    "        \n",
    "        loglike = np.sum(np.log(1+np.exp(X.dot(ws))) - y*(X.dot(ws)))\n",
    "        \n",
    "        R2 = 1-(loglike/loglike0)\n",
    "        R2_adj.append(R2 - (k/(n-k-1)*(1-R2)))\n",
    "        \n",
    "    R2adj_chosen = np.max(R2_adj)\n",
    "    best_R2adj.append(R2adj_chosen)\n",
    "    idx_chosen = np.argmax(R2_adj)\n",
    "    \n",
    "    if R2adj_chosen > R2adj_max:\n",
    "        R2adj_max = R2adj_chosen\n",
    "        ind_max = idx_chosen\n",
    "        \n",
    "        H = np.concatenate((H, all_candidates[:,ind_max].reshape(n,1)), axis = 1)\n",
    "        \n",
    "        all_candidates = np.delete(all_candidates,ind_max,1)\n",
    "        print('-------------------------------------------------')\n",
    "        print('Feature chosen: ', features[ind_max][1])\n",
    "        idx_features.append(features[ind_max][0])\n",
    "        del(features[ind_max])\n",
    "        \n",
    "        del(X)\n",
    "        \n",
    "    else:\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features selection with STEPWISE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "my_path = r'C:\\Users\\utente\\Documents\\GitHub\\Project1_ML'\n",
    "sys.path.insert(0,my_path + r'\\code\\COMMON')\n",
    "\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from proj1_helpers import load_csv_data, predict_labels \n",
    "from implementations import *\n",
    "from outliers import handle_outliers\n",
    "from labels import idx_2labels\n",
    "from standard import standardize\n",
    "from costs import compute_loglikelihood_reg\n",
    "from optimize_hyperparams import *\n",
    "from cross_validation import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data and outliers management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "yb, input_data, ids = load_csv_data(my_path + r'/data/train.csv', sub_sample=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(250000, 30)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-999 are replaced by the mean value of the feature\n"
     ]
    }
   ],
   "source": [
    "input_data, Y = handle_outliers(input_data,yb,-999,'mean') # substiution with mean because the standardization\n",
    "                                                           #can be affected, otherwise we should delete the whole row\n",
    "ind_back, ind_sig = idx_2labels(Y, [-1,1])\n",
    "Y[ind_back] = 0\n",
    "\n",
    "input_data, mean_X, std_X = standardize(input_data)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Subdived the X features space in single features\n",
    "all_features = np.genfromtxt(my_path + r'/data/train.csv', delimiter=\",\", dtype=str, max_rows = 1)[2:]\n",
    "# converting array in list in order to simplify the adding of features\n",
    "all_features = list(all_features)\n",
    "\n",
    "features = []\n",
    "for i in range(len(all_features)):\n",
    "    features.append((i,all_features[i]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## R^2  as stopping criteria : 1) R2 with error , 2) R2 of Tjur or 3) R2 of McFadden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The only way to use the stepwise is using R2 of Tjur or McFadden because of the binary values of the indipendent variable, but the error was also used "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def results_r2_stepwise(list_r2_adj,indices_features):\n",
    "    print(\"R2 asjusted values:\")\n",
    "    \n",
    "    for i in range(len(list_r2_adj)):\n",
    "        print(list_r2_adj[i])\n",
    "    print(\"-------------------------------------------------------\")\n",
    "    print(\"Number of features chosen:\", len(indices_features))\n",
    "    print(\"\\n\")\n",
    "    print(\"Indices of features chosen: \", indices_features)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A) Least square model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No cross validation (NC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) NC: Use of the error before binarization (R2 with loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------\n",
      "Feature chosen:  DER_mass_transverse_met_lep (index : 1 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  PRI_tau_pt (index : 13 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  DER_deltaeta_jet_jet (index : 4 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  DER_met_phi_centrality (index : 11 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  DER_deltar_tau_lep (index : 7 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  DER_mass_vis (index : 2 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  PRI_lep_pt (index : 16 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  DER_pt_ratio_lep_tau (index : 10 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  PRI_met (index : 19 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  DER_lep_eta_centrality (index : 12 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  PRI_jet_leading_pt (index : 23 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  DER_pt_tot (index : 8 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  DER_mass_jet_jet (index : 5 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  PRI_jet_subleading_pt (index : 26 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  PRI_jet_num (index : 22 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  PRI_met_sumet (index : 21 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  DER_mass_MMC (index : 0 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  PRI_lep_phi (index : 18 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  DER_prodeta_jet_jet (index : 6 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  DER_pt_h (index : 3 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  PRI_jet_subleading_phi (index : 28 )\n"
     ]
    }
   ],
   "source": [
    "# Start of STEP-WISE algorithm \n",
    "all_candidates = input_data\n",
    "\n",
    "n = all_candidates.shape[0] #needed for the R^2 adjusted\n",
    "num = all_candidates.shape[1]\n",
    "H = np.ones((n,1)) #offset\n",
    "\n",
    "#Initialization only with offsets (lack of info)\n",
    "X = H\n",
    "k = 0 #needed for the R^2 adjusted\n",
    "\n",
    "w0, loss = least_squares(Y,X)  # The loss cannot be used as a measure for the feature selection because it's a \n",
    "y = predict_labels(w0, X)\n",
    "\n",
    "sse = loss\n",
    "sst = np.sum((Y - Y.mean())**2)  #lack of information\n",
    "R2 = np.abs((sst-sse)/sst)\n",
    "R2adj_0 = R2 - (k/(n-k-1)*(1-R2))\n",
    "\n",
    "#fix the R2adj_max\n",
    "\n",
    "R2adj_max = R2adj_0\n",
    "ind_max = 0  # this index will show us which is the best feature chosen\n",
    "del(X)\n",
    "idx_features = []\n",
    "best_R2adj = []\n",
    "\n",
    "for j in range(num):\n",
    "    R2_adj = []\n",
    "    for i in range(all_candidates.shape[1]):\n",
    "        \n",
    "        X = np.concatenate((H,all_candidates[:,i].reshape(n,1)), axis=1)\n",
    "        ws , loss = least_squares(Y,X)\n",
    "        k = len(ws) -1 # k is the number of regressor I use -> -1 because I don't consider the offset\n",
    "        \n",
    "        #y = predict_labels(ws,X)   #***** NO USE OF PREDICTION\n",
    "        SSE = loss\n",
    "        SST = np.sum((Y- Y.mean())**2)\n",
    "        R2 = np.abs((SST-SSE)/SST)\n",
    "        R2_adj.append(R2 - (k/(n-k-1)*(1-R2)))\n",
    "        \n",
    "    R2adj_chosen = np.max(R2_adj)\n",
    "    best_R2adj.append(R2adj_chosen)\n",
    "    idx_chosen = np.argmax(R2_adj)\n",
    "    \n",
    "    if R2adj_chosen > R2adj_max:\n",
    "        R2adj_max = R2adj_chosen\n",
    "        ind_max = idx_chosen\n",
    "        \n",
    "        H = np.concatenate((H, all_candidates[:,ind_max].reshape(n,1)), axis = 1)\n",
    "        \n",
    "        all_candidates = np.delete(all_candidates,ind_max,1)\n",
    "        print('-------------------------------------------------')\n",
    "        print('Feature chosen: ', features[ind_max][1], '(index :', features[ind_max][0], ')')\n",
    "        idx_features.append(features[ind_max][0])\n",
    "        del(features[ind_max])\n",
    "        \n",
    "        del(X)\n",
    "        \n",
    "    else:\n",
    "        break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 asjusted values:\n",
      "0.999998246996\n",
      "0.999998316254\n",
      "0.999998366571\n",
      "0.999998394757\n",
      "0.99999840969\n",
      "0.999998424917\n",
      "0.99999844367\n",
      "0.999998459265\n",
      "0.999998468735\n",
      "0.999998474896\n",
      "0.99999847968\n",
      "0.999998482105\n",
      "0.999998484408\n",
      "0.999998486981\n",
      "0.99999848737\n",
      "0.999998488309\n",
      "0.999998488373\n",
      "0.999998488384\n",
      "0.99999848839\n",
      "0.999998488392\n",
      "0.999998488393\n",
      "-------------------------------------------------------\n",
      "Number of features chosen: 21\n",
      "\n",
      "\n",
      "Indices of features chosen:  [1, 13, 4, 11, 7, 2, 16, 10, 19, 12, 23, 8, 5, 26, 22, 21, 0, 18, 6, 3, 28]\n"
     ]
    }
   ],
   "source": [
    "results_r2_stepwise(best_R2adj[:len(best_R2adj)-1], idx_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) NC: Use of the probability of the 2 events (R2 Tjur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Realloc FEATURES\n",
    "features = []\n",
    "for i in range(len(all_features)):\n",
    "    features.append((i,all_features[i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No signal detected\n",
      "No signal detected\n",
      "No signal detected\n",
      "No signal detected\n",
      "No signal detected\n",
      "No signal detected\n",
      "No signal detected\n",
      "No signal detected\n",
      "No signal detected\n",
      "No signal detected\n",
      "No signal detected\n",
      "No signal detected\n",
      "No signal detected\n",
      "No signal detected\n",
      "No signal detected\n",
      "No signal detected\n",
      "No signal detected\n",
      "-------------------------------------------------\n",
      "Feature chosen:  DER_mass_jet_jet (index : 5 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  PRI_tau_pt (index : 13 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  DER_pt_h (index : 3 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  PRI_jet_subleading_pt (index : 26 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  DER_mass_vis (index : 2 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  PRI_met (index : 19 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  DER_deltar_tau_lep (index : 7 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  PRI_jet_all_pt (index : 29 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  DER_pt_tot (index : 8 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  PRI_jet_subleading_phi (index : 28 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  PRI_jet_subleading_eta (index : 27 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  PRI_jet_leading_eta (index : 24 )\n"
     ]
    }
   ],
   "source": [
    "# Start of STEP-WISE algorithm \n",
    "all_candidates = input_data\n",
    "\n",
    "n = all_candidates.shape[0] #needed for the R^2 adjusted\n",
    "num = all_candidates.shape[1]\n",
    "H = np.ones((n,1)) #offset\n",
    "\n",
    "#Initialization only with offsets (lack of info)\n",
    "X = H\n",
    "k = 0 #needed for the R^2 adjusted\n",
    "\n",
    "w0, loss = least_squares(Y,X) \n",
    "y = predict_labels(w0, X)\n",
    "ind_back, ind_sig = idx_2labels(y, [0,1])\n",
    "\n",
    "y_ = X.dot(w0)\n",
    "R2 = 0\n",
    "R2adj_0 = R2 - (k/(n-k-1)*(1-R2))\n",
    "\n",
    "#fix the R2adj_max\n",
    "R2adj_max = R2adj_0\n",
    "ind_max = 0  # this index will show us which is the best feature chosen\n",
    "del(X)\n",
    "idx_features = []\n",
    "best_R2adj = []\n",
    "\n",
    "for j in range(num):\n",
    "    R2_adj = []\n",
    "    for i in range(all_candidates.shape[1]):\n",
    "        \n",
    "        X = np.concatenate((H,all_candidates[:,i].reshape(n,1)), axis=1)\n",
    "        ws , loss = least_squares(Y,X)\n",
    "        k = len(ws) -1 # k is the number of regressor I use -> -1 because I don't consider the offset\n",
    "        \n",
    "        y = predict_labels(ws,X)          \n",
    "        ind_back, ind_sig = idx_2labels(y, [0,1])\n",
    "        \n",
    "        if len(ind_sig) == 0 or len(ind_back) ==0:\n",
    "            print('No signal detected')\n",
    "            R2_adj.append(0)\n",
    "            \n",
    "        else: \n",
    "            \n",
    "            y_ = X.dot(ws)\n",
    "\n",
    "            R2 = np.abs((np.mean(y_[ind_sig]) - np.mean(y_[ind_back])))\n",
    "            R2_adj.append(R2 - (k/(n-k-1)*(1-R2)))\n",
    "            \n",
    "        \n",
    "    R2adj_chosen = np.max(R2_adj)\n",
    "    best_R2adj.append(R2adj_chosen)\n",
    "    idx_chosen = np.argmax(R2_adj)\n",
    "\n",
    "    if R2adj_chosen > R2adj_max:\n",
    "        R2adj_max = R2adj_chosen\n",
    "        ind_max = idx_chosen\n",
    "\n",
    "        #idx_features.append(np.where(all_candidates[:,ind_max] == input_data))\n",
    "        H = np.concatenate((H, all_candidates[:,ind_max].reshape(n,1)), axis = 1)\n",
    "\n",
    "        all_candidates = np.delete(all_candidates,ind_max,1)\n",
    "        print('-------------------------------------------------')\n",
    "        print('Feature chosen: ', features[ind_max][1], '(index :', features[ind_max][0], ')')\n",
    "        idx_features.append(features[ind_max][0])\n",
    "        del(features[ind_max])\n",
    "\n",
    "        del(X)\n",
    "\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 asjusted values:\n",
      "0.346306088284\n",
      "0.364393069363\n",
      "0.380616523588\n",
      "0.389912517644\n",
      "0.394024256458\n",
      "0.396117256195\n",
      "0.397938510559\n",
      "0.398364531728\n",
      "0.398434460516\n",
      "0.398560902406\n",
      "0.398597637228\n",
      "0.398607879751\n",
      "-------------------------------------------------------\n",
      "Number of features chosen: 12\n",
      "\n",
      "\n",
      "Indices of features chosen:  [5, 13, 3, 26, 2, 19, 7, 29, 8, 28, 27, 24]\n"
     ]
    }
   ],
   "source": [
    "results_r2_stepwise(best_R2adj[:len(best_R2adj)-1], idx_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3) NC: Use of the likelihood (McFadden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Realloc FEATURES\n",
    "features = []\n",
    "for i in range(len(all_features)):\n",
    "    features.append((i,all_features[i]))\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------\n",
      "Feature chosen:  DER_mass_transverse_met_lep (index : 1 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  DER_met_phi_centrality (index : 11 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  DER_sum_pt (index : 9 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  DER_mass_vis (index : 2 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  PRI_lep_phi (index : 18 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  PRI_jet_subleading_phi (index : 28 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  PRI_jet_leading_eta (index : 24 )\n"
     ]
    }
   ],
   "source": [
    "# Start of STEP-WISE algorithm \n",
    "all_candidates = input_data\n",
    "\n",
    "n = all_candidates.shape[0] #needed for the R^2 adjusted\n",
    "num = all_candidates.shape[1]\n",
    "H = np.ones((n,1)) #offset\n",
    "\n",
    "#Initialization only with offsets (lack of info)\n",
    "X = H\n",
    "k = 0 #needed for the R^2 adjusted\n",
    "\n",
    "w0, loss = least_squares(Y,X)  # The loss cannot be used as a measure for the feature selection because it's a \n",
    "y = predict_labels(w0, X)\n",
    "loglike0 = compute_loglikelihood_reg(y,X,w0)#np.sum(np.log(1+np.exp(X.dot(w0))) - y*(X.dot(w0)))\n",
    "\n",
    "R2 = 0        # For the definition of McFadden 1-1 = 0\n",
    "R2adj_0 = 0\n",
    "\n",
    "#fix the R2adj_max\n",
    "\n",
    "R2adj_max = R2adj_0\n",
    "ind_max = 0  # this index will show us which is the best feature chosen\n",
    "del(X)\n",
    "idx_features = []\n",
    "best_R2adj = []\n",
    "\n",
    "for j in range(num):\n",
    "    R2_adj = []\n",
    "    for i in range(all_candidates.shape[1]):\n",
    "        \n",
    "        X = np.concatenate((H,all_candidates[:,i].reshape(n,1)), axis=1)\n",
    "        ws , loss = least_squares(Y,X)\n",
    "        k = len(ws) -1 # k is the number of regressor I use -> -1 because I don't consider the offset\n",
    "        \n",
    "        y = predict_labels(ws,X)   \n",
    "        \n",
    "        loglike = compute_loglikelihood_reg(y,X,ws) #np.sum(np.log(1+np.exp(X.dot(ws))) - y*(X.dot(ws)))\n",
    "        \n",
    "        R2 = 1-(loglike/loglike0)\n",
    "        R2_adj.append(R2 - (k/(n-k-1)*(1-R2)))\n",
    "        \n",
    "    R2adj_chosen = np.max(R2_adj)\n",
    "    best_R2adj.append(R2adj_chosen)\n",
    "    idx_chosen = np.argmax(R2_adj)\n",
    "    \n",
    "    if R2adj_chosen > R2adj_max:\n",
    "        R2adj_max = R2adj_chosen\n",
    "        ind_max = idx_chosen\n",
    "        \n",
    "        H = np.concatenate((H, all_candidates[:,ind_max].reshape(n,1)), axis = 1)\n",
    "        \n",
    "        all_candidates = np.delete(all_candidates,ind_max,1)\n",
    "        print('-------------------------------------------------')\n",
    "        print('Feature chosen: ', features[ind_max][1], '(index :', features[ind_max][0], ')')\n",
    "        idx_features.append(features[ind_max][0])\n",
    "        del(features[ind_max])\n",
    "        \n",
    "        del(X)\n",
    "        \n",
    "    else:\n",
    "        break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 asjusted values:\n",
      "0.127199992503\n",
      "0.161949175423\n",
      "0.162775033532\n",
      "0.163218892521\n",
      "0.163296584222\n",
      "0.163326074239\n",
      "0.163331726027\n",
      "-------------------------------------------------------\n",
      "Number of features chosen: 7\n",
      "\n",
      "\n",
      "Indices of features chosen:  [1, 11, 9, 2, 18, 28, 24]\n"
     ]
    }
   ],
   "source": [
    "results_r2_stepwise(best_R2adj[:len(best_R2adj)-1], idx_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8376553003945949"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loglike/loglike0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using cross validation (C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am not sure that cross validation can be used we don't have to estimate any hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3) C: R2 with likelihood (McFadden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from split_data import split_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Realloc FEATURES\n",
    "features = []\n",
    "for i in range(len(all_features)):\n",
    "    features.append((i,all_features[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------\n",
      "Feature chosen:  DER_mass_transverse_met_lep (index : 1 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  DER_met_phi_centrality (index : 11 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  DER_sum_pt (index : 9 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  PRI_jet_all_pt (index : 29 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  PRI_met (index : 19 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  DER_pt_h (index : 3 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  DER_lep_eta_centrality (index : 12 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  DER_mass_MMC (index : 0 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  DER_deltar_tau_lep (index : 7 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  DER_pt_ratio_lep_tau (index : 10 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  DER_mass_vis (index : 2 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  PRI_lep_pt (index : 16 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  PRI_jet_leading_pt (index : 23 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  PRI_met_sumet (index : 21 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  PRI_tau_phi (index : 15 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  PRI_tau_pt (index : 13 )\n"
     ]
    }
   ],
   "source": [
    "# Start of STEP-WISE algorithm \n",
    "all_candidates = input_data\n",
    "\n",
    "n = all_candidates.shape[0] #needed for the R^2 adjusted\n",
    "num = all_candidates.shape[1]\n",
    "H = np.ones((n,1)) #offset\n",
    "\n",
    "#Initialization only with offsets (lack of info)\n",
    "X = H\n",
    "k = 0 #needed for the R^2 adjusted\n",
    "\n",
    "w0, loss = least_squares(Y,X)  # The loss cannot be used as a measure for the feature selection because it's a \n",
    "y = predict_labels(w0, X)\n",
    "loglike0 = np.sum(np.log(1+np.exp(X.dot(w0))) - y*(X.dot(w0)))\n",
    "\n",
    "R2 = 0   # For the definition of McFadden 1-1 = 0\n",
    "R2adj_0 = 0\n",
    "\n",
    "#fix the R2adj_max\n",
    "\n",
    "R2adj_max = R2adj_0\n",
    "ind_max = 0  # this index will show us which is the best feature chosen\n",
    "del(X)\n",
    "idx_features = []\n",
    "best_R2adj = []\n",
    "\n",
    "# parameters for cross validation\n",
    "arg_ls = dict()\n",
    "arg_ls['method'] = 'ls'\n",
    "arg_ls['loss'] = 'rmse'\n",
    "arg_ls['k_fold'] = 10\n",
    "\n",
    "\n",
    "for j in range(num):\n",
    "    R2_adj = []\n",
    "    for i in range(all_candidates.shape[1]):\n",
    "        \n",
    "        X = np.concatenate((H,all_candidates[:,i].reshape(n,1)), axis=1)\n",
    "        \n",
    "        # CROSS-VALIDATION\n",
    "        \n",
    "        w_tr_tot, loss_tr_tot, loss_te_tot = cross_validation(Y, X, arg_ls)\n",
    "        \n",
    "        ws = w_tr_tot[np.argmin(loss_te_tot)]\n",
    "        \n",
    "        k = len(ws) -1 # k is the number of regressor I use -> -1 because I don't consider the offset\n",
    "        \n",
    "        y = predict_labels(ws,X)   \n",
    "        \n",
    "        loglike = np.sum(np.log(1+np.exp(X.dot(ws))) - y*(X.dot(ws)))\n",
    "        \n",
    "        R2 = 1-(loglike/loglike0)\n",
    "        R2_adj.append(R2 - (k/(n-k-1)*(1-R2)))\n",
    "        \n",
    "    R2adj_chosen = np.max(R2_adj)\n",
    "    best_R2adj.append(R2adj_chosen)\n",
    "    idx_chosen = np.argmax(R2_adj)\n",
    "    \n",
    "    if R2adj_chosen > R2adj_max:\n",
    "        R2adj_max = R2adj_chosen\n",
    "        ind_max = idx_chosen\n",
    "        \n",
    "        H = np.concatenate((H, all_candidates[:,ind_max].reshape(n,1)), axis = 1)\n",
    "        \n",
    "        all_candidates = np.delete(all_candidates,ind_max,1)\n",
    "        print('-------------------------------------------------')\n",
    "        print('Feature chosen: ', features[ind_max][1], '(index :', features[ind_max][0], ')')\n",
    "        idx_features.append(features[ind_max][0])\n",
    "        del(features[ind_max])\n",
    "        \n",
    "        del(X)\n",
    "        \n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 asjusted values:\n",
      "0.127029003781\n",
      "0.162219139573\n",
      "0.163016309637\n",
      "0.16354554708\n",
      "0.167617483869\n",
      "0.172882697354\n",
      "0.174062939737\n",
      "0.174659663743\n",
      "0.175157077078\n",
      "0.176255853643\n",
      "0.177589693328\n",
      "0.17903001667\n",
      "0.180289605671\n",
      "0.180653688622\n",
      "0.180673303474\n",
      "0.18068436144\n",
      "-------------------------------------------------------\n",
      "Number of features chosen: 16\n",
      "\n",
      "\n",
      "Indices of features chosen:  [1, 11, 9, 29, 19, 3, 12, 0, 7, 10, 2, 16, 23, 21, 15, 13]\n"
     ]
    }
   ],
   "source": [
    "results_r2_stepwise(best_R2adj[:len(best_R2adj)-1], idx_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# B) Ridge regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I used only lambda as hyperparameter because I am not building a polynomial model. But we can add different features transformation (square or log or power), so maybe we can test the polynomial after the best features are selected "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## No cross validation (NC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set lambda\n",
    "lambda_ = 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) (NC) Using the loss from ridge regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Realloc FEATURES\n",
    "features = []\n",
    "for i in range(len(all_features)):\n",
    "    features.append((i,all_features[i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------\n",
      "Feature chosen:  DER_mass_transverse_met_lep (index : 1 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  PRI_tau_pt (index : 13 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  DER_deltaeta_jet_jet (index : 4 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  DER_met_phi_centrality (index : 11 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  DER_deltar_tau_lep (index : 7 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  DER_lep_eta_centrality (index : 12 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  PRI_met (index : 19 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  DER_mass_vis (index : 2 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  DER_mass_jet_jet (index : 5 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  PRI_jet_subleading_pt (index : 26 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  DER_pt_tot (index : 8 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  DER_pt_h (index : 3 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  PRI_jet_num (index : 22 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  PRI_lep_phi (index : 18 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  PRI_tau_phi (index : 15 )\n"
     ]
    }
   ],
   "source": [
    "# Start of STEP-WISE algorithm \n",
    "all_candidates = input_data\n",
    "\n",
    "n = all_candidates.shape[0] #needed for the R^2 adjusted\n",
    "num = all_candidates.shape[1]\n",
    "H = np.ones((n,1)) #offset\n",
    "\n",
    "#Initialization only with offsets (lack of info)\n",
    "X = H\n",
    "k = 0 #needed for the R^2 adjusted\n",
    "\n",
    "w0, loss = ridge_regression(Y,X,0)  # start with lambda = 0  \n",
    "y = predict_labels(w0, X)\n",
    "\n",
    "sse = loss\n",
    "sst = np.sum((Y - Y.mean())**2)  #lack of information\n",
    "R2 = np.abs((sst-sse)/sst)\n",
    "R2adj_0 = R2 - (k/(n-k-1)*(1-R2))\n",
    "\n",
    "#fix the R2adj_max\n",
    "\n",
    "R2adj_max = R2adj_0\n",
    "ind_max = 0  # this index will show us which is the best feature chosen\n",
    "del(X)\n",
    "idx_features = []\n",
    "best_R2adj = []\n",
    "\n",
    "for j in range(num):\n",
    "    R2_adj = []\n",
    "    for i in range(all_candidates.shape[1]):\n",
    "        \n",
    "        X = np.concatenate((H,all_candidates[:,i].reshape(n,1)), axis=1)\n",
    "        \n",
    "        ws, loss = ridge_regression(Y,X,lambda_)\n",
    "        k = len(ws) -1 # k is the number of regressor I use -> -1 because I don't consider the offset\n",
    "        \n",
    "        SSE = loss\n",
    "        SST = np.sum((Y- Y.mean())**2)   # it has no sense\n",
    "        R2 = np.abs((SST-SSE)/SST)\n",
    "        R2_adj.append(R2 - (k/(n-k-1)*(1-R2)))\n",
    "        \n",
    "    R2adj_chosen = np.max(R2_adj)\n",
    "    best_R2adj.append(R2adj_chosen)\n",
    "    idx_chosen = np.argmax(R2_adj)\n",
    "    \n",
    "    if R2adj_chosen > R2adj_max:\n",
    "        R2adj_max = R2adj_chosen\n",
    "        ind_max = idx_chosen\n",
    "        \n",
    "        H = np.concatenate((H, all_candidates[:,ind_max].reshape(n,1)), axis = 1)\n",
    "        \n",
    "        all_candidates = np.delete(all_candidates,ind_max,1)\n",
    "        print('-------------------------------------------------')\n",
    "        print('Feature chosen: ', features[ind_max][1], '(index :', features[ind_max][0], ')')\n",
    "        idx_features.append(features[ind_max][0])\n",
    "        del(features[ind_max])\n",
    "        \n",
    "        del(X)\n",
    "        \n",
    "    else:\n",
    "        break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 asjusted values:\n",
      "0.999998118035\n",
      "0.999998183913\n",
      "0.999998230611\n",
      "0.999998262345\n",
      "0.999998274162\n",
      "0.999998283279\n",
      "0.999998287416\n",
      "0.999998291185\n",
      "0.999998293376\n",
      "0.999998296691\n",
      "0.999998297975\n",
      "0.999998299392\n",
      "0.999998299686\n",
      "0.999998299704\n",
      "0.999998299707\n",
      "-------------------------------------------------------\n",
      "Number of features chosen: 15\n",
      "\n",
      "\n",
      "Indices of features chosen:  [1, 13, 4, 11, 7, 12, 19, 2, 5, 26, 8, 3, 22, 18, 15]\n"
     ]
    }
   ],
   "source": [
    "results_r2_stepwise(best_R2adj[:len(best_R2adj)-1], idx_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) (NC) Use of the probability of the 2 events (R2 Tjur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Realloc FEATURES\n",
    "features = []\n",
    "for i in range(len(all_features)):\n",
    "    features.append((i,all_features[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No signal detected\n",
      "No signal detected\n",
      "No signal detected\n",
      "No signal detected\n",
      "No signal detected\n",
      "No signal detected\n",
      "No signal detected\n",
      "No signal detected\n",
      "No signal detected\n",
      "No signal detected\n",
      "No signal detected\n",
      "No signal detected\n",
      "No signal detected\n",
      "No signal detected\n",
      "No signal detected\n",
      "No signal detected\n",
      "No signal detected\n",
      "No signal detected\n",
      "No signal detected\n",
      "No signal detected\n",
      "No signal detected\n",
      "No signal detected\n",
      "No signal detected\n",
      "No signal detected\n",
      "No signal detected\n",
      "No signal detected\n",
      "No signal detected\n",
      "No signal detected\n",
      "No signal detected\n",
      "No signal detected\n"
     ]
    }
   ],
   "source": [
    "# Start of STEP-WISE algorithm \n",
    "all_candidates = input_data\n",
    "\n",
    "n = all_candidates.shape[0] #needed for the R^2 adjusted\n",
    "num = all_candidates.shape[1]\n",
    "H = np.ones((n,1)) #offset\n",
    "\n",
    "#Initialization only with offsets (lack of info)\n",
    "X = H\n",
    "k = 0 #needed for the R^2 adjusted\n",
    "\n",
    "w0, loss = ridge_regression(Y,X,0)  \n",
    "y = predict_labels(w0, X)\n",
    "ind_back, ind_sig = idx_2labels(y, [0,1])\n",
    "\n",
    "y_ = X.dot(w0)\n",
    "R2 = 0\n",
    "R2adj_0 = R2 - (k/(n-k-1)*(1-R2))\n",
    "\n",
    "#fix the R2adj_max\n",
    "R2adj_max = R2adj_0\n",
    "ind_max = 0  # this index will show us which is the best feature chosen\n",
    "del(X)\n",
    "idx_features = []\n",
    "best_R2adj = []\n",
    "\n",
    "for j in range(num):\n",
    "    R2_adj = []\n",
    "    for i in range(all_candidates.shape[1]):\n",
    "        \n",
    "        X = np.concatenate((H,all_candidates[:,i].reshape(n,1)), axis=1)\n",
    "        ws, loss = ridge_regression(Y,X,lambda_)\n",
    "        \n",
    "        k = len(ws) -1 # k is the number of regressor I use -> -1 because I don't consider the offset\n",
    "        \n",
    "        y = predict_labels(ws,X)          \n",
    "        ind_back, ind_sig = idx_2labels(y, [-1,1])\n",
    "        \n",
    "        if len(ind_sig) == 0 or len(ind_back) ==0:\n",
    "            print('No signal detected')\n",
    "            R2_adj.append(0)\n",
    "            \n",
    "        else: \n",
    "            \n",
    "            y_ = X.dot(ws)\n",
    "\n",
    "            R2 = np.abs((np.mean(y_[ind_sig]) - np.mean(y_[ind_back])))\n",
    "            R2_adj.append(R2 - (k/(n-k-1)*(1-R2)))\n",
    "            \n",
    "        \n",
    "    R2adj_chosen = np.max(R2_adj)\n",
    "    best_R2adj.append(R2adj_chosen)\n",
    "    idx_chosen = np.argmax(R2_adj)\n",
    "\n",
    "    if R2adj_chosen > R2adj_max:\n",
    "        R2adj_max = R2adj_chosen\n",
    "        ind_max = idx_chosen\n",
    "\n",
    "        #idx_features.append(np.where(all_candidates[:,ind_max] == input_data))\n",
    "        H = np.concatenate((H, all_candidates[:,ind_max].reshape(n,1)), axis = 1)\n",
    "\n",
    "        all_candidates = np.delete(all_candidates,ind_max,1)\n",
    "        print('-------------------------------------------------')\n",
    "        print('Feature chosen: ', features[ind_max][1], '(index :', features[ind_max][0], ')')\n",
    "        idx_features.append(features[ind_max][0])\n",
    "        del(features[ind_max])\n",
    "\n",
    "        del(X)\n",
    "\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 asjusted values:\n",
      "-------------------------------------------------------\n",
      "Number of features chosen: 0\n",
      "\n",
      "\n",
      "Indices of features chosen:  []\n"
     ]
    }
   ],
   "source": [
    "results_r2_stepwise(best_R2adj[:len(best_R2adj)-1], idx_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) (NC) Use of the likelihood (McFadden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Realloc FEATURES\n",
    "features = []\n",
    "for i in range(len(all_features)):\n",
    "    features.append((i,all_features[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------\n",
      "Feature chosen:  PRI_tau_pt (index : 13 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  DER_mass_transverse_met_lep (index : 1 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  DER_deltaeta_jet_jet (index : 4 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  DER_met_phi_centrality (index : 11 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  DER_lep_eta_centrality (index : 12 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  PRI_met (index : 19 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  DER_pt_h (index : 3 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  PRI_lep_pt (index : 16 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  DER_mass_vis (index : 2 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  DER_deltar_tau_lep (index : 7 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  PRI_jet_leading_pt (index : 23 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  DER_pt_tot (index : 8 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  PRI_jet_num (index : 22 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  PRI_met_sumet (index : 21 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  DER_mass_jet_jet (index : 5 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  PRI_lep_phi (index : 18 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  DER_mass_MMC (index : 0 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  PRI_met_phi (index : 20 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  PRI_lep_eta (index : 17 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  PRI_jet_subleading_phi (index : 28 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  PRI_jet_subleading_eta (index : 27 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  PRI_jet_leading_eta (index : 24 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  PRI_tau_eta (index : 14 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  PRI_tau_phi (index : 15 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  PRI_jet_leading_phi (index : 25 )\n"
     ]
    }
   ],
   "source": [
    "# Start of STEP-WISE algorithm \n",
    "all_candidates = input_data\n",
    "\n",
    "n = all_candidates.shape[0] #needed for the R^2 adjusted\n",
    "num = all_candidates.shape[1]\n",
    "H = np.ones((n,1)) #offset\n",
    "\n",
    "#Initialization only with offsets (lack of info)\n",
    "X = H\n",
    "k = 0 #needed for the R^2 adjusted\n",
    "\n",
    "w0, loss = ridge_regression(Y,X,0)  # lambda set to 0 \n",
    "y = predict_labels(w0, X)\n",
    "loglike0 = compute_loglikelihood_reg(y,X,w0) #np.sum(np.log(1+np.exp(X.dot(w0))) - y*(X.dot(w0)))\n",
    "\n",
    "R2 = 0        # For the definition of McFadden 1-1 = 0\n",
    "R2adj_0 = 0\n",
    "\n",
    "#fix the R2adj_max\n",
    "\n",
    "R2adj_max = R2adj_0\n",
    "ind_max = 0  # this index will show us which is the best feature chosen\n",
    "del(X)\n",
    "idx_features = []\n",
    "best_R2adj = []\n",
    "\n",
    "for j in range(num):\n",
    "    R2_adj = []\n",
    "    for i in range(all_candidates.shape[1]):\n",
    "        \n",
    "        X = np.concatenate((H,all_candidates[:,i].reshape(n,1)), axis=1)\n",
    "        \n",
    "        ws, loss = ridge_regression(Y,X,lambda_)\n",
    "        \n",
    "        y = predict_labels(ws,X)   \n",
    "        \n",
    "        loglike = compute_loglikelihood_reg(y,X,ws) #np.sum(np.log(1+np.exp(X.dot(ws))) - y*(X.dot(ws)))\n",
    "        \n",
    "        R2 = 1-(loglike/loglike0)\n",
    "        R2_adj.append(R2 - (k/(n-k-1)*(1-R2)))\n",
    "        \n",
    "    R2adj_chosen = np.max(R2_adj)\n",
    "    best_R2adj.append(R2adj_chosen)\n",
    "    idx_chosen = np.argmax(R2_adj)\n",
    "    \n",
    "    if R2adj_chosen > R2adj_max:\n",
    "        R2adj_max = R2adj_chosen\n",
    "        ind_max = idx_chosen\n",
    "        \n",
    "        H = np.concatenate((H, all_candidates[:,ind_max].reshape(n,1)), axis = 1)\n",
    "        \n",
    "        all_candidates = np.delete(all_candidates,ind_max,1)\n",
    "        print('-------------------------------------------------')\n",
    "        print('Feature chosen: ', features[ind_max][1], '(index :', features[ind_max][0], ')')\n",
    "        idx_features.append(features[ind_max][0])\n",
    "        del(features[ind_max])\n",
    "        \n",
    "        del(X)\n",
    "        \n",
    "    else:\n",
    "        break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 asjusted values:\n",
      "0.144854047951\n",
      "0.245180817163\n",
      "0.352173598228\n",
      "0.41170504767\n",
      "0.424708632929\n",
      "0.432288557592\n",
      "0.443235724243\n",
      "0.473466109895\n",
      "0.477541148029\n",
      "0.483139657023\n",
      "0.490491175076\n",
      "0.492657971875\n",
      "0.494326119857\n",
      "0.495663494828\n",
      "0.496289473241\n",
      "0.496334681561\n",
      "0.496370986565\n",
      "0.496388422301\n",
      "0.49640087404\n",
      "0.496411964442\n",
      "0.496414840522\n",
      "0.496418199262\n",
      "0.496421128045\n",
      "0.496423325284\n",
      "0.496423537179\n",
      "-------------------------------------------------------\n",
      "Number of features chosen: 25\n",
      "\n",
      "\n",
      "Indices of features chosen:  [13, 1, 4, 11, 12, 19, 3, 16, 2, 7, 23, 8, 22, 21, 5, 18, 0, 20, 17, 28, 27, 24, 14, 15, 25]\n"
     ]
    }
   ],
   "source": [
    "results_r2_stepwise(best_R2adj[:len(best_R2adj)-1], idx_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With cross validation (C) (it's needed in order to choose the best hyperparameter lambda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) (C) Using the loss of ridge regression as the error of R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Realloc FEATURES\n",
    "features = []\n",
    "for i in range(len(all_features)):\n",
    "    features.append((i,all_features[i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Start of STEP-WISE algorithm \n",
    "all_candidates = input_data\n",
    "\n",
    "n = all_candidates.shape[0] #needed for the R^2 adjusted\n",
    "num = all_candidates.shape[1]\n",
    "H = np.ones((n,1)) #offset\n",
    "\n",
    "#Initialization only with offsets (lack of info)\n",
    "X = H\n",
    "k = 0 #needed for the R^2 adjusted\n",
    "\n",
    "w0, loss = ridge_regression(Y,X,0)  # start with lambda = 0  \n",
    "y = predict_labels(w0, X)\n",
    "\n",
    "sse = loss\n",
    "sst = np.sum((Y - Y.mean())**2)  #lack of information\n",
    "R2 = np.abs((sst-sse)/sst)\n",
    "R2adj_0 = R2 - (k/(n-k-1)*(1-R2))\n",
    "\n",
    "#fix the R2adj_max\n",
    "\n",
    "R2adj_max = R2adj_0\n",
    "ind_max = 0  # this index will show us which is the best feature chosen\n",
    "del(X)\n",
    "idx_features = []\n",
    "best_R2adj = []\n",
    "\n",
    "for j in range(num):\n",
    "    R2_adj = []\n",
    "    for i in range(all_candidates.shape[1]):\n",
    "        \n",
    "        X = np.concatenate((H,all_candidates[:,i].reshape(n,1)), axis=1)\n",
    "        #CROSS VALIDATION\n",
    "        w_tr_tot, loss_tr_tot, loss_te_tot = cross_validation_rr(Y,X)\n",
    "        \n",
    "        ws = w_tr_tot[np.argmin(loss_te_tot)]\n",
    "        loss = np.min(loss_te_tot)\n",
    "        k = len(ws) -1 # k is the number of regressor I use -> -1 because I don't consider the offset\n",
    "        \n",
    "        SSE = loss\n",
    "        SST = np.sum((Y- Y.mean())**2)\n",
    "        R2 = np.abs((SST-SSE)/SST)\n",
    "        R2_adj.append(R2 - (k/(n-k-1)*(1-R2)))\n",
    "        \n",
    "    R2adj_chosen = np.max(R2_adj)\n",
    "    best_R2adj.append(R2adj_chosen)\n",
    "    idx_chosen = np.argmax(R2_adj)\n",
    "    \n",
    "    if R2adj_chosen > R2adj_max:\n",
    "        R2adj_max = R2adj_chosen\n",
    "        ind_max = idx_chosen\n",
    "        \n",
    "        H = np.concatenate((H, all_candidates[:,ind_max].reshape(n,1)), axis = 1)\n",
    "        \n",
    "        all_candidates = np.delete(all_candidates,ind_max,1)\n",
    "        print('-------------------------------------------------')\n",
    "        print('Feature chosen: ', features[ind_max][1], '(index :', features[ind_max][0], ')')\n",
    "        idx_features.append(features[ind_max][0])\n",
    "        del(features[ind_max])\n",
    "        \n",
    "        del(X)\n",
    "        \n",
    "    else:\n",
    "        break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 asjusted values:\n",
      "-------------------------------------------------------\n",
      "Number of features chosen: 0\n",
      "\n",
      "\n",
      "Indices of features chosen:  []\n"
     ]
    }
   ],
   "source": [
    "results_r2_stepwise(best_R2adj[:len(best_R2adj)-1], idx_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) (C) Use of the probability of the 2 events (R2 Tjur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Realloc FEATURES\n",
    "features = []\n",
    "for i in range(len(all_features)):\n",
    "    features.append((i,all_features[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No signal detected\n",
      "No signal detected\n",
      "No signal detected\n",
      "No signal detected\n",
      "No signal detected\n",
      "No signal detected\n",
      "No signal detected\n",
      "No signal detected\n",
      "No signal detected\n",
      "No signal detected\n",
      "No signal detected\n",
      "No signal detected\n",
      "No signal detected\n",
      "No signal detected\n",
      "No signal detected\n",
      "No signal detected\n",
      "No signal detected\n",
      "-------------------------------------------------\n",
      "Feature chosen:  DER_mass_jet_jet (index : 5 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  PRI_tau_pt (index : 13 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  DER_pt_h (index : 3 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  PRI_jet_subleading_pt (index : 26 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  DER_mass_vis (index : 2 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  PRI_met (index : 19 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  DER_deltar_tau_lep (index : 7 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  PRI_jet_all_pt (index : 29 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  DER_pt_tot (index : 8 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  PRI_jet_subleading_phi (index : 28 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  PRI_jet_subleading_eta (index : 27 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  PRI_jet_leading_eta (index : 24 )\n"
     ]
    }
   ],
   "source": [
    "# Start of STEP-WISE algorithm \n",
    "all_candidates = input_data\n",
    "\n",
    "n = all_candidates.shape[0] #needed for the R^2 adjusted\n",
    "num = all_candidates.shape[1]\n",
    "H = np.ones((n,1)) #offset\n",
    "\n",
    "#Initialization only with offsets (lack of info)\n",
    "X = H\n",
    "k = 0 #needed for the R^2 adjusted\n",
    "\n",
    "w0, loss = ridge_regression(Y,X,0)  \n",
    "y = predict_labels(w0, X)\n",
    "ind_back, ind_sig = idx_2labels(y, [0,1])\n",
    "\n",
    "y_ = X.dot(w0)\n",
    "R2 = 0\n",
    "R2adj_0 = R2 - (k/(n-k-1)*(1-R2))\n",
    "\n",
    "#fix the R2adj_max\n",
    "R2adj_max = R2adj_0\n",
    "ind_max = 0  # this index will show us which is the best feature chosen\n",
    "del(X)\n",
    "idx_features = []\n",
    "best_R2adj = []\n",
    "\n",
    "for j in range(num):\n",
    "    R2_adj = []\n",
    "    for i in range(all_candidates.shape[1]):\n",
    "        \n",
    "        X = np.concatenate((H,all_candidates[:,i].reshape(n,1)), axis=1)\n",
    "        #CROSS VALIDATION\n",
    "        w_tr_tot, loss_tr_tot, loss_te_tot = cross_validation_rr(Y,X)\n",
    "        ws = w_tr_tot[np.argmin(loss_te_tot)]\n",
    "        \n",
    "        k = len(ws) -1 # k is the number of regressor I use -> -1 because I don't consider the offset\n",
    "        \n",
    "        y = predict_labels(ws,X)          \n",
    "        ind_back, ind_sig = idx_2labels(y, [-1,1])\n",
    "        \n",
    "        if len(ind_sig) == 0 or len(ind_back) ==0:\n",
    "            print('No signal detected')\n",
    "            R2_adj.append(0)\n",
    "            \n",
    "        else: \n",
    "            \n",
    "            y_ = X.dot(ws)\n",
    "\n",
    "            R2 = np.abs((np.mean(y_[ind_sig]) - np.mean(y_[ind_back])))\n",
    "            R2_adj.append(R2 - (k/(n-k-1)*(1-R2)))\n",
    "            \n",
    "        \n",
    "    R2adj_chosen = np.max(R2_adj)\n",
    "    best_R2adj.append(R2adj_chosen)\n",
    "    idx_chosen = np.argmax(R2_adj)\n",
    "\n",
    "    if R2adj_chosen > R2adj_max:\n",
    "        R2adj_max = R2adj_chosen\n",
    "        ind_max = idx_chosen\n",
    "\n",
    "        #idx_features.append(np.where(all_candidates[:,ind_max] == input_data))\n",
    "        H = np.concatenate((H, all_candidates[:,ind_max].reshape(n,1)), axis = 1)\n",
    "\n",
    "        all_candidates = np.delete(all_candidates,ind_max,1)\n",
    "        print('-------------------------------------------------')\n",
    "        print('Feature chosen: ', features[ind_max][1], '(index :', features[ind_max][0], ')')\n",
    "        idx_features.append(features[ind_max][0])\n",
    "        del(features[ind_max])\n",
    "\n",
    "        del(X)\n",
    "\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 asjusted values:\n",
      "0.692583907083\n",
      "0.728802362346\n",
      "0.761239966883\n",
      "0.779850696222\n",
      "0.788063711181\n",
      "0.792264545618\n",
      "0.795889920268\n",
      "0.796756354309\n",
      "0.7969376439\n",
      "0.797170043648\n",
      "0.797259734087\n",
      "0.797271889943\n",
      "-------------------------------------------------------\n",
      "Number of features chosen: 12\n",
      "\n",
      "\n",
      "Indices of features chosen:  [5, 13, 3, 26, 2, 19, 7, 29, 8, 28, 27, 24]\n"
     ]
    }
   ],
   "source": [
    "results_r2_stepwise(best_R2adj[:len(best_R2adj)-1], idx_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) (C) Use of the likelihood (McFadden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Realloc FEATURES\n",
    "features = []\n",
    "for i in range(len(all_features)):\n",
    "    features.append((i,all_features[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------\n",
      "Feature chosen:  PRI_tau_pt (index : 13 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  DER_mass_transverse_met_lep (index : 1 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  DER_deltaeta_jet_jet (index : 4 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  DER_met_phi_centrality (index : 11 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  DER_lep_eta_centrality (index : 12 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  PRI_met (index : 19 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  DER_pt_h (index : 3 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  PRI_lep_pt (index : 16 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  DER_mass_vis (index : 2 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  DER_deltar_tau_lep (index : 7 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  PRI_jet_leading_pt (index : 23 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  DER_pt_tot (index : 8 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  PRI_jet_num (index : 22 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  PRI_met_sumet (index : 21 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  DER_mass_jet_jet (index : 5 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  PRI_lep_phi (index : 18 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  DER_mass_MMC (index : 0 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  PRI_met_phi (index : 20 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  PRI_lep_eta (index : 17 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  PRI_jet_subleading_phi (index : 28 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  PRI_jet_subleading_eta (index : 27 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  PRI_jet_leading_eta (index : 24 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  PRI_tau_phi (index : 15 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  PRI_tau_eta (index : 14 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  PRI_jet_leading_phi (index : 25 )\n"
     ]
    }
   ],
   "source": [
    "# Start of STEP-WISE algorithm \n",
    "all_candidates = input_data\n",
    "\n",
    "n = all_candidates.shape[0] #needed for the R^2 adjusted\n",
    "num = all_candidates.shape[1]\n",
    "H = np.ones((n,1)) #offset\n",
    "\n",
    "#Initialization only with offsets (lack of info)\n",
    "X = H\n",
    "k = 0 #needed for the R^2 adjusted\n",
    "\n",
    "w0, loss = ridge_regression(Y,X,0)  # lambda set to 0 \n",
    "y = predict_labels(w0, X)\n",
    "loglike0 = np.sum(np.log(1+np.exp(X.dot(w0))) - y*(X.dot(w0)))\n",
    "\n",
    "R2 = 0        # For the definition of McFadden 1-1 = 0\n",
    "R2adj_0 = 0\n",
    "\n",
    "#fix the R2adj_max\n",
    "\n",
    "R2adj_max = R2adj_0\n",
    "ind_max = 0  # this index will show us which is the best feature chosen\n",
    "del(X)\n",
    "idx_features = []\n",
    "best_R2adj = []\n",
    "\n",
    "for j in range(num):\n",
    "    R2_adj = []\n",
    "    for i in range(all_candidates.shape[1]):\n",
    "        \n",
    "        X = np.concatenate((H,all_candidates[:,i].reshape(n,1)), axis=1)\n",
    "        #CROSS VALIDATION\n",
    "        w_tr_tot, loss_tr_tot, loss_te_tot = cross_validation_rr(Y,X)\n",
    "        ws = w_tr_tot[np.argmin(loss_te_tot)]\n",
    "        \n",
    "        y = predict_labels(ws,X)   \n",
    "        \n",
    "        loglike = np.sum(np.log(1+np.exp(X.dot(ws))) - y*(X.dot(ws)))\n",
    "        \n",
    "        R2 = 1-(loglike/loglike0)\n",
    "        R2_adj.append(R2 - (k/(n-k-1)*(1-R2)))\n",
    "        \n",
    "    R2adj_chosen = np.max(R2_adj)\n",
    "    best_R2adj.append(R2adj_chosen)\n",
    "    idx_chosen = np.argmax(R2_adj)\n",
    "    \n",
    "    if R2adj_chosen > R2adj_max:\n",
    "        R2adj_max = R2adj_chosen\n",
    "        ind_max = idx_chosen\n",
    "        \n",
    "        H = np.concatenate((H, all_candidates[:,ind_max].reshape(n,1)), axis = 1)\n",
    "        \n",
    "        all_candidates = np.delete(all_candidates,ind_max,1)\n",
    "        print('-------------------------------------------------')\n",
    "        print('Feature chosen: ', features[ind_max][1], '(index :', features[ind_max][0], ')')\n",
    "        idx_features.append(features[ind_max][0])\n",
    "        del(features[ind_max])\n",
    "        \n",
    "        del(X)\n",
    "        \n",
    "    else:\n",
    "        break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 asjusted values:\n",
      "0.144857765242\n",
      "0.245184572292\n",
      "0.352177585943\n",
      "0.411708293799\n",
      "0.424710904491\n",
      "0.432292091945\n",
      "0.443241438144\n",
      "0.47347719231\n",
      "0.477550694143\n",
      "0.483149352784\n",
      "0.4905044717\n",
      "0.4926683267\n",
      "0.494334962769\n",
      "0.495673376908\n",
      "0.496299873075\n",
      "0.496344537618\n",
      "0.496380190427\n",
      "0.496397587194\n",
      "0.496409721352\n",
      "0.496420779729\n",
      "0.496423639692\n",
      "0.49642657291\n",
      "0.496428791606\n",
      "0.496430850605\n",
      "0.496431354733\n",
      "-------------------------------------------------------\n",
      "Number of features chosen: 25\n",
      "\n",
      "\n",
      "Indices of features chosen:  [13, 1, 4, 11, 12, 19, 3, 16, 2, 7, 23, 8, 22, 21, 5, 18, 0, 20, 17, 28, 27, 24, 15, 14, 25]\n"
     ]
    }
   ],
   "source": [
    "results_r2_stepwise(best_R2adj[:len(best_R2adj)-1], idx_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No cross validation (hyperparameter fixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initialization\n",
    "max_iters = 100\n",
    "threshold = 1e-8\n",
    "gamma = 0\n",
    "method = 'gd'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use of the likelihood (McFadden)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I used only this method because it's the most reasonable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Realloc FEATURES\n",
    "features = []\n",
    "for i in range(len(all_features)):\n",
    "    features.append((i,all_features[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression (99/99): loss logLikelihood=-62866720559.99994\n",
      "Logistic Regression (99/99): loss logLikelihood=-62916782566.017204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ilaria/Scrivania/Machine_Learning/Project_1/Project1_ML/code/COMMON/costs.py:56: RuntimeWarning: overflow encountered in exp\n",
      "  loglikelihood = np.sum(np.log(1+np.exp(tx.dot(w))) - y*(tx.dot(w))) + lambda_*w.T.dot(w)\n",
      "/home/ilaria/Scrivania/Machine_Learning/Project_1/Project1_ML/code/COMMON/sigmoid.py:6: RuntimeWarning: overflow encountered in exp\n",
      "  return np.exp(z)/(np.exp(z)+1)\n",
      "/home/ilaria/Scrivania/Machine_Learning/Project_1/Project1_ML/code/COMMON/sigmoid.py:6: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return np.exp(z)/(np.exp(z)+1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression (99/99): loss logLikelihood=nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ilaria/Scrivania/Machine_Learning/Project_1/Project1_ML/code/COMMON/proj1_helpers.py:28: RuntimeWarning: invalid value encountered in less_equal\n",
      "  y_pred[np.where(y_pred <= 0)] = -1\n",
      "/home/ilaria/Scrivania/Machine_Learning/Project_1/Project1_ML/code/COMMON/proj1_helpers.py:29: RuntimeWarning: invalid value encountered in greater\n",
      "  y_pred[np.where(y_pred > 0)] = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression (99/99): loss logLikelihood=-62977964651.30821\n",
      "Logistic Regression (99/99): loss logLikelihood=nan\n",
      "Logistic Regression (99/99): loss logLikelihood=nan\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-b4a3e82b12dd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0minitial_w\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mws\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogistic_regression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_w\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mws\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mloglike\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_loglikelihood_reg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mws\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ilaria/Scrivania/Machine_Learning/Project_1/Project1_ML/code/COMMON/implementations.py\u001b[0m in \u001b[0;36mlogistic_regression\u001b[0;34m(y, tx, initial_w, max_iters, gamma, method)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m             \u001b[0;31m# compute the gradient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m             \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_gradient_logLikelihood_reg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_tot\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m             \u001b[0;31m# update w\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ilaria/Scrivania/Machine_Learning/Project_1/Project1_ML/code/COMMON/compute_gradient.py\u001b[0m in \u001b[0;36mcompute_gradient_logLikelihood_reg\u001b[0;34m(y, tx, w, lambda_)\u001b[0m\n\u001b[1;32m     21\u001b[0m     'lambda_' > 0 for the penalized likelihood. \"\"\"\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlambda_\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ilaria/Scrivania/Machine_Learning/Project_1/Project1_ML/code/COMMON/sigmoid.py\u001b[0m in \u001b[0;36msigmoid\u001b[0;34m(z)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;34m\"\"\"apply sigmoid function on z.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Start of STEP-WISE algorithm \n",
    "all_candidates = input_data\n",
    "\n",
    "n = all_candidates.shape[0] #needed for the R^2 adjusted\n",
    "num = all_candidates.shape[1]\n",
    "H = np.ones((n,1)) #offset\n",
    "\n",
    "#Initialization only with offsets (lack of info)\n",
    "X = H\n",
    "k = 0 #needed for the R^2 adjusted\n",
    "\n",
    "initial_w = np.zeros(X.shape[1])\n",
    "\n",
    "w0, loss = logistic_regression(Y,X, initial_w, max_iters, gamma, method)\n",
    "y = predict_labels(w0[-1], X)\n",
    "loglike0 = np.sum(np.log(1+np.exp(X.dot(w0))) - y*(X.dot(w0)))\n",
    "\n",
    "R2 = 0        # For the definition of McFadden 1-1 = 0\n",
    "R2adj_0 = 0\n",
    "\n",
    "#fix the R2adj_max\n",
    "\n",
    "R2adj_max = R2adj_0\n",
    "ind_max = 0  # this index will show us which is the best feature chosen\n",
    "del(X)\n",
    "idx_features = []\n",
    "best_R2adj = []\n",
    "\n",
    "for j in range(num):\n",
    "    R2_adj = []\n",
    "    for i in range(all_candidates.shape[1]):\n",
    "        \n",
    "        X = np.concatenate((H,all_candidates[:,i].reshape(n,1)), axis=1)\n",
    "        \n",
    "        initial_w = np.zeros(X.shape[1])\n",
    "        ws, loss = logistic_regression(Y,X, initial_w, max_iters, gamma, method)\n",
    "        y = predict_labels(ws[-1], X)\n",
    "        loglike = compute_loglikelihood_reg(y, X, ws)\n",
    "        \n",
    "        R2 = 1-(loglike/loglike0)\n",
    "        R2_adj.append(R2 - (k/(n-k-1)*(1-R2)))\n",
    "        \n",
    "    R2adj_chosen = np.max(R2_adj)\n",
    "    best_R2adj.append(R2adj_chosen)\n",
    "    idx_chosen = np.argmax(R2_adj)\n",
    "    \n",
    "    if R2adj_chosen > R2adj_max:\n",
    "        R2adj_max = R2adj_chosen\n",
    "        ind_max = idx_chosen\n",
    "        \n",
    "        H = np.concatenate((H, all_candidates[:,ind_max].reshape(n,1)), axis = 1)\n",
    "        \n",
    "        all_candidates = np.delete(all_candidates,ind_max,1)\n",
    "        print('-------------------------------------------------')\n",
    "        print('Feature chosen: ', features[ind_max][1], '(index :', features[ind_max][0], ')')\n",
    "        idx_features.append(features[ind_max][0])\n",
    "        del(features[ind_max])\n",
    "        \n",
    "        del(X)\n",
    "        \n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 asjusted values:\n",
      "-------------------------------------------------------\n",
      "Number of features chosen: 0\n",
      "\n",
      "\n",
      "Indices of features chosen:  []\n"
     ]
    }
   ],
   "source": [
    "results_r2_stepwise(best_R2adj[:len(best_R2adj)-1], idx_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With cross correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use of the likelihood (McFadden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Realloc FEATURES\n",
    "features = []\n",
    "for i in range(len(all_features)):\n",
    "    features.append((i,all_features[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Start of STEP-WISE algorithm \n",
    "all_candidates = input_data\n",
    "\n",
    "n = all_candidates.shape[0] #needed for the R^2 adjusted\n",
    "num = all_candidates.shape[1]\n",
    "H = np.ones((n,1)) #offset\n",
    "\n",
    "#Initialization only with offsets (lack of info)\n",
    "X = H\n",
    "k = 0 #needed for the R^2 adjusted\n",
    "\n",
    "w0, loss = logistic_regression(Y,X, initial_w, max_iters, gamma, method)\n",
    "y = predict_labels(w0, X)\n",
    "loglike0 = np.sum(np.log(1+np.exp(X.dot(w0))) - y*(X.dot(w0)))\n",
    "\n",
    "R2 = 0        # For the definition of McFadden 1-1 = 0\n",
    "R2adj_0 = 0\n",
    "\n",
    "#fix the R2adj_max\n",
    "\n",
    "R2adj_max = R2adj_0\n",
    "ind_max = 0  # this index will show us which is the best feature chosen\n",
    "del(X)\n",
    "idx_features = []\n",
    "best_R2adj = []\n",
    "\n",
    "for j in range(num):\n",
    "    R2_adj = []\n",
    "    for i in range(all_candidates.shape[1]):\n",
    "        \n",
    "        X = np.concatenate((H,all_candidates[:,i].reshape(n,1)), axis=1)\n",
    "        #CROSS VALIDATION\n",
    "        w_tr_tot, loss_tr_tot, loss_te_tot = cross_validation_lr(Y,X)\n",
    "        ws = w_tr_tot[np.argmin(loss_te_tot)]\n",
    "        \n",
    "        y = predict_labels(ws,X)   \n",
    "        \n",
    "        loglike = np.sum(np.log(1+np.exp(X.dot(ws))) - y*(X.dot(ws)))\n",
    "        \n",
    "        R2 = 1-(loglike/loglike0)\n",
    "        R2_adj.append(R2 - (k/(n-k-1)*(1-R2)))\n",
    "        \n",
    "    R2adj_chosen = np.max(R2_adj)\n",
    "    best_R2adj.append(R2adj_chosen)\n",
    "    idx_chosen = np.argmax(R2_adj)\n",
    "    \n",
    "    if R2adj_chosen > R2adj_max:\n",
    "        R2adj_max = R2adj_chosen\n",
    "        ind_max = idx_chosen\n",
    "        \n",
    "        H = np.concatenate((H, all_candidates[:,ind_max].reshape(n,1)), axis = 1)\n",
    "        \n",
    "        all_candidates = np.delete(all_candidates,ind_max,1)\n",
    "        print('-------------------------------------------------')\n",
    "        print('Feature chosen: ', features[ind_max][1], '(index :', features[ind_max][0], ')')\n",
    "        idx_features.append(features[ind_max][0])\n",
    "        del(features[ind_max])\n",
    "        \n",
    "        del(X)\n",
    "        \n",
    "    else:\n",
    "        break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 asjusted values:\n",
      "-------------------------------------------------------\n",
      "Number of features chosen: 0\n",
      "\n",
      "\n",
      "Indices of features chosen:  []\n"
     ]
    }
   ],
   "source": [
    "results_r2_stepwise(best_R2adj[:len(best_R2adj)-1], idx_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

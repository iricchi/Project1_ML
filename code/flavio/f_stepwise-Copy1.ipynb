{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features selection with STEPWISE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "my_path = r'C:\\Users\\utente\\Documents\\GitHub\\Project1_ML'\n",
    "sys.path.insert(0,my_path + r'\\code\\COMMON')\n",
    "\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from proj1_helpers import load_csv_data, predict_labels \n",
    "from implementations import *\n",
    "from outliers import handle_outliers\n",
    "from labels import idx_2labels\n",
    "from standard import standardize\n",
    "from costs import compute_loglikelihood_reg\n",
    "from optimize_hyperparams import *\n",
    "from cross_validation import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data and outliers management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "yb, input_data, ids = load_csv_data(my_path + r'/data/train.csv', sub_sample=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(250000, 30)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-999 are replaced by the mean value of the feature\n"
     ]
    }
   ],
   "source": [
    "input_data, Y = handle_outliers(input_data,yb,-999,'mean') # substiution with mean because the standardization\n",
    "                                                           #can be affected, otherwise we should delete the whole row\n",
    "ind_back, ind_sig = idx_2labels(Y, [-1,1])\n",
    "Y[ind_back] = 0\n",
    "\n",
    "input_data, mean_X, std_X = standardize(input_data)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Subdived the X features space in single features\n",
    "all_features = np.genfromtxt(my_path + r'/data/train.csv', delimiter=\",\", dtype=str, max_rows = 1)[2:]\n",
    "# converting array in list in order to simplify the adding of features\n",
    "all_features = list(all_features)\n",
    "\n",
    "features = []\n",
    "for i in range(len(all_features)):\n",
    "    features.append((i,all_features[i]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## R^2  as stopping criteria : 1) R2 with error , 2) R2 of Tjur or 3) R2 of McFadden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The only way to use the stepwise is using R2 of Tjur or McFadden because of the binary values of the indipendent variable, but the error was also used "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def results_r2_stepwise(list_r2_adj,indices_features):\n",
    "    print(\"R2 asjusted values:\")\n",
    "    \n",
    "    for i in range(len(list_r2_adj)):\n",
    "        print(list_r2_adj[i])\n",
    "    print(\"-------------------------------------------------------\")\n",
    "    print(\"Number of features chosen:\", len(indices_features))\n",
    "    print(\"\\n\")\n",
    "    print(\"Indices of features chosen: \", indices_features)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A) Least square model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No cross validation (NC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) NC: Use of the error before binarization (R2 with loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------\n",
      "Feature chosen:  DER_mass_transverse_met_lep (index : 1 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  PRI_tau_pt (index : 13 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  DER_deltaeta_jet_jet (index : 4 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  DER_met_phi_centrality (index : 11 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  DER_deltar_tau_lep (index : 7 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  DER_mass_vis (index : 2 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  PRI_lep_pt (index : 16 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  DER_pt_ratio_lep_tau (index : 10 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  PRI_met (index : 19 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  DER_lep_eta_centrality (index : 12 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  PRI_jet_leading_pt (index : 23 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  DER_pt_tot (index : 8 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  DER_mass_jet_jet (index : 5 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  PRI_jet_subleading_pt (index : 26 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  PRI_jet_num (index : 22 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  PRI_met_sumet (index : 21 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  DER_mass_MMC (index : 0 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  PRI_lep_phi (index : 18 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  DER_prodeta_jet_jet (index : 6 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  DER_pt_h (index : 3 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  PRI_jet_subleading_phi (index : 28 )\n"
     ]
    }
   ],
   "source": [
    "# Start of STEP-WISE algorithm \n",
    "all_candidates = input_data\n",
    "\n",
    "n = all_candidates.shape[0] #needed for the R^2 adjusted\n",
    "num = all_candidates.shape[1]\n",
    "H = np.ones((n,1)) #offset\n",
    "\n",
    "#Initialization only with offsets (lack of info)\n",
    "X = H\n",
    "k = 0 #needed for the R^2 adjusted\n",
    "\n",
    "w0, loss = least_squares(Y,X)  # The loss cannot be used as a measure for the feature selection because it's a \n",
    "y = predict_labels(w0, X)\n",
    "\n",
    "sse = loss*2*n\n",
    "sst = np.sum((Y - Y.mean())**2)  #lack of information\n",
    "R2 = np.abs((sst-sse)/sst)\n",
    "R2adj_0 = R2 - (k/(n-k-1)*(1-R2))\n",
    "\n",
    "#fix the R2adj_max\n",
    "\n",
    "R2adj_max = R2adj_0\n",
    "ind_max = 0  # this index will show us which is the best feature chosen\n",
    "del(X)\n",
    "idx_features = []\n",
    "best_R2adj = []\n",
    "\n",
    "for j in range(num):\n",
    "    R2_adj = []\n",
    "    for i in range(all_candidates.shape[1]):\n",
    "        \n",
    "        X = np.concatenate((H,all_candidates[:,i].reshape(n,1)), axis=1)\n",
    "        ws , loss = least_squares(Y,X)\n",
    "        k = len(ws) -1 # k is the number of regressor I use -> -1 because I don't consider the offset\n",
    "        \n",
    "        #y = predict_labels(ws,X)   #***** NO USE OF PREDICTION\n",
    "        SSE = loss*2*n\n",
    "        SST = np.sum((Y- Y.mean())**2)\n",
    "        R2 = np.abs((SST-SSE)/SST)\n",
    "        R2_adj.append(R2 - (k/(n-k-1)*(1-R2)))\n",
    "        \n",
    "    R2adj_chosen = np.max(R2_adj)\n",
    "    best_R2adj.append(R2adj_chosen)\n",
    "    idx_chosen = np.argmax(R2_adj)\n",
    "    \n",
    "    if R2adj_chosen > R2adj_max:\n",
    "        R2adj_max = R2adj_chosen\n",
    "        ind_max = idx_chosen\n",
    "        \n",
    "        H = np.concatenate((H, all_candidates[:,ind_max].reshape(n,1)), axis = 1)\n",
    "        \n",
    "        all_candidates = np.delete(all_candidates,ind_max,1)\n",
    "        print('-------------------------------------------------')\n",
    "        print('Feature chosen: ', features[ind_max][1], '(index :', features[ind_max][0], ')')\n",
    "        idx_features.append(features[ind_max][0])\n",
    "        del(features[ind_max])\n",
    "        \n",
    "        del(X)\n",
    "        \n",
    "    else:\n",
    "        break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 asjusted values:\n",
      "0.123498102139\n",
      "0.158127051218\n",
      "0.183285452779\n",
      "0.19737862558\n",
      "0.204845050856\n",
      "0.212458380282\n",
      "0.221835080472\n",
      "0.22963272572\n",
      "0.234367607585\n",
      "0.237448089064\n",
      "0.239839917382\n",
      "0.241052424021\n",
      "0.242204099894\n",
      "0.243490389003\n",
      "0.243684846279\n",
      "0.244154585661\n",
      "0.244186288257\n",
      "0.244191908959\n",
      "0.244195224799\n",
      "0.24419603504\n",
      "0.244196344677\n",
      "-------------------------------------------------------\n",
      "Number of features chosen: 21\n",
      "\n",
      "\n",
      "Indices of features chosen:  [1, 13, 4, 11, 7, 2, 16, 10, 19, 12, 23, 8, 5, 26, 22, 21, 0, 18, 6, 3, 28]\n"
     ]
    }
   ],
   "source": [
    "results_r2_stepwise(best_R2adj[:len(best_R2adj)-1], idx_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) NC: Use of the probability of the 2 events (R2 Tjur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Realloc FEATURES\n",
    "features = []\n",
    "for i in range(len(all_features)):\n",
    "    features.append((i,all_features[i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Start of STEP-WISE algorithm \n",
    "all_candidates = input_data\n",
    "\n",
    "n = all_candidates.shape[0] #needed for the R^2 adjusted\n",
    "num = all_candidates.shape[1]\n",
    "H = np.ones((n,1)) #offset\n",
    "\n",
    "#Initialization only with offsets (lack of info)\n",
    "X = H\n",
    "k = 0 #needed for the R^2 adjusted\n",
    "\n",
    "w0, loss = least_squares(Y,X) \n",
    "y = predict_labels(w0, X)\n",
    "ind_back, ind_sig = idx_2labels(y, [0,1])\n",
    "\n",
    "y_ = X.dot(w0)\n",
    "R2 = 0\n",
    "R2adj_0 = R2 - (k/(n-k-1)*(1-R2))\n",
    "\n",
    "#fix the R2adj_max\n",
    "R2adj_max = R2adj_0\n",
    "ind_max = 0  # this index will show us which is the best feature chosen\n",
    "del(X)\n",
    "idx_features = []\n",
    "best_R2adj = []\n",
    "\n",
    "for j in range(num):\n",
    "    R2_adj = []\n",
    "    for i in range(all_candidates.shape[1]):\n",
    "        \n",
    "        X = np.concatenate((H,all_candidates[:,i].reshape(n,1)), axis=1)\n",
    "        ws , loss = least_squares(Y,X)\n",
    "        k = len(ws) -1 # k is the number of regressor I use -> -1 because I don't consider the offset\n",
    "        \n",
    "        y = predict_labels(ws,X)          \n",
    "        ind_back, ind_sig = idx_2labels(y, [0,1])\n",
    "        \n",
    "        if len(ind_sig) == 0 or len(ind_back) ==0:\n",
    "            print('No signal detected')\n",
    "            R2_adj.append(0)\n",
    "            \n",
    "        else: \n",
    "            \n",
    "            y_ = X.dot(ws)\n",
    "\n",
    "            R2 = np.abs((np.mean(y_[ind_sig]) - np.mean(y_[ind_back])))\n",
    "            R2_adj.append(R2 - (k/(n-k-1)*(1-R2)))\n",
    "            \n",
    "        \n",
    "    R2adj_chosen = np.max(R2_adj)\n",
    "    best_R2adj.append(R2adj_chosen)\n",
    "    idx_chosen = np.argmax(R2_adj)\n",
    "\n",
    "    if R2adj_chosen > R2adj_max:\n",
    "        R2adj_max = R2adj_chosen\n",
    "        ind_max = idx_chosen\n",
    "\n",
    "        #idx_features.append(np.where(all_candidates[:,ind_max] == input_data))\n",
    "        H = np.concatenate((H, all_candidates[:,ind_max].reshape(n,1)), axis = 1)\n",
    "\n",
    "        all_candidates = np.delete(all_candidates,ind_max,1)\n",
    "        print('-------------------------------------------------')\n",
    "        print('Feature chosen: ', features[ind_max][1], '(index :', features[ind_max][0], ')')\n",
    "        idx_features.append(features[ind_max][0])\n",
    "        del(features[ind_max])\n",
    "\n",
    "        del(X)\n",
    "\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results_r2_stepwise(best_R2adj[:len(best_R2adj)-1], idx_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3) NC: Use of the likelihood (McFadden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Realloc FEATURES\n",
    "features = []\n",
    "for i in range(len(all_features)):\n",
    "    features.append((i,all_features[i]))\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------\n",
      "Feature chosen:  DER_mass_transverse_met_lep (index : 1 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  DER_met_phi_centrality (index : 11 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  DER_sum_pt (index : 9 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  DER_mass_vis (index : 2 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  PRI_lep_phi (index : 18 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  PRI_jet_subleading_phi (index : 28 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  PRI_jet_leading_eta (index : 24 )\n"
     ]
    }
   ],
   "source": [
    "# Start of STEP-WISE algorithm \n",
    "all_candidates = input_data\n",
    "\n",
    "n = all_candidates.shape[0] #needed for the R^2 adjusted\n",
    "num = all_candidates.shape[1]\n",
    "H = np.ones((n,1)) #offset\n",
    "\n",
    "#Initialization only with offsets (lack of info)\n",
    "X = H\n",
    "k = 0 #needed for the R^2 adjusted\n",
    "\n",
    "w0, loss = least_squares(Y,X)  # The loss cannot be used as a measure for the feature selection because it's a \n",
    "y = predict_labels(w0, X)\n",
    "loglike0 = compute_loglikelihood_reg(y,X,w0)#np.sum(np.log(1+np.exp(X.dot(w0))) - y*(X.dot(w0)))\n",
    "\n",
    "R2 = 0        # For the definition of McFadden 1-1 = 0\n",
    "R2adj_0 = 0\n",
    "\n",
    "#fix the R2adj_max\n",
    "\n",
    "R2adj_max = R2adj_0\n",
    "ind_max = 0  # this index will show us which is the best feature chosen\n",
    "del(X)\n",
    "idx_features = []\n",
    "best_R2adj = []\n",
    "\n",
    "for j in range(num):\n",
    "    R2_adj = []\n",
    "    for i in range(all_candidates.shape[1]):\n",
    "        \n",
    "        X = np.concatenate((H,all_candidates[:,i].reshape(n,1)), axis=1)\n",
    "        ws , loss = least_squares(Y,X)\n",
    "        k = len(ws) -1 # k is the number of regressor I use -> -1 because I don't consider the offset\n",
    "        \n",
    "        y = predict_labels(ws,X)   \n",
    "        \n",
    "        loglike = compute_loglikelihood_reg(y,X,ws) #np.sum(np.log(1+np.exp(X.dot(ws))) - y*(X.dot(ws)))\n",
    "        \n",
    "        R2 = 1-(loglike/loglike0)\n",
    "        R2_adj.append(R2 - (k/(n-k-1)*(1-R2)))\n",
    "        \n",
    "    R2adj_chosen = np.max(R2_adj)\n",
    "    best_R2adj.append(R2adj_chosen)\n",
    "    idx_chosen = np.argmax(R2_adj)\n",
    "    \n",
    "    if R2adj_chosen > R2adj_max:\n",
    "        R2adj_max = R2adj_chosen\n",
    "        ind_max = idx_chosen\n",
    "        \n",
    "        H = np.concatenate((H, all_candidates[:,ind_max].reshape(n,1)), axis = 1)\n",
    "        \n",
    "        all_candidates = np.delete(all_candidates,ind_max,1)\n",
    "        print('-------------------------------------------------')\n",
    "        print('Feature chosen: ', features[ind_max][1], '(index :', features[ind_max][0], ')')\n",
    "        idx_features.append(features[ind_max][0])\n",
    "        del(features[ind_max])\n",
    "        \n",
    "        del(X)\n",
    "        \n",
    "    else:\n",
    "        break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 asjusted values:\n",
      "0.127199992503\n",
      "0.161949175423\n",
      "0.162775033532\n",
      "0.163218892521\n",
      "0.163296584222\n",
      "0.163326074239\n",
      "0.163331726027\n",
      "-------------------------------------------------------\n",
      "Number of features chosen: 7\n",
      "\n",
      "\n",
      "Indices of features chosen:  [1, 11, 9, 2, 18, 28, 24]\n"
     ]
    }
   ],
   "source": [
    "results_r2_stepwise(best_R2adj[:len(best_R2adj)-1], idx_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loglike/loglike0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using cross validation (C) (TO BE DELETED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am not sure that cross validation can be used we don't have to estimate any hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) (C): R2 with likelihood (McFadden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from split_data import split_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Realloc FEATURES\n",
    "features = []\n",
    "for i in range(len(all_features)):\n",
    "    features.append((i,all_features[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------\n",
      "Feature chosen:  DER_mass_transverse_met_lep (index : 1 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  DER_met_phi_centrality (index : 11 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  DER_sum_pt (index : 9 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  PRI_jet_all_pt (index : 29 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  PRI_met (index : 19 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  DER_pt_h (index : 3 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  DER_lep_eta_centrality (index : 12 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  DER_mass_MMC (index : 0 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  DER_deltar_tau_lep (index : 7 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  DER_pt_ratio_lep_tau (index : 10 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  DER_mass_vis (index : 2 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  PRI_lep_pt (index : 16 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  PRI_jet_leading_pt (index : 23 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  PRI_met_sumet (index : 21 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  PRI_tau_phi (index : 15 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  PRI_tau_pt (index : 13 )\n"
     ]
    }
   ],
   "source": [
    "# Start of STEP-WISE algorithm \n",
    "all_candidates = input_data\n",
    "\n",
    "n = all_candidates.shape[0] #needed for the R^2 adjusted\n",
    "num = all_candidates.shape[1]\n",
    "H = np.ones((n,1)) #offset\n",
    "\n",
    "#Initialization only with offsets (lack of info)\n",
    "X = H\n",
    "k = 0 #needed for the R^2 adjusted\n",
    "\n",
    "w0, loss = least_squares(Y,X)  # The loss cannot be used as a measure for the feature selection because it's a \n",
    "y = predict_labels(w0, X)\n",
    "loglike0 = np.sum(np.log(1+np.exp(X.dot(w0))) - y*(X.dot(w0)))\n",
    "\n",
    "R2 = 0   # For the definition of McFadden 1-1 = 0\n",
    "R2adj_0 = 0\n",
    "\n",
    "#fix the R2adj_max\n",
    "\n",
    "R2adj_max = R2adj_0\n",
    "ind_max = 0  # this index will show us which is the best feature chosen\n",
    "del(X)\n",
    "idx_features = []\n",
    "best_R2adj = []\n",
    "\n",
    "# parameters for cross validation\n",
    "arg_ls = dict()\n",
    "arg_ls['method'] = 'ls'\n",
    "arg_ls['loss'] = 'rmse'\n",
    "arg_ls['k_fold'] = 10\n",
    "\n",
    "\n",
    "for j in range(num):\n",
    "    R2_adj = []\n",
    "    for i in range(all_candidates.shape[1]):\n",
    "        \n",
    "        X = np.concatenate((H,all_candidates[:,i].reshape(n,1)), axis=1)\n",
    "        \n",
    "        # CROSS-VALIDATION\n",
    "        \n",
    "        w_tr_tot, loss_tr_tot, loss_te_tot = cross_validation(Y, X, arg_ls)\n",
    "        \n",
    "        ws = w_tr_tot[np.argmin(loss_te_tot)]\n",
    "        \n",
    "        k = len(ws) -1 # k is the number of regressor I use -> -1 because I don't consider the offset\n",
    "        \n",
    "        y = predict_labels(ws,X)   \n",
    "        \n",
    "        loglike = np.sum(np.log(1+np.exp(X.dot(ws))) - y*(X.dot(ws)))\n",
    "        \n",
    "        R2 = 1-(loglike/loglike0)\n",
    "        R2_adj.append(R2 - (k/(n-k-1)*(1-R2)))\n",
    "        \n",
    "    R2adj_chosen = np.max(R2_adj)\n",
    "    best_R2adj.append(R2adj_chosen)\n",
    "    idx_chosen = np.argmax(R2_adj)\n",
    "    \n",
    "    if R2adj_chosen > R2adj_max:\n",
    "        R2adj_max = R2adj_chosen\n",
    "        ind_max = idx_chosen\n",
    "        \n",
    "        H = np.concatenate((H, all_candidates[:,ind_max].reshape(n,1)), axis = 1)\n",
    "        \n",
    "        all_candidates = np.delete(all_candidates,ind_max,1)\n",
    "        print('-------------------------------------------------')\n",
    "        print('Feature chosen: ', features[ind_max][1], '(index :', features[ind_max][0], ')')\n",
    "        idx_features.append(features[ind_max][0])\n",
    "        del(features[ind_max])\n",
    "        \n",
    "        del(X)\n",
    "        \n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 asjusted values:\n",
      "0.127029003781\n",
      "0.162219139573\n",
      "0.163016309637\n",
      "0.16354554708\n",
      "0.167617483869\n",
      "0.172882697354\n",
      "0.174062939737\n",
      "0.174659663743\n",
      "0.175157077078\n",
      "0.176255853643\n",
      "0.177589693328\n",
      "0.17903001667\n",
      "0.180289605671\n",
      "0.180653688622\n",
      "0.180673303474\n",
      "0.18068436144\n",
      "-------------------------------------------------------\n",
      "Number of features chosen: 16\n",
      "\n",
      "\n",
      "Indices of features chosen:  [1, 11, 9, 29, 19, 3, 12, 0, 7, 10, 2, 16, 23, 21, 15, 13]\n"
     ]
    }
   ],
   "source": [
    "results_r2_stepwise(best_R2adj[:len(best_R2adj)-1], idx_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# B) Ridge regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I used only lambda as hyperparameter because I am not building a polynomial model. But we can add different features transformation (square or log or power), so maybe we can test the polynomial after the best features are selected "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## No cross validation (NC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set lambda\n",
    "lambda_ = 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) (NC) Using the loss from ridge regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Realloc FEATURES\n",
    "features = []\n",
    "for i in range(len(all_features)):\n",
    "    features.append((i,all_features[i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------\n",
      "Feature chosen:  DER_mass_transverse_met_lep (index : 1 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  PRI_tau_pt (index : 13 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  DER_deltaeta_jet_jet (index : 4 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  DER_met_phi_centrality (index : 11 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  DER_deltar_tau_lep (index : 7 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  DER_lep_eta_centrality (index : 12 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  PRI_met (index : 19 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  DER_mass_vis (index : 2 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  DER_mass_jet_jet (index : 5 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  PRI_jet_subleading_pt (index : 26 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  DER_pt_tot (index : 8 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  DER_pt_h (index : 3 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  PRI_jet_num (index : 22 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  PRI_lep_phi (index : 18 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  PRI_tau_phi (index : 15 )\n"
     ]
    }
   ],
   "source": [
    "# Start of STEP-WISE algorithm \n",
    "all_candidates = input_data\n",
    "\n",
    "n = all_candidates.shape[0] #needed for the R^2 adjusted\n",
    "num = all_candidates.shape[1]\n",
    "H = np.ones((n,1)) #offset\n",
    "\n",
    "#Initialization only with offsets (lack of info)\n",
    "X = H\n",
    "k = 0 #needed for the R^2 adjusted\n",
    "\n",
    "w0, loss = ridge_regression(Y,X,0)  # start with lambda = 0  \n",
    "y = predict_labels(w0, X)\n",
    "\n",
    "sse = loss*2*n\n",
    "sst = np.sum((Y - Y.mean())**2)  #lack of information\n",
    "R2 = np.abs((sst-sse)/sst)\n",
    "R2adj_0 = R2 - (k/(n-k-1)*(1-R2))\n",
    "\n",
    "#fix the R2adj_max\n",
    "\n",
    "R2adj_max = R2adj_0\n",
    "ind_max = 0  # this index will show us which is the best feature chosen\n",
    "del(X)\n",
    "idx_features = []\n",
    "best_R2adj = []\n",
    "\n",
    "for j in range(num):\n",
    "    R2_adj = []\n",
    "    for i in range(all_candidates.shape[1]):\n",
    "        \n",
    "        X = np.concatenate((H,all_candidates[:,i].reshape(n,1)), axis=1)\n",
    "        \n",
    "        ws, loss = ridge_regression(Y,X,lambda_)\n",
    "        k = len(ws) -1 # k is the number of regressor I use -> -1 because I don't consider the offset\n",
    "        \n",
    "        SSE = loss*2*n\n",
    "        SST = np.sum((Y- Y.mean())**2)   # it has no sense\n",
    "        R2 = np.abs((SST-SSE)/SST)\n",
    "        R2_adj.append(R2 - (k/(n-k-1)*(1-R2)))\n",
    "        \n",
    "    R2adj_chosen = np.max(R2_adj)\n",
    "    best_R2adj.append(R2adj_chosen)\n",
    "    idx_chosen = np.argmax(R2_adj)\n",
    "    \n",
    "    if R2adj_chosen > R2adj_max:\n",
    "        R2adj_max = R2adj_chosen\n",
    "        ind_max = idx_chosen\n",
    "        \n",
    "        H = np.concatenate((H, all_candidates[:,ind_max].reshape(n,1)), axis = 1)\n",
    "        \n",
    "        all_candidates = np.delete(all_candidates,ind_max,1)\n",
    "        print('-------------------------------------------------')\n",
    "        print('Feature chosen: ', features[ind_max][1], '(index :', features[ind_max][0], ')')\n",
    "        idx_features.append(features[ind_max][0])\n",
    "        del(features[ind_max])\n",
    "        \n",
    "        del(X)\n",
    "        \n",
    "    else:\n",
    "        break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 asjusted values:\n",
      "0.0590175831678\n",
      "0.0919564321754\n",
      "0.115305280064\n",
      "0.131172460715\n",
      "0.137081038671\n",
      "0.14163931635\n",
      "0.143708108081\n",
      "0.145592367705\n",
      "0.146688011854\n",
      "0.148345611287\n",
      "0.148987515541\n",
      "0.149696003179\n",
      "0.14984311946\n",
      "0.149851916892\n",
      "0.149853409866\n",
      "-------------------------------------------------------\n",
      "Number of features chosen: 15\n",
      "\n",
      "\n",
      "Indices of features chosen:  [1, 13, 4, 11, 7, 12, 19, 2, 5, 26, 8, 3, 22, 18, 15]\n"
     ]
    }
   ],
   "source": [
    "results_r2_stepwise(best_R2adj[:len(best_R2adj)-1], idx_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) (NC) Use of the probability of the 2 events (R2 Tjur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Realloc FEATURES\n",
    "features = []\n",
    "for i in range(len(all_features)):\n",
    "    features.append((i,all_features[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Start of STEP-WISE algorithm \n",
    "all_candidates = input_data\n",
    "\n",
    "n = all_candidates.shape[0] #needed for the R^2 adjusted\n",
    "num = all_candidates.shape[1]\n",
    "H = np.ones((n,1)) #offset\n",
    "\n",
    "#Initialization only with offsets (lack of info)\n",
    "X = H\n",
    "k = 0 #needed for the R^2 adjusted\n",
    "\n",
    "w0, loss = ridge_regression(Y,X,0)  \n",
    "y = predict_labels(w0, X)\n",
    "ind_back, ind_sig = idx_2labels(y, [0,1])\n",
    "\n",
    "y_ = X.dot(w0)\n",
    "R2 = 0\n",
    "R2adj_0 = R2 - (k/(n-k-1)*(1-R2))\n",
    "\n",
    "#fix the R2adj_max\n",
    "R2adj_max = R2adj_0\n",
    "ind_max = 0  # this index will show us which is the best feature chosen\n",
    "del(X)\n",
    "idx_features = []\n",
    "best_R2adj = []\n",
    "\n",
    "for j in range(num):\n",
    "    R2_adj = []\n",
    "    for i in range(all_candidates.shape[1]):\n",
    "        \n",
    "        X = np.concatenate((H,all_candidates[:,i].reshape(n,1)), axis=1)\n",
    "        ws, loss = ridge_regression(Y,X,lambda_)\n",
    "        \n",
    "        k = len(ws) -1 # k is the number of regressor I use -> -1 because I don't consider the offset\n",
    "        \n",
    "        y = predict_labels(ws,X)          \n",
    "        ind_back, ind_sig = idx_2labels(y, [-1,1])\n",
    "        \n",
    "        if len(ind_sig) == 0 or len(ind_back) ==0:\n",
    "            print('No signal detected')\n",
    "            R2_adj.append(0)\n",
    "            \n",
    "        else: \n",
    "            \n",
    "            y_ = X.dot(ws)\n",
    "\n",
    "            R2 = np.abs((np.mean(y_[ind_sig]) - np.mean(y_[ind_back])))\n",
    "            R2_adj.append(R2 - (k/(n-k-1)*(1-R2)))\n",
    "            \n",
    "        \n",
    "    R2adj_chosen = np.max(R2_adj)\n",
    "    best_R2adj.append(R2adj_chosen)\n",
    "    idx_chosen = np.argmax(R2_adj)\n",
    "\n",
    "    if R2adj_chosen > R2adj_max:\n",
    "        R2adj_max = R2adj_chosen\n",
    "        ind_max = idx_chosen\n",
    "\n",
    "        #idx_features.append(np.where(all_candidates[:,ind_max] == input_data))\n",
    "        H = np.concatenate((H, all_candidates[:,ind_max].reshape(n,1)), axis = 1)\n",
    "\n",
    "        all_candidates = np.delete(all_candidates,ind_max,1)\n",
    "        print('-------------------------------------------------')\n",
    "        print('Feature chosen: ', features[ind_max][1], '(index :', features[ind_max][0], ')')\n",
    "        idx_features.append(features[ind_max][0])\n",
    "        del(features[ind_max])\n",
    "\n",
    "        del(X)\n",
    "\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results_r2_stepwise(best_R2adj[:len(best_R2adj)-1], idx_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) (NC) Use of the likelihood (McFadden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Realloc FEATURES\n",
    "features = []\n",
    "for i in range(len(all_features)):\n",
    "    features.append((i,all_features[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------\n",
      "Feature chosen:  DER_mass_transverse_met_lep (index : 1 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  DER_met_phi_centrality (index : 11 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  DER_sum_pt (index : 9 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  DER_mass_vis (index : 2 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  PRI_lep_phi (index : 18 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  PRI_jet_subleading_phi (index : 28 )\n",
      "-------------------------------------------------\n",
      "Feature chosen:  PRI_jet_leading_eta (index : 24 )\n"
     ]
    }
   ],
   "source": [
    "# Start of STEP-WISE algorithm \n",
    "all_candidates = input_data\n",
    "\n",
    "n = all_candidates.shape[0] #needed for the R^2 adjusted\n",
    "num = all_candidates.shape[1]\n",
    "H = np.ones((n,1)) #offset\n",
    "\n",
    "#Initialization only with offsets (lack of info)\n",
    "X = H\n",
    "k = 0 #needed for the R^2 adjusted\n",
    "\n",
    "w0, loss = ridge_regression(Y,X,0)  # lambda set to 0 \n",
    "y = predict_labels(w0, X)\n",
    "loglike0 = compute_loglikelihood_reg(y,X,w0) #np.sum(np.log(1+np.exp(X.dot(w0))) - y*(X.dot(w0)))\n",
    "\n",
    "R2 = 0        # For the definition of McFadden 1-1 = 0\n",
    "R2adj_0 = 0\n",
    "\n",
    "#fix the R2adj_max\n",
    "\n",
    "R2adj_max = R2adj_0\n",
    "ind_max = 0  # this index will show us which is the best feature chosen\n",
    "del(X)\n",
    "idx_features = []\n",
    "best_R2adj = []\n",
    "\n",
    "for j in range(num):\n",
    "    R2_adj = []\n",
    "    for i in range(all_candidates.shape[1]):\n",
    "        \n",
    "        X = np.concatenate((H,all_candidates[:,i].reshape(n,1)), axis=1)\n",
    "        \n",
    "        ws, loss = ridge_regression(Y,X,lambda_)\n",
    "        \n",
    "        k = len(ws) -1 # k is the number of regressor I use -> -1 because I don't consider the offset\n",
    "        \n",
    "        y = predict_labels(ws,X)   \n",
    "        \n",
    "        loglike = compute_loglikelihood_reg(y,X,ws) #np.sum(np.log(1+np.exp(X.dot(ws))) - y*(X.dot(ws)))\n",
    "        \n",
    "        R2 = 1-(loglike/loglike0)\n",
    "        R2_adj.append(R2 - (k/(n-k-1)*(1-R2)))\n",
    "        \n",
    "    R2adj_chosen = np.max(R2_adj)\n",
    "    best_R2adj.append(R2adj_chosen)\n",
    "    idx_chosen = np.argmax(R2_adj)\n",
    "    \n",
    "    if R2adj_chosen > R2adj_max:\n",
    "        R2adj_max = R2adj_chosen\n",
    "        ind_max = idx_chosen\n",
    "        \n",
    "        H = np.concatenate((H, all_candidates[:,ind_max].reshape(n,1)), axis = 1)\n",
    "        \n",
    "        all_candidates = np.delete(all_candidates,ind_max,1)\n",
    "        print('-------------------------------------------------')\n",
    "        print('Feature chosen: ', features[ind_max][1], '(index :', features[ind_max][0], ')')\n",
    "        idx_features.append(features[ind_max][0])\n",
    "        del(features[ind_max])\n",
    "        \n",
    "        del(X)\n",
    "        \n",
    "    else:\n",
    "        break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 asjusted values:\n",
      "0.127200013384\n",
      "0.161949192879\n",
      "0.162775051476\n",
      "0.163218910102\n",
      "0.163296601788\n",
      "0.1633260918\n",
      "0.163331743587\n",
      "-------------------------------------------------------\n",
      "Number of features chosen: 7\n",
      "\n",
      "\n",
      "Indices of features chosen:  [1, 11, 9, 2, 18, 28, 24]\n"
     ]
    }
   ],
   "source": [
    "results_r2_stepwise(best_R2adj[:len(best_R2adj)-1], idx_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With cross validation (C) (it's needed in order to choose the best hyperparameter lambda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) (C) Using the loss of ridge regression as the error of R2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Realloc FEATURES\n",
    "features = []\n",
    "for i in range(len(all_features)):\n",
    "    features.append((i,all_features[i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2adj_0=  5.22003232182e-14\n",
      "SSE: 237291.57955  SST: 56311.660444  R2 3.21389775544 R2_adj:  [3.2139066111045418]\n",
      "SSE: 222166.97139  SST: 56311.660444  R2 2.94531025437 R2_adj:  [3.2139066111045418, 2.9453180356717179]\n",
      "SSE: 237278.684431  SST: 56311.660444  R2 3.21366875991 R2_adj:  [3.2139066111045418, 2.9453180356717179, 3.2136776146527186]\n",
      "SSE: 232862.58042  SST: 56311.660444  R2 3.13524620982 R2_adj:  [3.2139066111045418, 2.9453180356717179, 3.2136776146527186, 3.1352547508779942]\n",
      "SSE: 233286.64172  SST: 56311.660444  R2 3.14277682244 R2_adj:  [3.2139066111045418, 2.9453180356717179, 3.2136776146527186, 3.1352547508779942, 3.1427853936117813]\n",
      "SSE: 233563.179252  SST: 56311.660444  R2 3.14768766203 R2_adj:  [3.2139066111045418, 2.9453180356717179, 3.2136776146527186, 3.1352547508779942, 3.1427853936117813, 3.1476962528492343]\n",
      "SSE: 234083.688294  SST: 56311.660444  R2 3.15693102368 R2_adj:  [3.2139066111045418, 2.9453180356717179, 3.2136776146527186, 3.1352547508779942, 3.1427853936117813, 3.1476962528492343, 3.1569396514684209]\n",
      "SSE: 237284.407098  SST: 56311.660444  R2 3.21377038481 R2_adj:  [3.2139066111045418, 2.9453180356717179, 3.2136776146527186, 3.1352547508779942, 3.1427853936117813, 3.1476962528492343, 3.1569396514684209, 3.2137792399633129]\n",
      "SSE: 237275.312461  SST: 56311.660444  R2 3.21360887941 R2_adj:  [3.2139066111045418, 2.9453180356717179, 3.2136776146527186, 3.1352547508779942, 3.1427853936117813, 3.1476962528492343, 3.1569396514684209, 3.2137792399633129, 3.2136177339159024]\n",
      "SSE: 234499.80327  SST: 56311.660444  R2 3.16432052299 R2_adj:  [3.2139066111045418, 2.9453180356717179, 3.2136776146527186, 3.1352547508779942, 3.1427853936117813, 3.1476962528492343, 3.1569396514684209, 3.2137792399633129, 3.2136177339159024, 3.1643291803372549]\n",
      "SSE: 232727.90769  SST: 56311.660444  R2 3.13285464955 R2_adj:  [3.2139066111045418, 2.9453180356717179, 3.2136776146527186, 3.1352547508779942, 3.1427853936117813, 3.1476962528492343, 3.1569396514684209, 3.2137792399633129, 3.2136177339159024, 3.1643291803372549, 3.1328631810319014]\n",
      "SSE: 228371.559773  SST: 56311.660444  R2 3.05549326679 R2_adj:  [3.2139066111045418, 2.9453180356717179, 3.2136776146527186, 3.1352547508779942, 3.1427853936117813, 3.1476962528492343, 3.1569396514684209, 3.2137792399633129, 3.2136177339159024, 3.1643291803372549, 3.1328631810319014, 3.0555014888334062]\n",
      "SSE: 233756.930616  SST: 56311.660444  R2 3.15112835908 R2_adj:  [3.2139066111045418, 2.9453180356717179, 3.2136776146527186, 3.1352547508779942, 3.1427853936117813, 3.1476962528492343, 3.1569396514684209, 3.2137792399633129, 3.2136177339159024, 3.1643291803372549, 3.1328631810319014, 3.0555014888334062, 3.1511369636591851]\n",
      "SSE: 230643.314117  SST: 56311.660444  R2 3.0958357878 R2_adj:  [3.2139066111045418, 2.9453180356717179, 3.2136776146527186, 3.1352547508779942, 3.1427853936117813, 3.1476962528492343, 3.1569396514684209, 3.2137792399633129, 3.2136177339159024, 3.1643291803372549, 3.1328631810319014, 3.0555014888334062, 3.1511369636591851, 3.0958441712067239]\n",
      "SSE: 237302.823932  SST: 56311.660444  R2 3.21409743668 R2_adj:  [3.2139066111045418, 2.9453180356717179, 3.2136776146527186, 3.1352547508779942, 3.1427853936117813, 3.1476962528492343, 3.1569396514684209, 3.2137792399633129, 3.2136177339159024, 3.1643291803372549, 3.1328631810319014, 3.0555014888334062, 3.1511369636591851, 3.0958441712067239, 3.2141062931440474]\n",
      "SSE: 237299.491792  SST: 56311.660444  R2 3.21403826349 R2_adj:  [3.2139066111045418, 2.9453180356717179, 3.2136776146527186, 3.1352547508779942, 3.1427853936117813, 3.1476962528492343, 3.1569396514684209, 3.2137792399633129, 3.2136177339159024, 3.1643291803372549, 3.1328631810319014, 3.0555014888334062, 3.1511369636591851, 3.0958441712067239, 3.2141062931440474, 3.2140471197146332]\n",
      "SSE: 237180.919802  SST: 56311.660444  R2 3.21193262518 R2_adj:  [3.2139066111045418, 2.9453180356717179, 3.2136776146527186, 3.1352547508779942, 3.1427853936117813, 3.1476962528492343, 3.1569396514684209, 3.2137792399633129, 3.2136177339159024, 3.1643291803372549, 3.1328631810319014, 3.0555014888334062, 3.1511369636591851, 3.0958441712067239, 3.2141062931440474, 3.2140471197146332, 3.2119414729836446]\n",
      "SSE: 237302.0406  SST: 56311.660444  R2 3.21408352602 R2_adj:  [3.2139066111045418, 2.9453180356717179, 3.2136776146527186, 3.1352547508779942, 3.1427853936117813, 3.1476962528492343, 3.1569396514684209, 3.2137792399633129, 3.2136177339159024, 3.1643291803372549, 3.1328631810319014, 3.0555014888334062, 3.1511369636591851, 3.0958441712067239, 3.2141062931440474, 3.2140471197146332, 3.2119414729836446, 3.2140923824249508]\n",
      "SSE: 237301.01402  SST: 56311.660444  R2 3.2140652957 R2_adj:  [3.2139066111045418, 2.9453180356717179, 3.2136776146527186, 3.1352547508779942, 3.1427853936117813, 3.1476962528492343, 3.1569396514684209, 3.2137792399633129, 3.2136177339159024, 3.1643291803372549, 3.1328631810319014, 3.0555014888334062, 3.1511369636591851, 3.0958441712067239, 3.2141062931440474, 3.2140471197146332, 3.2119414729836446, 3.2140923824249508, 3.2140741520292671]\n",
      "SSE: 237242.302955  SST: 56311.660444  R2 3.21302268632 R2_adj:  [3.2139066111045418, 2.9453180356717179, 3.2136776146527186, 3.1352547508779942, 3.1427853936117813, 3.1476962528492343, 3.1569396514684209, 3.2137792399633129, 3.2136177339159024, 3.1643291803372549, 3.1328631810319014, 3.0555014888334062, 3.1511369636591851, 3.0958441712067239, 3.2141062931440474, 3.2140471197146332, 3.2119414729836446, 3.2140923824249508, 3.2140741520292671, 3.2130315384843251]\n",
      "SSE: 237295.645452  SST: 56311.660444  R2 3.21396995899 R2_adj:  [3.2139066111045418, 2.9453180356717179, 3.2136776146527186, 3.1352547508779942, 3.1427853936117813, 3.1476962528492343, 3.1569396514684209, 3.2137792399633129, 3.2136177339159024, 3.1643291803372549, 3.1328631810319014, 3.0555014888334062, 3.1511369636591851, 3.0958441712067239, 3.2141062931440474, 3.2140471197146332, 3.2119414729836446, 3.2140923824249508, 3.2140741520292671, 3.2130315384843251, 3.2139788149441491]\n",
      "SSE: 235113.100954  SST: 56311.660444  R2 3.17521165422 R2_adj:  [3.2139066111045418, 2.9453180356717179, 3.2136776146527186, 3.1352547508779942, 3.1427853936117813, 3.1476962528492343, 3.1569396514684209, 3.2137792399633129, 3.2136177339159024, 3.1643291803372549, 3.1328631810319014, 3.0555014888334062, 3.1511369636591851, 3.0958441712067239, 3.2141062931440474, 3.2140471197146332, 3.2119414729836446, 3.2140923824249508, 3.2140741520292671, 3.2130315384843251, 3.2139788149441491, 3.1752203551391895]\n",
      "SSE: 235176.227908  SST: 56311.660444  R2 3.17633268232 R2_adj:  [3.2139066111045418, 2.9453180356717179, 3.2136776146527186, 3.1352547508779942, 3.1427853936117813, 3.1476962528492343, 3.1569396514684209, 3.2137792399633129, 3.2136177339159024, 3.1643291803372549, 3.1328631810319014, 3.0555014888334062, 3.1511369636591851, 3.0958441712067239, 3.2141062931440474, 3.2140471197146332, 3.2119414729836446, 3.2140923824249508, 3.2140741520292671, 3.2130315384843251, 3.2139788149441491, 3.1752203551391895, 3.1763413877188031]\n",
      "SSE: 236985.635239  SST: 56311.660444  R2 3.20846470109 R2_adj:  [3.2139066111045418, 2.9453180356717179, 3.2136776146527186, 3.1352547508779942, 3.1427853936117813, 3.1476962528492343, 3.1569396514684209, 3.2137792399633129, 3.2136177339159024, 3.1643291803372549, 3.1328631810319014, 3.0555014888334062, 3.1511369636591851, 3.0958441712067239, 3.2141062931440474, 3.2140471197146332, 3.2119414729836446, 3.2140923824249508, 3.2140741520292671, 3.2130315384843251, 3.2139788149441491, 3.1752203551391895, 3.1763413877188031, 3.2084735350236708]\n",
      "SSE: 237302.410893  SST: 56311.660444  R2 3.2140901018 R2_adj:  [3.2139066111045418, 2.9453180356717179, 3.2136776146527186, 3.1352547508779942, 3.1427853936117813, 3.1476962528492343, 3.1569396514684209, 3.2137792399633129, 3.2136177339159024, 3.1643291803372549, 3.1328631810319014, 3.0555014888334062, 3.1511369636591851, 3.0958441712067239, 3.2141062931440474, 3.2140471197146332, 3.2119414729836446, 3.2140923824249508, 3.2140741520292671, 3.2130315384843251, 3.2139788149441491, 3.1752203551391895, 3.1763413877188031, 3.2084735350236708, 3.2140989582273543]\n",
      "SSE: 237301.964156  SST: 56311.660444  R2 3.21408216851 R2_adj:  [3.2139066111045418, 2.9453180356717179, 3.2136776146527186, 3.1352547508779942, 3.1427853936117813, 3.1476962528492343, 3.1569396514684209, 3.2137792399633129, 3.2136177339159024, 3.1643291803372549, 3.1328631810319014, 3.0555014888334062, 3.1511369636591851, 3.0958441712067239, 3.2141062931440474, 3.2140471197146332, 3.2119414729836446, 3.2140923824249508, 3.2140741520292671, 3.2130315384843251, 3.2139788149441491, 3.1752203551391895, 3.1763413877188031, 3.2084735350236708, 3.2140989582273543, 3.2140910249122383]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SSE: 237279.890767  SST: 56311.660444  R2 3.21369018239 R2_adj:  [3.2139066111045418, 2.9453180356717179, 3.2136776146527186, 3.1352547508779942, 3.1427853936117813, 3.1476962528492343, 3.1569396514684209, 3.2137792399633129, 3.2136177339159024, 3.1643291803372549, 3.1328631810319014, 3.0555014888334062, 3.1511369636591851, 3.0958441712067239, 3.2141062931440474, 3.2140471197146332, 3.2119414729836446, 3.2140923824249508, 3.2140741520292671, 3.2130315384843251, 3.2139788149441491, 3.1752203551391895, 3.1763413877188031, 3.2084735350236708, 3.2140989582273543, 3.2140910249122383, 3.2136990372255343]\n",
      "SSE: 237302.27354  SST: 56311.660444  R2 3.21408766264 R2_adj:  [3.2139066111045418, 2.9453180356717179, 3.2136776146527186, 3.1352547508779942, 3.1427853936117813, 3.1476962528492343, 3.1569396514684209, 3.2137792399633129, 3.2136177339159024, 3.1643291803372549, 3.1328631810319014, 3.0555014888334062, 3.1511369636591851, 3.0958441712067239, 3.2141062931440474, 3.2140471197146332, 3.2119414729836446, 3.2140923824249508, 3.2140741520292671, 3.2130315384843251, 3.2139788149441491, 3.1752203551391895, 3.1763413877188031, 3.2084735350236708, 3.2140989582273543, 3.2140910249122383, 3.2136990372255343, 3.2140965190633826]\n",
      "SSE: 237301.240753  SST: 56311.660444  R2 3.2140693221 R2_adj:  [3.2139066111045418, 2.9453180356717179, 3.2136776146527186, 3.1352547508779942, 3.1427853936117813, 3.1476962528492343, 3.1569396514684209, 3.2137792399633129, 3.2136177339159024, 3.1643291803372549, 3.1328631810319014, 3.0555014888334062, 3.1511369636591851, 3.0958441712067239, 3.2141062931440474, 3.2140471197146332, 3.2119414729836446, 3.2140923824249508, 3.2140741520292671, 3.2130315384843251, 3.2139788149441491, 3.1752203551391895, 3.1763413877188031, 3.2084735350236708, 3.2140989582273543, 3.2140910249122383, 3.2136990372255343, 3.2140965190633826, 3.2140781784451735]\n",
      "SSE: 235152.67367  SST: 56311.660444  R2 3.17591439882 R2_adj:  [3.2139066111045418, 2.9453180356717179, 3.2136776146527186, 3.1352547508779942, 3.1427853936117813, 3.1476962528492343, 3.1569396514684209, 3.2137792399633129, 3.2136177339159024, 3.1643291803372549, 3.1328631810319014, 3.0555014888334062, 3.1511369636591851, 3.0958441712067239, 3.2141062931440474, 3.2140471197146332, 3.2119414729836446, 3.2140923824249508, 3.2140741520292671, 3.2130315384843251, 3.2139788149441491, 3.1752203551391895, 3.1763413877188031, 3.2084735350236708, 3.2140989582273543, 3.2140910249122383, 3.2136990372255343, 3.2140965190633826, 3.2140781784451735, 3.175923102548011]\n",
      "-------------------------------------------------\n",
      "Feature chosen:  PRI_tau_eta (index : 14 )\n",
      "SSE: 237293.098177  SST: 56311.660444  R2 3.21392472368 R2_adj:  [3.2139424352927648]\n",
      "SSE: 222168.558912  SST: 56311.660444  R2 2.94533844607 R2_adj:  [3.2139424352927648, 2.9453540089653028]\n",
      "SSE: 237280.207254  SST: 56311.660444  R2 3.21369580266 R2_adj:  [3.2139424352927648, 2.9453540089653028, 3.2137135124393912]\n",
      "SSE: 232864.061832  SST: 56311.660444  R2 3.1352725172 R2_adj:  [3.2139424352927648, 2.9453540089653028, 3.2137135124393912, 3.1352895995859744]\n",
      "SSE: 233288.315474  SST: 56311.660444  R2 3.14280654547 R2_adj:  [3.2139424352927648, 2.9453540089653028, 3.2137135124393912, 3.1352895995859744, 3.1428236881254494]\n",
      "SSE: 233564.916537  SST: 56311.660444  R2 3.14771851327 R2_adj:  [3.2139424352927648, 2.9453540089653028, 3.2137135124393912, 3.1352895995859744, 3.1428236881254494, 3.1477356952247733]\n",
      "SSE: 234085.291605  SST: 56311.660444  R2 3.15695949577 R2_adj:  [3.2139424352927648, 2.9453540089653028, 3.2137135124393912, 3.1352895995859744, 3.1428236881254494, 3.1477356952247733, 3.1569767516542502]\n",
      "SSE: 237285.928186  SST: 56311.660444  R2 3.21379739675 R2_adj:  [3.2139424352927648, 2.9453540089653028, 3.2137135124393912, 3.1352895995859744, 3.1428236881254494, 3.1477356952247733, 3.1569767516542502, 3.2138151073415058]\n",
      "SSE: 237276.837853  SST: 56311.660444  R2 3.2136359678 R2_adj:  [3.2139424352927648, 2.9453540089653028, 3.2137135124393912, 3.1352895995859744, 3.1428236881254494, 3.1477356952247733, 3.1569767516542502, 3.2138151073415058, 3.2136536771010751]\n",
      "SSE: 234501.41772  SST: 56311.660444  R2 3.16434919289 R2_adj:  [3.2139424352927648, 2.9453540089653028, 3.2137135124393912, 3.1352895995859744, 3.1428236881254494, 3.1477356952247733, 3.1569767516542502, 3.2138151073415058, 3.2136536771010751, 3.1643665078920646]\n",
      "SSE: 232729.338422  SST: 56311.660444  R2 3.13288005694 R2_adj:  [3.2139424352927648, 2.9453540089653028, 3.2137135124393912, 3.1352895995859744, 3.1428236881254494, 3.1477356952247733, 3.1569767516542502, 3.2138151073415058, 3.2136536771010751, 3.1643665078920646, 3.1328971201825397]\n",
      "SSE: 228372.673165  SST: 56311.660444  R2 3.05551303876 R2_adj:  [3.2139424352927648, 2.9453540089653028, 3.2137135124393912, 3.1352895995859744, 3.1428236881254494, 3.1477356952247733, 3.1569767516542502, 3.2138151073415058, 3.2136536771010751, 3.1643665078920646, 3.1328971201825397, 3.0555294830601172]\n",
      "SSE: 233758.548736  SST: 56311.660444  R2 3.15115709416 R2_adj:  [3.2139424352927648, 2.9453540089653028, 3.2137135124393912, 3.1352895995859744, 3.1428236881254494, 3.1477356952247733, 3.1569767516542502, 3.2138151073415058, 3.2136536771010751, 3.1643665078920646, 3.1328971201825397, 3.0555294830601172, 3.1511743036216071]\n",
      "SSE: 230644.82024  SST: 56311.660444  R2 3.09586253399 R2_adj:  [3.2139424352927648, 2.9453540089653028, 3.2137135124393912, 3.1352895995859744, 3.1428236881254494, 3.1477356952247733, 3.1569767516542502, 3.2138151073415058, 3.2136536771010751, 3.1643665078920646, 3.1328971201825397, 3.0555294830601172, 3.1511743036216071, 3.0958793010960903]\n",
      "SSE: 237301.015638  SST: 56311.660444  R2 3.21406532443 R2_adj:  [3.2139424352927648, 2.9453540089653028, 3.2137135124393912, 3.1352895995859744, 3.1428236881254494, 3.1477356952247733, 3.1569767516542502, 3.2138151073415058, 3.2136536771010751, 3.1643665078920646, 3.1328971201825397, 3.0555294830601172, 3.1511743036216071, 3.0958793010960903, 3.214083037164909]\n",
      "SSE: 237182.418113  SST: 56311.660444  R2 3.21195923265 R2_adj:  [3.2139424352927648, 2.9453540089653028, 3.2137135124393912, 3.1352895995859744, 3.1428236881254494, 3.1477356952247733, 3.1569767516542502, 3.2138151073415058, 3.2136536771010751, 3.1643665078920646, 3.1328971201825397, 3.0555294830601172, 3.1511743036216071, 3.0958793010960903, 3.214083037164909, 3.2119769285380717]\n",
      "SSE: 237303.300734  SST: 56311.660444  R2 3.21410590387 R2_adj:  [3.2139424352927648, 2.9453540089653028, 3.2137135124393912, 3.1352895995859744, 3.1428236881254494, 3.1477356952247733, 3.1569767516542502, 3.2138151073415058, 3.2136536771010751, 3.1643665078920646, 3.1328971201825397, 3.0555294830601172, 3.1511743036216071, 3.0958793010960903, 3.214083037164909, 3.2119769285380717, 3.2141236169308138]\n",
      "SSE: 237302.533895  SST: 56311.660444  R2 3.21409228611 R2_adj:  [3.2139424352927648, 2.9453540089653028, 3.2137135124393912, 3.1352895995859744, 3.1428236881254494, 3.1477356952247733, 3.1569767516542502, 3.2138151073415058, 3.2136536771010751, 3.1643665078920646, 3.1328971201825397, 3.0555294830601172, 3.1511743036216071, 3.0958793010960903, 3.214083037164909, 3.2119769285380717, 3.2141236169308138, 3.2141099990571322]\n",
      "SSE: 237243.806158  SST: 56311.660444  R2 3.21304938066 R2_adj:  [3.2139424352927648, 2.9453540089653028, 3.2137135124393912, 3.1352895995859744, 3.1428236881254494, 3.1477356952247733, 3.1569767516542502, 3.2138151073415058, 3.2136536771010751, 3.1643665078920646, 3.1328971201825397, 3.0555294830601172, 3.1511743036216071, 3.0958793010960903, 3.214083037164909, 3.2119769285380717, 3.2141236169308138, 3.2141099990571322, 3.213067085271093]\n",
      "SSE: 237297.174622  SST: 56311.660444  R2 3.21399711447 R2_adj:  [3.2139424352927648, 2.9453540089653028, 3.2137135124393912, 3.1352895995859744, 3.1428236881254494, 3.1477356952247733, 3.1569767516542502, 3.2138151073415058, 3.2136536771010751, 3.1643665078920646, 3.1328971201825397, 3.0555294830601172, 3.1511743036216071, 3.0958793010960903, 3.214083037164909, 3.2119769285380717, 3.2141236169308138, 3.2141099990571322, 3.213067085271093, 3.2140148266580777]\n",
      "SSE: 235114.6791  SST: 56311.660444  R2 3.17523967943 R2_adj:  [3.2139424352927648, 2.9453540089653028, 3.2137135124393912, 3.1352895995859744, 3.1428236881254494, 3.1477356952247733, 3.1569767516542502, 3.2138151073415058, 3.2136536771010751, 3.1643665078920646, 3.1328971201825397, 3.0555294830601172, 3.1511743036216071, 3.0958793010960903, 3.214083037164909, 3.2119769285380717, 3.2141236169308138, 3.2141099990571322, 3.213067085271093, 3.2140148266580777, 3.1752570815513192]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SSE: 235177.600888  SST: 56311.660444  R2 3.17635706413 R2_adj:  [3.2139424352927648, 2.9453540089653028, 3.2137135124393912, 3.1352895995859744, 3.1428236881254494, 3.1477356952247733, 3.1569767516542502, 3.2138151073415058, 3.2136536771010751, 3.1643665078920646, 3.1328971201825397, 3.0555294830601172, 3.1511743036216071, 3.0958793010960903, 3.214083037164909, 3.2119769285380717, 3.2141236169308138, 3.2141099990571322, 3.213067085271093, 3.2140148266580777, 3.1752570815513192, 3.1763744751937701]\n",
      "SSE: 236987.20262  SST: 56311.660444  R2 3.20849253513 R2_adj:  [3.2139424352927648, 2.9453540089653028, 3.2137135124393912, 3.1352895995859744, 3.1428236881254494, 3.1477356952247733, 3.1569767516542502, 3.2138151073415058, 3.2136536771010751, 3.1643665078920646, 3.1328971201825397, 3.0555294830601172, 3.1511743036216071, 3.0958793010960903, 3.214083037164909, 3.2119769285380717, 3.2141236169308138, 3.2141099990571322, 3.213067085271093, 3.2140148266580777, 3.1752570815513192, 3.1763744751937701, 3.2085102032859445]\n",
      "SSE: 237303.871204  SST: 56311.660444  R2 3.21411603446 R2_adj:  [3.2139424352927648, 2.9453540089653028, 3.2137135124393912, 3.1352895995859744, 3.1428236881254494, 3.1477356952247733, 3.1569767516542502, 3.2138151073415058, 3.2136536771010751, 3.1643665078920646, 3.1328971201825397, 3.0555294830601172, 3.1511743036216071, 3.0958793010960903, 3.214083037164909, 3.2119769285380717, 3.2141236169308138, 3.2141099990571322, 3.213067085271093, 3.2140148266580777, 3.1752570815513192, 3.1763744751937701, 3.2085102032859445, 3.2141337475963878]\n",
      "SSE: 237303.488971  SST: 56311.660444  R2 3.21410924665 R2_adj:  [3.2139424352927648, 2.9453540089653028, 3.2137135124393912, 3.1352895995859744, 3.1428236881254494, 3.1477356952247733, 3.1569767516542502, 3.2138151073415058, 3.2136536771010751, 3.1643665078920646, 3.1328971201825397, 3.0555294830601172, 3.1511743036216071, 3.0958793010960903, 3.214083037164909, 3.2119769285380717, 3.2141236169308138, 3.2141099990571322, 3.213067085271093, 3.2140148266580777, 3.1752570815513192, 3.1763744751937701, 3.2085102032859445, 3.2141337475963878, 3.2141269597333073]\n",
      "SSE: 237281.389679  SST: 56311.660444  R2 3.21371680055 R2_adj:  [3.2139424352927648, 2.9453540089653028, 3.2137135124393912, 3.1352895995859744, 3.1428236881254494, 3.1477356952247733, 3.1569767516542502, 3.2138151073415058, 3.2136536771010751, 3.1643665078920646, 3.1328971201825397, 3.0555294830601172, 3.1511743036216071, 3.0958793010960903, 3.214083037164909, 3.2119769285380717, 3.2141236169308138, 3.2141099990571322, 3.213067085271093, 3.2140148266580777, 3.1752570815513192, 3.1763744751937701, 3.2085102032859445, 3.2141337475963878, 3.2141269597333073, 3.2137345104923174]\n",
      "SSE: 237303.820261  SST: 56311.660444  R2 3.21411512979 R2_adj:  [3.2139424352927648, 2.9453540089653028, 3.2137135124393912, 3.1352895995859744, 3.1428236881254494, 3.1477356952247733, 3.1569767516542502, 3.2138151073415058, 3.2136536771010751, 3.1643665078920646, 3.1328971201825397, 3.0555294830601172, 3.1511743036216071, 3.0958793010960903, 3.214083037164909, 3.2119769285380717, 3.2141236169308138, 3.2141099990571322, 3.213067085271093, 3.2140148266580777, 3.1752570815513192, 3.1763744751937701, 3.2085102032859445, 3.2141337475963878, 3.2141269597333073, 3.2137345104923174, 3.214132842921968]\n",
      "SSE: 237302.763016  SST: 56311.660444  R2 3.21409635491 R2_adj:  [3.2139424352927648, 2.9453540089653028, 3.2137135124393912, 3.1352895995859744, 3.1428236881254494, 3.1477356952247733, 3.1569767516542502, 3.2138151073415058, 3.2136536771010751, 3.1643665078920646, 3.1328971201825397, 3.0555294830601172, 3.1511743036216071, 3.0958793010960903, 3.214083037164909, 3.2119769285380717, 3.2141236169308138, 3.2141099990571322, 3.213067085271093, 3.2140148266580777, 3.1752570815513192, 3.1763744751937701, 3.2085102032859445, 3.2141337475963878, 3.2141269597333073, 3.2137345104923174, 3.214132842921968, 3.2141140678944708]\n",
      "SSE: 235154.242329  SST: 56311.660444  R2 3.17594225557 R2_adj:  [3.2139424352927648, 2.9453540089653028, 3.2137135124393912, 3.1352895995859744, 3.1428236881254494, 3.1477356952247733, 3.1569767516542502, 3.2138151073415058, 3.2136536771010751, 3.1643665078920646, 3.1328971201825397, 3.0555294830601172, 3.1511743036216071, 3.0958793010960903, 3.214083037164909, 3.2119769285380717, 3.2141236169308138, 3.2141099990571322, 3.213067085271093, 3.2140148266580777, 3.1752570815513192, 3.1763744751937701, 3.2085102032859445, 3.2141337475963878, 3.2141269597333073, 3.2137345104923174, 3.214132842921968, 3.2141140678944708, 3.1759596633168803]\n",
      "-------------------------------------------------\n",
      "Feature chosen:  PRI_jet_leading_eta (index : 24 )\n",
      "SSE: 237294.15427  SST: 56311.660444  R2 3.21394347811 R2_adj:  [3.2139700458569354]\n",
      "SSE: 222169.518613  SST: 56311.660444  R2 2.94535548874 R2_adj:  [3.2139700458569354, 2.9453788333770152]\n",
      "SSE: 237281.242087  SST: 56311.660444  R2 3.21371417954 R2_adj:  [3.2139700458569354, 2.9453788333770152, 3.2137407445396029]\n",
      "SSE: 232865.069872  SST: 56311.660444  R2 3.13529041829 R2_adj:  [3.2139700458569354, 2.9453788333770152, 3.2137407445396029, 3.1353160421843422]\n",
      "SSE: 233289.291598  SST: 56311.660444  R2 3.1428238798 R2_adj:  [3.2139700458569354, 2.9453788333770152, 3.2137407445396029, 3.1353160421843422, 3.1428495940939847]\n",
      "SSE: 233565.780661  SST: 56311.660444  R2 3.14773385867 R2_adj:  [3.2139700458569354, 2.9453788333770152, 3.2137407445396029, 3.1353160421843422, 3.1428495940939847, 3.1477596318845769]\n",
      "SSE: 234086.317948  SST: 56311.660444  R2 3.15697772189 R2_adj:  [3.2139700458569354, 2.9453788333770152, 3.2137407445396029, 3.1353160421843422, 3.1428495940939847, 3.1477596318845769, 3.1570036060331566]\n",
      "SSE: 237286.986586  SST: 56311.660444  R2 3.21381619215 R2_adj:  [3.2139700458569354, 2.9453788333770152, 3.2137407445396029, 3.1353160421843422, 3.1428495940939847, 3.1477596318845769, 3.1570036060331566, 3.2138427583655496]\n",
      "SSE: 237277.888804  SST: 56311.660444  R2 3.21365463091 R2_adj:  [3.2139700458569354, 2.9453788333770152, 3.2137407445396029, 3.1353160421843422, 3.1428495940939847, 3.1477596318845769, 3.1570036060331566, 3.2138427583655496, 3.213681195188784]\n",
      "SSE: 234502.396794  SST: 56311.660444  R2 3.16436657959 R2_adj:  [3.2139700458569354, 2.9453788333770152, 3.2137407445396029, 3.1353160421843422, 3.1428495940939847, 3.1477596318845769, 3.1570036060331566, 3.2138427583655496, 3.213681195188784, 3.1643925524092329]\n",
      "SSE: 232730.307913  SST: 56311.660444  R2 3.13289727347 R2_adj:  [3.2139700458569354, 2.9453788333770152, 3.2137407445396029, 3.1353160421843422, 3.1428495940939847, 3.1477596318845769, 3.1570036060331566, 3.2138427583655496, 3.213681195188784, 3.1643925524092329, 3.132922868644699]\n",
      "SSE: 228373.596512  SST: 56311.660444  R2 3.05552943585 R2_adj:  [3.2139700458569354, 2.9453788333770152, 3.2137407445396029, 3.1353160421843422, 3.1428495940939847, 3.1477596318845769, 3.1570036060331566, 3.2138427583655496, 3.213681195188784, 3.1643925524092329, 3.132922868644699, 3.0555541025982076]\n",
      "SSE: 233759.468762  SST: 56311.660444  R2 3.15117343227 R2_adj:  [3.2139700458569354, 2.9453788333770152, 3.2137407445396029, 3.1353160421843422, 3.1428495940939847, 3.1477596318845769, 3.1570036060331566, 3.2138427583655496, 3.213681195188784, 3.1643925524092329, 3.132922868644699, 3.0555541025982076, 3.1511992467632486]\n",
      "SSE: 230646.048982  SST: 56311.660444  R2 3.09588435439 R2_adj:  [3.2139700458569354, 2.9453788333770152, 3.2137407445396029, 3.1353160421843422, 3.1428495940939847, 3.1477596318845769, 3.1570036060331566, 3.2138427583655496, 3.213681195188784, 3.1643925524092329, 3.132922868644699, 3.0555541025982076, 3.1511992467632486, 3.0959095054070898]\n",
      "SSE: 237302.058631  SST: 56311.660444  R2 3.21408384622 R2_adj:  [3.2139700458569354, 2.9453788333770152, 3.2137407445396029, 3.1353160421843422, 3.1428495940939847, 3.1477596318845769, 3.1570036060331566, 3.2138427583655496, 3.213681195188784, 3.1643925524092329, 3.132922868644699, 3.0555541025982076, 3.1511992467632486, 3.0959095054070898, 3.214110415647514]\n",
      "SSE: 237183.448561  SST: 56311.660444  R2 3.21197753167 R2_adj:  [3.2139700458569354, 2.9453788333770152, 3.2137407445396029, 3.1353160421843422, 3.1428495940939847, 3.1477596318845769, 3.1570036060331566, 3.2138427583655496, 3.213681195188784, 3.1643925524092329, 3.132922868644699, 3.0555541025982076, 3.1511992467632486, 3.0959095054070898, 3.214110415647514, 3.2120040758204782]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SSE: 237304.36599  SST: 56311.660444  R2 3.21412482102 R2_adj:  [3.2139700458569354, 2.9453788333770152, 3.2137407445396029, 3.1353160421843422, 3.1428495940939847, 3.1477596318845769, 3.1570036060331566, 3.2138427583655496, 3.213681195188784, 3.1643925524092329, 3.132922868644699, 3.0555541025982076, 3.1511992467632486, 3.0959095054070898, 3.214110415647514, 3.2120040758204782, 3.2141513909444517]\n",
      "SSE: 237303.577353  SST: 56311.660444  R2 3.21411081616 R2_adj:  [3.2139700458569354, 2.9453788333770152, 3.2137407445396029, 3.1353160421843422, 3.1428495940939847, 3.1477596318845769, 3.1570036060331566, 3.2138427583655496, 3.213681195188784, 3.1643925524092329, 3.132922868644699, 3.0555541025982076, 3.1511992467632486, 3.0959095054070898, 3.214110415647514, 3.2120040758204782, 3.2141513909444517, 3.2141373859142748]\n",
      "SSE: 237244.862739  SST: 56311.660444  R2 3.21306814376 R2_adj:  [3.2139700458569354, 2.9453788333770152, 3.2137407445396029, 3.1353160421843422, 3.1428495940939847, 3.1477596318845769, 3.1570036060331566, 3.2138427583655496, 3.213681195188784, 3.1643925524092329, 3.132922868644699, 3.0555541025982076, 3.1511992467632486, 3.0959095054070898, 3.214110415647514, 3.2120040758204782, 3.2141513909444517, 3.2141373859142748, 3.2130947010048052]\n",
      "SSE: 237298.225446  SST: 56311.660444  R2 3.21401577533 R2_adj:  [3.2139700458569354, 2.9453788333770152, 3.2137407445396029, 3.1353160421843422, 3.1428495940939847, 3.1477596318845769, 3.1570036060331566, 3.2138427583655496, 3.213681195188784, 3.1643925524092329, 3.132922868644699, 3.0555541025982076, 3.1511992467632486, 3.0959095054070898, 3.214110415647514, 3.2120040758204782, 3.2141513909444517, 3.2141373859142748, 3.2130947010048052, 3.2140423439458843]\n",
      "SSE: 235115.656327  SST: 56311.660444  R2 3.17525703333 R2_adj:  [3.2139700458569354, 2.9453788333770152, 3.2137407445396029, 3.1353160421843422, 3.1428495940939847, 3.1477596318845769, 3.1570036060331566, 3.2138427583655496, 3.213681195188784, 3.1643925524092329, 3.132922868644699, 3.0555541025982076, 3.1511992467632486, 3.0959095054070898, 3.214110415647514, 3.2120040758204782, 3.2141513909444517, 3.2141373859142748, 3.2130947010048052, 3.2140423439458843, 3.1752831368341323]\n",
      "SSE: 235178.500214  SST: 56311.660444  R2 3.17637303464 R2_adj:  [3.2139700458569354, 2.9453788333770152, 3.2137407445396029, 3.1353160421843422, 3.1428495940939847, 3.1477596318845769, 3.1570036060331566, 3.2138427583655496, 3.213681195188784, 3.1643925524092329, 3.132922868644699, 3.0555541025982076, 3.1511992467632486, 3.0959095054070898, 3.214110415647514, 3.2120040758204782, 3.2141513909444517, 3.2141373859142748, 3.2130947010048052, 3.2140423439458843, 3.1752831368341323, 3.1763991515308549]\n",
      "SSE: 236988.233367  SST: 56311.660444  R2 3.20851083946 R2_adj:  [3.2139700458569354, 2.9453788333770152, 3.2137407445396029, 3.1353160421843422, 3.1428495940939847, 3.1477596318845769, 3.1570036060331566, 3.2138427583655496, 3.213681195188784, 3.1643925524092329, 3.132922868644699, 3.0555541025982076, 3.1511992467632486, 3.0959095054070898, 3.214110415647514, 3.2120040758204782, 3.2141513909444517, 3.2141373859142748, 3.2130947010048052, 3.2140423439458843, 3.1752831368341323, 3.1763991515308549, 3.2085373420148811]\n",
      "SSE: 237304.537396  SST: 56311.660444  R2 3.21412786491 R2_adj:  [3.2139700458569354, 2.9453788333770152, 3.2137407445396029, 3.1353160421843422, 3.1428495940939847, 3.1477596318845769, 3.1570036060331566, 3.2138427583655496, 3.213681195188784, 3.1643925524092329, 3.132922868644699, 3.0555541025982076, 3.1511992467632486, 3.0959095054070898, 3.214110415647514, 3.2120040758204782, 3.2141513909444517, 3.2141373859142748, 3.2130947010048052, 3.2140423439458843, 3.1752831368341323, 3.1763991515308549, 3.2085373420148811, 3.2141544348668063]\n",
      "SSE: 237282.43598  SST: 56311.660444  R2 3.21373538108 R2_adj:  [3.2139700458569354, 2.9453788333770152, 3.2137407445396029, 3.1353160421843422, 3.1428495940939847, 3.1477596318845769, 3.1570036060331566, 3.2138427583655496, 3.213681195188784, 3.1643925524092329, 3.132922868644699, 3.0555541025982076, 3.1511992467632486, 3.0959095054070898, 3.214110415647514, 3.2120040758204782, 3.2141513909444517, 3.2141373859142748, 3.2130947010048052, 3.2140423439458843, 3.1752831368341323, 3.1763991515308549, 3.2085373420148811, 3.2141544348668063, 3.2137619463276241]\n",
      "SSE: 237304.774469  SST: 56311.660444  R2 3.21413207491 R2_adj:  [3.2139700458569354, 2.9453788333770152, 3.2137407445396029, 3.1353160421843422, 3.1428495940939847, 3.1477596318845769, 3.1570036060331566, 3.2138427583655496, 3.213681195188784, 3.1643925524092329, 3.132922868644699, 3.0555541025982076, 3.1511992467632486, 3.0959095054070898, 3.214110415647514, 3.2120040758204782, 3.2141513909444517, 3.2141373859142748, 3.2130947010048052, 3.2140423439458843, 3.1752831368341323, 3.1763991515308549, 3.2085373420148811, 3.2141544348668063, 3.2137619463276241, 3.214158644921425]\n",
      "SSE: 237303.821928  SST: 56311.660444  R2 3.21411515939 R2_adj:  [3.2139700458569354, 2.9453788333770152, 3.2137407445396029, 3.1353160421843422, 3.1428495940939847, 3.1477596318845769, 3.1570036060331566, 3.2138427583655496, 3.213681195188784, 3.1643925524092329, 3.132922868644699, 3.0555541025982076, 3.1511992467632486, 3.0959095054070898, 3.214110415647514, 3.2120040758204782, 3.2141513909444517, 3.2141373859142748, 3.2130947010048052, 3.2140423439458843, 3.1752831368341323, 3.1763991515308549, 3.2085373420148811, 3.2141544348668063, 3.2137619463276241, 3.214158644921425, 3.2141417291992851]\n",
      "SSE: 235155.187052  SST: 56311.660444  R2 3.17595903225 R2_adj:  [3.2139700458569354, 2.9453788333770152, 3.2137407445396029, 3.1353160421843422, 3.1428495940939847, 3.1477596318845769, 3.1570036060331566, 3.2138427583655496, 3.213681195188784, 3.1643925524092329, 3.132922868644699, 3.0555541025982076, 3.1511992467632486, 3.0959095054070898, 3.214110415647514, 3.2120040758204782, 3.2141513909444517, 3.2141373859142748, 3.2130947010048052, 3.2140423439458843, 3.1752831368341323, 3.1763991515308549, 3.2085373420148811, 3.2141544348668063, 3.2137619463276241, 3.214158644921425, 3.2141417291992851, 3.1759851441734326]\n",
      "-------------------------------------------------\n",
      "Feature chosen:  PRI_jet_subleading_eta (index : 27 )\n",
      "SSE: 237295.053164  SST: 56311.660444  R2 3.21395944095 R2_adj:  [3.2139948650084702]\n",
      "SSE: 222170.124445  SST: 56311.660444  R2 2.9453662473 R2_adj:  [3.2139948650084702, 2.9453973737867791]\n",
      "SSE: 237282.147522  SST: 56311.660444  R2 3.21373025855 R2_adj:  [3.2139948650084702, 2.9453973737867791, 3.2137656789446689]\n",
      "SSE: 232865.809148  SST: 56311.660444  R2 3.13530354659 R2_adj:  [3.2139948650084702, 2.9453973737867791, 3.2137656789446689, 3.13533771212684]\n",
      "SSE: 233289.933989  SST: 56311.660444  R2 3.14283528757 R2_adj:  [3.2139948650084702, 2.9453973737867791, 3.2137656789446689, 3.13533771212684, 3.1428695736161325]\n",
      "SSE: 233566.680279  SST: 56311.660444  R2 3.14774983436 R2_adj:  [3.2139948650084702, 2.9453973737867791, 3.2137656789446689, 3.13533771212684, 3.1428695736161325, 3.1477841990477526]\n",
      "SSE: 234087.700079  SST: 56311.660444  R2 3.1570022662 R2_adj:  [3.2139948650084702, 2.9453973737867791, 3.2137656789446689, 3.13533771212684, 3.1428695736161325, 3.1477841990477526, 3.1570367789266376]\n",
      "SSE: 237287.882861  SST: 56311.660444  R2 3.21383210849 R2_adj:  [3.2139948650084702, 2.9453973737867791, 3.2137656789446689, 3.13533771212684, 3.1428695736161325, 3.1477841990477526, 3.1570367789266376, 3.2138675305082494]\n",
      "SSE: 237278.784025  SST: 56311.660444  R2 3.21367052852 R2_adj:  [3.2139948650084702, 2.9453973737867791, 3.2137656789446689, 3.13533771212684, 3.1428695736161325, 3.1477841990477526, 3.1570367789266376, 3.2138675305082494, 3.2137059479557539]\n",
      "SSE: 234503.219729  SST: 56311.660444  R2 3.16438119353 R2_adj:  [3.2139948650084702, 2.9453973737867791, 3.2137656789446689, 3.13533771212684, 3.1428695736161325, 3.1477841990477526, 3.1570367789266376, 3.2138675305082494, 3.2137059479557539, 3.1644158243220768]\n",
      "SSE: 232731.346565  SST: 56311.660444  R2 3.13291571817 R2_adj:  [3.2139948650084702, 2.9453973737867791, 3.2137656789446689, 3.13533771212684, 3.1428695736161325, 3.1477841990477526, 3.1570367789266376, 3.2138675305082494, 3.2137059479557539, 3.1644158243220768, 3.132949845500987]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SSE: 228374.161168  SST: 56311.660444  R2 3.05553946318 R2_adj:  [3.2139948650084702, 2.9453973737867791, 3.2137656789446689, 3.13533771212684, 3.1428695736161325, 3.1477841990477526, 3.1570367789266376, 3.2138675305082494, 3.2137059479557539, 3.1644158243220768, 3.132949845500987, 3.0555723524697087]\n",
      "SSE: 233760.58421  SST: 56311.660444  R2 3.15119324074 R2_adj:  [3.2139948650084702, 2.9453973737867791, 3.2137656789446689, 3.13533771212684, 3.1428695736161325, 3.1477841990477526, 3.1570367789266376, 3.2138675305082494, 3.2137059479557539, 3.1644158243220768, 3.132949845500987, 3.0555723524697087, 3.1512276605223968]\n",
      "SSE: 230647.034471  SST: 56311.660444  R2 3.095901855 R2_adj:  [3.2139948650084702, 2.9453973737867791, 3.2137656789446689, 3.13533771212684, 3.1428695736161325, 3.1477841990477526, 3.1570367789266376, 3.2138675305082494, 3.2137059479557539, 3.1644158243220768, 3.132949845500987, 3.0555723524697087, 3.1512276605223968, 3.095935390098302]\n",
      "SSE: 237302.963643  SST: 56311.660444  R2 3.2140999177 R2_adj:  [3.2139948650084702, 2.9453973737867791, 3.2137656789446689, 3.13533771212684, 3.1428695736161325, 3.1477841990477526, 3.1570367789266376, 3.2138675305082494, 3.2137059479557539, 3.1644158243220768, 3.132949845500987, 3.0555723524697087, 3.1512276605223968, 3.095935390098302, 3.2141353440114027]\n",
      "SSE: 237184.359085  SST: 56311.660444  R2 3.21199370103 R2_adj:  [3.2139948650084702, 2.9453973737867791, 3.2137656789446689, 3.13533771212684, 3.1428695736161325, 3.1477841990477526, 3.1570367789266376, 3.2138675305082494, 3.2137059479557539, 3.1644158243220768, 3.132949845500987, 3.0555723524697087, 3.1512276605223968, 3.095935390098302, 3.2141353440114027, 3.2120290936403095]\n",
      "SSE: 237305.355801  SST: 56311.660444  R2 3.2141423984 R2_adj:  [3.2139948650084702, 2.9453973737867791, 3.2137656789446689, 3.13533771212684, 3.1428695736161325, 3.1477841990477526, 3.1570367789266376, 3.2138675305082494, 3.2137059479557539, 3.1644158243220768, 3.132949845500987, 3.0555723524697087, 3.1512276605223968, 3.095935390098302, 3.2141353440114027, 3.2120290936403095, 3.2141778253892546]\n",
      "SSE: 237304.479498  SST: 56311.660444  R2 3.21412683674 R2_adj:  [3.2139948650084702, 2.9453973737867791, 3.2137656789446689, 3.13533771212684, 3.1428695736161325, 3.1477841990477526, 3.1570367789266376, 3.2138675305082494, 3.2137059479557539, 3.1644158243220768, 3.132949845500987, 3.0555723524697087, 3.1512276605223968, 3.095935390098302, 3.2141353440114027, 3.2120290936403095, 3.2141778253892546, 3.2141622634729625]\n",
      "SSE: 237245.751499  SST: 56311.660444  R2 3.21308392664 R2_adj:  [3.2139948650084702, 2.9453973737867791, 3.2137656789446689, 3.13533771212684, 3.1428695736161325, 3.1477841990477526, 3.1570367789266376, 3.2138675305082494, 3.2137059479557539, 3.1644158243220768, 3.132949845500987, 3.0555723524697087, 3.1512276605223968, 3.095935390098302, 3.2141353440114027, 3.2120290936403095, 3.2141778253892546, 3.2141622634729625, 3.2131193366891742]\n",
      "SSE: 237299.130249  SST: 56311.660444  R2 3.21403184311 R2_adj:  [3.2139948650084702, 2.9453973737867791, 3.2137656789446689, 3.13533771212684, 3.1428695736161325, 3.1477841990477526, 3.1570367789266376, 3.2138675305082494, 3.2137059479557539, 3.1644158243220768, 3.132949845500987, 3.0555723524697087, 3.1512276605223968, 3.095935390098302, 3.2141353440114027, 3.2120290936403095, 3.2141778253892546, 3.2141622634729625, 3.2131193366891742, 3.2140672683275131]\n",
      "SSE: 235116.532847  SST: 56311.660444  R2 3.17527259883 R2_adj:  [3.2139948650084702, 2.9453973737867791, 3.2137656789446689, 3.13533771212684, 3.1428695736161325, 3.1477841990477526, 3.1570367789266376, 3.2138675305082494, 3.2137059479557539, 3.1644158243220768, 3.132949845500987, 3.0555723524697087, 3.1512276605223968, 3.095935390098302, 3.2141353440114027, 3.2120290936403095, 3.2141778253892546, 3.2141622634729625, 3.2131193366891742, 3.2140672683275131, 3.1753074038904927]\n",
      "SSE: 235179.294785  SST: 56311.660444  R2 3.17638714488 R2_adj:  [3.2139948650084702, 2.9453973737867791, 3.2137656789446689, 3.13533771212684, 3.1428695736161325, 3.1477841990477526, 3.1570367789266376, 3.2138675305082494, 3.2137059479557539, 3.1644158243220768, 3.132949845500987, 3.0555723524697087, 3.1512276605223968, 3.095935390098302, 3.2141353440114027, 3.2120290936403095, 3.2141778253892546, 3.2141622634729625, 3.2131193366891742, 3.2140672683275131, 3.1753074038904927, 3.1764219677705627]\n",
      "SSE: 236989.121511  SST: 56311.660444  R2 3.20852661141 R2_adj:  [3.2139948650084702, 2.9453973737867791, 3.2137656789446689, 3.13533771212684, 3.1428695736161325, 3.1477841990477526, 3.1570367789266376, 3.2138675305082494, 3.2137059479557539, 3.1644158243220768, 3.132949845500987, 3.0555723524697087, 3.1512276605223968, 3.095935390098302, 3.2141353440114027, 3.2120290936403095, 3.2141778253892546, 3.2141622634729625, 3.2131193366891742, 3.2140672683275131, 3.1753074038904927, 3.1764219677705627, 3.2085619485424957]\n",
      "SSE: 237305.441528  SST: 56311.660444  R2 3.21414392076 R2_adj:  [3.2139948650084702, 2.9453973737867791, 3.2137656789446689, 3.13533771212684, 3.1428695736161325, 3.1477841990477526, 3.1570367789266376, 3.2138675305082494, 3.2137059479557539, 3.1644158243220768, 3.132949845500987, 3.0555723524697087, 3.1512276605223968, 3.095935390098302, 3.2141353440114027, 3.2120290936403095, 3.2141778253892546, 3.2141622634729625, 3.2131193366891742, 3.2140672683275131, 3.1753074038904927, 3.1764219677705627, 3.2085619485424957, 3.2141793477738765]\n",
      "SSE: 237283.334  SST: 56311.660444  R2 3.2137513284 R2_adj:  [3.2139948650084702, 2.9453973737867791, 3.2137656789446689, 3.13533771212684, 3.1428695736161325, 3.1477841990477526, 3.1570367789266376, 3.2138675305082494, 3.2137059479557539, 3.1644158243220768, 3.132949845500987, 3.0555723524697087, 3.1512276605223968, 3.095935390098302, 3.2141353440114027, 3.2120290936403095, 3.2141778253892546, 3.2141622634729625, 3.2131193366891742, 3.2140672683275131, 3.1753074038904927, 3.1764219677705627, 3.2085619485424957, 3.2141793477738765, 3.2137867491314274]\n",
      "SSE: 237304.721153  SST: 56311.660444  R2 3.21413112812 R2_adj:  [3.2139948650084702, 2.9453973737867791, 3.2137656789446689, 3.13533771212684, 3.1428695736161325, 3.1477841990477526, 3.1570367789266376, 3.2138675305082494, 3.2137059479557539, 3.1644158243220768, 3.132949845500987, 3.0555723524697087, 3.1512276605223968, 3.095935390098302, 3.2141353440114027, 3.2120290936403095, 3.2141778253892546, 3.2141622634729625, 3.2131193366891742, 3.2140672683275131, 3.1753074038904927, 3.1764219677705627, 3.2085619485424957, 3.2141793477738765, 3.2137867491314274, 3.2141665549252028]\n",
      "SSE: 235155.998323  SST: 56311.660444  R2 3.17597343905 R2_adj:  [3.2139948650084702, 2.9453973737867791, 3.2137656789446689, 3.13533771212684, 3.1428695736161325, 3.1477841990477526, 3.1570367789266376, 3.2138675305082494, 3.2137059479557539, 3.1644158243220768, 3.132949845500987, 3.0555723524697087, 3.1512276605223968, 3.095935390098302, 3.2141353440114027, 3.2120290936403095, 3.2141778253892546, 3.2141622634729625, 3.2131193366891742, 3.2140672683275131, 3.1753074038904927, 3.1764219677705627, 3.2085619485424957, 3.2141793477738765, 3.2137867491314274, 3.2141665549252028, 3.1760082553225857]\n",
      "-------------------------------------------------\n",
      "Feature chosen:  PRI_jet_leading_phi (index : 25 )\n",
      "SSE: 237295.719416  SST: 56311.660444  R2 3.21397127246 R2_adj:  [3.2140155529478904]\n",
      "SSE: 222170.787096  SST: 56311.660444  R2 2.94537801486 R2_adj:  [3.2140155529478904, 2.9454169233524161]\n",
      "SSE: 237282.815261  SST: 56311.660444  R2 3.21374211646 R2_adj:  [3.2140155529478904, 2.9454169233524161, 3.2137863923653791]\n",
      "SSE: 232866.4038  SST: 56311.660444  R2 3.1353141066 R2_adj:  [3.2140155529478904, 2.9454169233524161, 3.2137863923653791, 3.1353568139114292]\n",
      "SSE: 233290.562801  SST: 56311.660444  R2 3.14284645421 R2_adj:  [3.2140155529478904, 2.9454169233524161, 3.2137863923653791, 3.1353568139114292, 3.142889312163637]\n",
      "SSE: 233567.290164  SST: 56311.660444  R2 3.14776066488 R2_adj:  [3.2140155529478904, 2.9454169233524161, 3.2137863923653791, 3.1353568139114292, 3.142889312163637, 3.1478036211241518]\n",
      "SSE: 234088.317173  SST: 56311.660444  R2 3.15701322475 R2_adj:  [3.2140155529478904, 2.9454169233524161, 3.2137863923653791, 3.1353568139114292, 3.142889312163637, 3.1478036211241518, 3.157056366051068]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SSE: 237288.541022  SST: 56311.660444  R2 3.21384379631 R2_adj:  [3.2140155529478904, 2.9454169233524161, 3.2137863923653791, 3.1353568139114292, 3.142889312163637, 3.1478036211241518, 3.157056366051068, 3.2138880742485627]\n",
      "SSE: 237279.467003  SST: 56311.660444  R2 3.21368265706 R2_adj:  [3.2140155529478904, 2.9454169233524161, 3.2137863923653791, 3.1353568139114292, 3.142889312163637, 3.1478036211241518, 3.157056366051068, 3.2138880742485627, 3.213726931774687]\n",
      "SSE: 234503.782048  SST: 56311.660444  R2 3.16439117936 R2_adj:  [3.2140155529478904, 2.9454169233524161, 3.2137863923653791, 3.1353568139114292, 3.142889312163637, 3.1478036211241518, 3.157056366051068, 3.2138880742485627, 3.213726931774687, 3.1644344682178795]\n",
      "SSE: 232732.345354  SST: 56311.660444  R2 3.13293345497 R2_adj:  [3.2140155529478904, 2.9454169233524161, 3.2137863923653791, 3.1353568139114292, 3.142889312163637, 3.1478036211241518, 3.157056366051068, 3.2138880742485627, 3.213726931774687, 3.1644344682178795, 3.1329761146652815]\n",
      "SSE: 228374.925405  SST: 56311.660444  R2 3.05555303475 R2_adj:  [3.2140155529478904, 2.9454169233524161, 3.2137863923653791, 3.1353568139114292, 3.142889312163637, 3.1478036211241518, 3.157056366051068, 3.2138880742485627, 3.213726931774687, 3.1644344682178795, 3.1329761146652815, 3.0555941467959986]\n",
      "SSE: 233761.157183  SST: 56311.660444  R2 3.15120341577 R2_adj:  [3.2140155529478904, 2.9454169233524161, 3.2137863923653791, 3.1353568139114292, 3.142889312163637, 3.1478036211241518, 3.157056366051068, 3.2138880742485627, 3.213726931774687, 3.1644344682178795, 3.1329761146652815, 3.0555941467959986, 3.1512464408692904]\n",
      "SSE: 230647.69126  SST: 56311.660444  R2 3.09591351847 R2_adj:  [3.2140155529478904, 2.9454169233524161, 3.2137863923653791, 3.1353568139114292, 3.142889312163637, 3.1478036211241518, 3.157056366051068, 3.2138880742485627, 3.213726931774687, 3.1644344682178795, 3.1329761146652815, 3.0555941467959986, 3.1512464408692904, 3.0959554377414751]\n",
      "SSE: 237303.561595  SST: 56311.660444  R2 3.21411053632 R2_adj:  [3.2140155529478904, 2.9454169233524161, 3.2137863923653791, 3.1353568139114292, 3.142889312163637, 3.1478036211241518, 3.157056366051068, 3.2138880742485627, 3.213726931774687, 3.1644344682178795, 3.1329761146652815, 3.0555941467959986, 3.1512464408692904, 3.0959554377414751, 3.2141548195901972]\n",
      "SSE: 237185.070917  SST: 56311.660444  R2 3.21200634197 R2_adj:  [3.2140155529478904, 2.9454169233524161, 3.2137863923653791, 3.1353568139114292, 3.142889312163637, 3.1478036211241518, 3.157056366051068, 3.2138880742485627, 3.213726931774687, 3.1644344682178795, 3.1329761146652815, 3.0555941467959986, 3.1512464408692904, 3.0959554377414751, 3.2141548195901972, 3.2120505831556443]\n",
      "SSE: 237306.024197  SST: 56311.660444  R2 3.21415426798 R2_adj:  [3.2140155529478904, 2.9454169233524161, 3.2137863923653791, 3.1353568139114292, 3.142889312163637, 3.1478036211241518, 3.157056366051068, 3.2138880742485627, 3.213726931774687, 3.1644344682178795, 3.1329761146652815, 3.0555941467959986, 3.1512464408692904, 3.0959554377414751, 3.2141548195901972, 3.2120505831556443, 3.2141985521271863]\n",
      "SSE: 237304.874612  SST: 56311.660444  R2 3.21413385328 R2_adj:  [3.2140155529478904, 2.9454169233524161, 3.2137863923653791, 3.1353568139114292, 3.142889312163637, 3.1478036211241518, 3.157056366051068, 3.2138880742485627, 3.213726931774687, 3.1644344682178795, 3.1329761146652815, 3.0555941467959986, 3.1512464408692904, 3.0959554377414751, 3.2141548195901972, 3.2120505831556443, 3.2141985521271863, 3.2141781370227682]\n",
      "SSE: 237246.418263  SST: 56311.660444  R2 3.21309576723 R2_adj:  [3.2140155529478904, 2.9454169233524161, 3.2137863923653791, 3.1353568139114292, 3.142889312163637, 3.1478036211241518, 3.157056366051068, 3.2138880742485627, 3.213726931774687, 3.1644344682178795, 3.1329761146652815, 3.0555941467959986, 3.1512464408692904, 3.0959554377414751, 3.2141548195901972, 3.2120505831556443, 3.2141985521271863, 3.2141781370227682, 3.2131400302112803]\n",
      "SSE: 237299.460903  SST: 56311.660444  R2 3.21403771496 R2_adj:  [3.2140155529478904, 2.9454169233524161, 3.2137863923653791, 3.1353568139114292, 3.142889312163637, 3.1478036211241518, 3.157056366051068, 3.2138880742485627, 3.213726931774687, 3.1644344682178795, 3.1329761146652815, 3.0555941467959986, 3.1512464408692904, 3.0959554377414751, 3.2141548195901972, 3.2120505831556443, 3.2141985521271863, 3.2141781370227682, 3.2131400302112803, 3.2140819967750587]\n",
      "SSE: 235117.075898  SST: 56311.660444  R2 3.17528224252 R2_adj:  [3.2140155529478904, 2.9454169233524161, 3.2137863923653791, 3.1353568139114292, 3.142889312163637, 3.1478036211241518, 3.157056366051068, 3.2138880742485627, 3.213726931774687, 3.1644344682178795, 3.1329761146652815, 3.0555941467959986, 3.1512464408692904, 3.0959554377414751, 3.2141548195901972, 3.2120505831556443, 3.2141985521271863, 3.2141781370227682, 3.2131400302112803, 3.2140819967750587, 3.1753257492043963]\n",
      "SSE: 235179.95939  SST: 56311.660444  R2 3.17639894713 R2_adj:  [3.2140155529478904, 2.9454169233524161, 3.2137863923653791, 3.1353568139114292, 3.142889312163637, 3.1478036211241518, 3.157056366051068, 3.2138880742485627, 3.213726931774687, 3.1644344682178795, 3.1329761146652815, 3.0555941467959986, 3.1512464408692904, 3.0959554377414751, 3.2141548195901972, 3.2120505831556443, 3.2141985521271863, 3.2141781370227682, 3.2131400302112803, 3.2140819967750587, 3.1753257492043963, 3.1764424761578716]\n",
      "SSE: 236989.72458  SST: 56311.660444  R2 3.20853732089 R2_adj:  [3.2140155529478904, 2.9454169233524161, 3.2137863923653791, 3.1353568139114292, 3.142889312163637, 3.1478036211241518, 3.157056366051068, 3.2138880742485627, 3.213726931774687, 3.1644344682178795, 3.1329761146652815, 3.0555941467959986, 3.1512464408692904, 3.0959554377414751, 3.2141548195901972, 3.2120505831556443, 3.2141985521271863, 3.2141781370227682, 3.2131400302112803, 3.2140819967750587, 3.1753257492043963, 3.1764424761578716, 3.2085814926986607]\n",
      "SSE: 237284.001439  SST: 56311.660444  R2 3.21376318099 R2_adj:  [3.2140155529478904, 2.9454169233524161, 3.2137863923653791, 3.1353568139114292, 3.142889312163637, 3.1478036211241518, 3.157056366051068, 3.2138880742485627, 3.213726931774687, 3.1644344682178795, 3.1329761146652815, 3.0555941467959986, 3.1512464408692904, 3.0959554377414751, 3.2141548195901972, 3.2120505831556443, 3.2141985521271863, 3.2141781370227682, 3.2131400302112803, 3.2140819967750587, 3.1753257492043963, 3.1764424761578716, 3.2085814926986607, 3.2138074573161037]\n",
      "SSE: 237305.391459  SST: 56311.660444  R2 3.21414303163 R2_adj:  [3.2140155529478904, 2.9454169233524161, 3.2137863923653791, 3.1353568139114292, 3.142889312163637, 3.1478036211241518, 3.157056366051068, 3.2138880742485627, 3.213726931774687, 3.1644344682178795, 3.1329761146652815, 3.0555941467959986, 3.1512464408692904, 3.0959554377414751, 3.2141548195901972, 3.2120505831556443, 3.2141985521271863, 3.2141781370227682, 3.2131400302112803, 3.2140819967750587, 3.1753257492043963, 3.1764424761578716, 3.2085814926986607, 3.2138074573161037, 3.214187315551523]\n",
      "SSE: 235156.60281  SST: 56311.660444  R2 3.17598417371 R2_adj:  [3.2140155529478904, 2.9454169233524161, 3.2137863923653791, 3.1353568139114292, 3.142889312163637, 3.1478036211241518, 3.157056366051068, 3.2138880742485627, 3.213726931774687, 3.1644344682178795, 3.1329761146652815, 3.0555941467959986, 3.1512464408692904, 3.0959554377414751, 3.2141548195901972, 3.2120505831556443, 3.2141985521271863, 3.2141781370227682, 3.2131400302112803, 3.2140819967750587, 3.1753257492043963, 3.1764424761578716, 3.2085814926986607, 3.2138074573161037, 3.214187315551523, 3.1760276944413444]\n",
      "-------------------------------------------------\n",
      "Feature chosen:  PRI_lep_eta (index : 17 )\n",
      "SSE: 237296.298525  SST: 56311.660444  R2 3.21398155647 R2_adj:  [3.2140346935184825]\n",
      "SSE: 222171.774875  SST: 56311.660444  R2 2.94539555615 R2_adj:  [3.2140346935184825, 2.9454422469518819]\n",
      "SSE: 237283.392588  SST: 56311.660444  R2 3.21375236882 R2_adj:  [3.2140346935184825, 2.9454422469518819, 3.2138055003670538]\n",
      "SSE: 232867.365008  SST: 56311.660444  R2 3.13533117602 R2_adj:  [3.2140346935184825, 2.9454422469518819, 3.2138055003670538, 3.1353824254071343]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SSE: 233290.998872  SST: 56311.660444  R2 3.1428541981 R2_adj:  [3.2140346935184825, 2.9454422469518819, 3.2138055003670538, 3.1353824254071343, 3.1429056280368224]\n",
      "SSE: 233567.977769  SST: 56311.660444  R2 3.14777287559 R2_adj:  [3.2140346935184825, 2.9454422469518819, 3.2138055003670538, 3.1353824254071343, 3.1429056280368224, 3.1478244235847206]\n",
      "SSE: 234088.831  SST: 56311.660444  R2 3.15702234945 R2_adj:  [3.2140346935184825, 2.9454422469518819, 3.2138055003670538, 3.1353824254071343, 3.1429056280368224, 3.1478244235847206, 3.1570741194381151]\n",
      "SSE: 237289.129297  SST: 56311.660444  R2 3.21385424309 R2_adj:  [3.2140346935184825, 2.9454422469518819, 3.2138055003670538, 3.1353824254071343, 3.1429056280368224, 3.1478244235847206, 3.1570741194381151, 3.2139073770762789]\n",
      "SSE: 237279.973393  SST: 56311.660444  R2 3.21369164969 R2_adj:  [3.2140346935184825, 2.9454422469518819, 3.2138055003670538, 3.1353824254071343, 3.1429056280368224, 3.1478244235847206, 3.1570741194381151, 3.2139073770762789, 3.2137447797788599]\n",
      "SSE: 234504.753659  SST: 56311.660444  R2 3.16440843352 R2_adj:  [3.2140346935184825, 2.9454422469518819, 3.2138055003670538, 3.1353824254071343, 3.1429056280368224, 3.1478244235847206, 3.1570741194381151, 3.2139073770762789, 3.2137447797788599, 3.1644603807792886]\n",
      "SSE: 232732.883607  SST: 56311.660444  R2 3.13294301344 R2_adj:  [3.2140346935184825, 2.9454422469518819, 3.2138055003670538, 3.1353824254071343, 3.1429056280368224, 3.1478244235847206, 3.1570741194381151, 3.2139073770762789, 3.2137447797788599, 3.1644603807792886, 3.132994205507734]\n",
      "SSE: 228376.165411  SST: 56311.660444  R2 3.05557505515 R2_adj:  [3.2140346935184825, 2.9454422469518819, 3.2138055003670538, 3.1353824254071343, 3.1429056280368224, 3.1478244235847206, 3.1570741194381151, 3.2139073770762789, 3.2137447797788599, 3.1644603807792886, 3.132994205507734, 3.0556243903335685]\n",
      "SSE: 233761.619238  SST: 56311.660444  R2 3.15121162108 R2_adj:  [3.2140346935184825, 2.9454422469518819, 3.2138055003670538, 3.1353824254071343, 3.1429056280368224, 3.1478244235847206, 3.1570741194381151, 3.2139073770762789, 3.2137447797788599, 3.1644603807792886, 3.132994205507734, 3.0556243903335685, 3.1512632516072232]\n",
      "SSE: 230648.279947  SST: 56311.660444  R2 3.09592397255 R2_adj:  [3.2140346935184825, 2.9454422469518819, 3.2138055003670538, 3.1353824254071343, 3.1429056280368224, 3.1478244235847206, 3.1570741194381151, 3.2139073770762789, 3.2137447797788599, 3.1644603807792886, 3.132994205507734, 3.0556243903335685, 3.1512632516072232, 3.0959742761342852]\n",
      "SSE: 237304.160517  SST: 56311.660444  R2 3.21412117216 R2_adj:  [3.2140346935184825, 2.9454422469518819, 3.2138055003670538, 3.1353824254071343, 3.1429056280368224, 3.1478244235847206, 3.1570741194381151, 3.2139073770762789, 3.2137447797788599, 3.1644603807792886, 3.132994205507734, 3.0556243903335685, 3.1512632516072232, 3.0959742761342852, 3.2141743125608908]\n",
      "SSE: 237185.650315  SST: 56311.660444  R2 3.21201663111 R2_adj:  [3.2140346935184825, 2.9454422469518819, 3.2138055003670538, 3.1353824254071343, 3.1429056280368224, 3.1478244235847206, 3.1570741194381151, 3.2139073770762789, 3.2137447797788599, 3.1644603807792886, 3.132994205507734, 3.0556243903335685, 3.1512632516072232, 3.0959742761342852, 3.2141743125608908, 3.2120697209939681]\n",
      "SSE: 237305.464862  SST: 56311.660444  R2 3.21414433513 R2_adj:  [3.2140346935184825, 2.9454422469518819, 3.2138055003670538, 3.1353824254071343, 3.1429056280368224, 3.1478244235847206, 3.1570741194381151, 3.2139073770762789, 3.2137447797788599, 3.1644603807792886, 3.132994205507734, 3.0556243903335685, 3.1512632516072232, 3.0959742761342852, 3.2141743125608908, 3.2120697209939681, 3.2141974760810652]\n",
      "SSE: 237246.997117  SST: 56311.660444  R2 3.21310604671 R2_adj:  [3.2140346935184825, 2.9454422469518819, 3.2138055003670538, 3.1353824254071343, 3.1429056280368224, 3.1478244235847206, 3.1570741194381151, 3.2139073770762789, 3.2137447797788599, 3.1644603807792886, 3.132994205507734, 3.0556243903335685, 3.1512632516072232, 3.0959742761342852, 3.2141743125608908, 3.2120697209939681, 3.2141974760810652, 3.2131591627473624]\n",
      "SSE: 237300.036057  SST: 56311.660444  R2 3.21404792871 R2_adj:  [3.2140346935184825, 2.9454422469518819, 3.2138055003670538, 3.1353824254071343, 3.1429056280368224, 3.1478244235847206, 3.1570741194381151, 3.2139073770762789, 3.2137447797788599, 3.1644603807792886, 3.132994205507734, 3.0556243903335685, 3.1512632516072232, 3.0959742761342852, 3.2141743125608908, 3.2120697209939681, 3.2141974760810652, 3.2131591627473624, 3.214101067352658]\n",
      "SSE: 235118.048153  SST: 56311.660444  R2 3.17529950812 R2_adj:  [3.2140346935184825, 2.9454422469518819, 3.2138055003670538, 3.1353824254071343, 3.1429056280368224, 3.1478244235847206, 3.1570741194381151, 3.2139073770762789, 3.2137447797788599, 3.1644603807792886, 3.132994205507734, 3.0556243903335685, 3.1512632516072232, 3.0959742761342852, 3.2141743125608908, 3.2120697209939681, 3.2141974760810652, 3.2131591627473624, 3.214101067352658, 3.175351716772925]\n",
      "SSE: 235181.127857  SST: 56311.660444  R2 3.17641969714 R2_adj:  [3.2140346935184825, 2.9454422469518819, 3.2138055003670538, 3.1353824254071343, 3.1429056280368224, 3.1478244235847206, 3.1570741194381151, 3.2139073770762789, 3.2137447797788599, 3.1644603807792886, 3.132994205507734, 3.0556243903335685, 3.1512632516072232, 3.0959742761342852, 3.2141743125608908, 3.2120697209939681, 3.2141974760810652, 3.2131591627473624, 3.214101067352658, 3.175351716772925, 3.1764719326727651]\n",
      "SSE: 236990.000428  SST: 56311.660444  R2 3.20854221948 R2_adj:  [3.2140346935184825, 2.9454422469518819, 3.2138055003670538, 3.1353824254071343, 3.1429056280368224, 3.1478244235847206, 3.1570741194381151, 3.2139073770762789, 3.2137447797788599, 3.1644603807792886, 3.132994205507734, 3.0556243903335685, 3.1512632516072232, 3.0959742761342852, 3.2141743125608908, 3.2120697209939681, 3.2141974760810652, 3.2131591627473624, 3.214101067352658, 3.175351716772925, 3.1764719326727651, 3.2085952259794182]\n",
      "SSE: 237284.591562  SST: 56311.660444  R2 3.21377366057 R2_adj:  [3.2140346935184825, 2.9454422469518819, 3.2138055003670538, 3.1353824254071343, 3.1429056280368224, 3.1478244235847206, 3.1570741194381151, 3.2139073770762789, 3.2137447797788599, 3.1644603807792886, 3.132994205507734, 3.0556243903335685, 3.1512632516072232, 3.0959742761342852, 3.2141743125608908, 3.2120697209939681, 3.2141974760810652, 3.2131591627473624, 3.214101067352658, 3.175351716772925, 3.1764719326727651, 3.2085952259794182, 3.2138267926259148]\n",
      "SSE: 237305.977011  SST: 56311.660444  R2 3.21415343003 R2_adj:  [3.2140346935184825, 2.9454422469518819, 3.2138055003670538, 3.1353824254071343, 3.1429056280368224, 3.1478244235847206, 3.1570741194381151, 3.2139073770762789, 3.2137447797788599, 3.1644603807792886, 3.132994205507734, 3.0556243903335685, 3.1512632516072232, 3.0959742761342852, 3.2141743125608908, 3.2120697209939681, 3.2141974760810652, 3.2131591627473624, 3.214101067352658, 3.175351716772925, 3.1764719326727651, 3.2085952259794182, 3.2138267926259148, 3.214206571197443]\n",
      "SSE: 235157.612234  SST: 56311.660444  R2 3.17600209938 R2_adj:  [3.2140346935184825, 2.9454422469518819, 3.2138055003670538, 3.1353824254071343, 3.1429056280368224, 3.1478244235847206, 3.1570741194381151, 3.2139073770762789, 3.2137447797788599, 3.1644603807792886, 3.132994205507734, 3.0556243903335685, 3.1512632516072232, 3.0959742761342852, 3.2141743125608908, 3.2120697209939681, 3.2141974760810652, 3.2131591627473624, 3.214101067352658, 3.175351716772925, 3.1764719326727651, 3.2085952259794182, 3.2138267926259148, 3.214206571197443, 3.1760543248958766]\n",
      "-------------------------------------------------\n",
      "Feature chosen:  PRI_jet_subleading_phi (index : 28 )\n",
      "SSE: 237296.259997  SST: 56311.660444  R2 3.21398087228 R2_adj:  [3.2140428657291431]\n",
      "SSE: 222172.606684  SST: 56311.660444  R2 2.94541032768 R2_adj:  [3.2140428657291431, 2.9454648009079354]\n",
      "SSE: 237283.347146  SST: 56311.660444  R2 3.21375156184 R2_adj:  [3.2140428657291431, 2.9454648009079354, 3.2138135488638162]\n",
      "SSE: 232867.981108  SST: 56311.660444  R2 3.13534211692 R2_adj:  [3.2140428657291431, 2.9454648009079354, 3.2138135488638162, 3.1354019084094387]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SSE: 233290.287702  SST: 56311.660444  R2 3.14284156892 R2_adj:  [3.2140428657291431, 2.9454648009079354, 3.2138135488638162, 3.1354019084094387, 3.1429015704020444]\n",
      "SSE: 233567.829938  SST: 56311.660444  R2 3.14777025036 R2_adj:  [3.2140428657291431, 2.9454648009079354, 3.2138135488638162, 3.1354019084094387, 3.1429015704020444, 3.1478303898519195]\n",
      "SSE: 234088.591374  SST: 56311.660444  R2 3.15701809409 R2_adj:  [3.2140428657291431, 2.9454648009079354, 3.2138135488638162, 3.1354019084094387, 3.1429015704020444, 3.1478303898519195, 3.1570784925328863]\n",
      "SSE: 237289.033377  SST: 56311.660444  R2 3.21385253971 R2_adj:  [3.2140428657291431, 2.9454648009079354, 3.2138135488638162, 3.1354019084094387, 3.1429015704020444, 3.1478303898519195, 3.1570784925328863, 3.2139145295690339]\n",
      "SSE: 237279.908004  SST: 56311.660444  R2 3.21369048849 R2_adj:  [3.2140428657291431, 2.9454648009079354, 3.2138135488638162, 3.1354019084094387, 3.1429015704020444, 3.1478303898519195, 3.1570784925328863, 3.2139145295690339, 3.2137524738057803]\n",
      "SSE: 234505.296631  SST: 56311.660444  R2 3.1644180758 R2_adj:  [3.2140428657291431, 2.9454648009079354, 3.2138135488638162, 3.1354019084094387, 3.1429015704020444, 3.1478303898519195, 3.1570784925328863, 3.2139145295690339, 3.2137524738057803, 3.1644786814448262]\n",
      "SSE: 232733.349342  SST: 56311.660444  R2 3.13295128411 R2_adj:  [3.2140428657291431, 2.9454648009079354, 3.2138135488638162, 3.1354019084094387, 3.1429015704020444, 3.1478303898519195, 3.1570784925328863, 3.2139145295690339, 3.2137524738057803, 3.1644786814448262, 3.1330110086554996]\n",
      "SSE: 228377.222124  SST: 56311.660444  R2 3.0555938206 R2_adj:  [3.2140428657291431, 2.9454648009079354, 3.2138135488638162, 3.1354019084094387, 3.1429015704020444, 3.1478303898519195, 3.1570784925328863, 3.2139145295690339, 3.2137524738057803, 3.1644786814448262, 3.1330110086554996, 3.0556513790658788]\n",
      "SSE: 233761.564818  SST: 56311.660444  R2 3.15121065468 R2_adj:  [3.2140428657291431, 2.9454648009079354, 3.2138135488638162, 3.1354019084094387, 3.1429015704020444, 3.1478303898519195, 3.1570784925328863, 3.2139145295690339, 3.2137524738057803, 3.1644786814448262, 3.1330110086554996, 3.0556513790658788, 3.1512708905079085]\n",
      "SSE: 230649.128539  SST: 56311.660444  R2 3.09593904211 R2_adj:  [3.2140428657291431, 2.9454648009079354, 3.2138135488638162, 3.1354019084094387, 3.1429015704020444, 3.1478303898519195, 3.1570784925328863, 3.2139145295690339, 3.2137524738057803, 3.1644786814448262, 3.1330110086554996, 3.0556513790658788, 3.1512708905079085, 3.0959977302831367]\n",
      "SSE: 237303.860738  SST: 56311.660444  R2 3.2141158486 R2_adj:  [3.2140428657291431, 2.9454648009079354, 3.2138135488638162, 3.1354019084094387, 3.1429015704020444, 3.1478303898519195, 3.1570784925328863, 3.2139145295690339, 3.2137524738057803, 3.1644786814448262, 3.1330110086554996, 3.0556513790658788, 3.1512708905079085, 3.0959977302831367, 3.2141778458250272]\n",
      "SSE: 237185.613238  SST: 56311.660444  R2 3.21201597267 R2_adj:  [3.2140428657291431, 2.9454648009079354, 3.2138135488638162, 3.1354019084094387, 3.1429015704020444, 3.1478303898519195, 3.1570784925328863, 3.2139145295690339, 3.2137524738057803, 3.1644786814448262, 3.1330110086554996, 3.0556513790658788, 3.1512708905079085, 3.0959977302831367, 3.2141778458250272, 3.2120779110960545]\n",
      "SSE: 237305.68803  SST: 56311.660444  R2 3.21414829822 R2_adj:  [3.2140428657291431, 2.9454648009079354, 3.2138135488638162, 3.1354019084094387, 3.1429015704020444, 3.1478303898519195, 3.1570784925328863, 3.2139145295690339, 3.2137524738057803, 3.1644786814448262, 3.1330110086554996, 3.0556513790658788, 3.1512708905079085, 3.0959977302831367, 3.2141778458250272, 3.2120779110960545, 3.2142102963544414]\n",
      "SSE: 237246.962234  SST: 56311.660444  R2 3.21310542724 R2_adj:  [3.2140428657291431, 2.9454648009079354, 3.2138135488638162, 3.1354019084094387, 3.1429015704020444, 3.1478303898519195, 3.1570784925328863, 3.2139145295690339, 3.2137524738057803, 3.1644786814448262, 3.1330110086554996, 3.0556513790658788, 3.1512708905079085, 3.0959977302831367, 3.2141778458250272, 3.2120779110960545, 3.2142102963544414, 3.2131673961775222]\n",
      "SSE: 237300.391256  SST: 56311.660444  R2 3.21405423646 R2_adj:  [3.2140428657291431, 2.9454648009079354, 3.2138135488638162, 3.1354019084094387, 3.1429015704020444, 3.1478303898519195, 3.1570784925328863, 3.2139145295690339, 3.2137524738057803, 3.1644786814448262, 3.1330110086554996, 3.0556513790658788, 3.1512708905079085, 3.0959977302831367, 3.2141778458250272, 3.2120779110960545, 3.2142102963544414, 3.2131673961775222, 3.2141162319671843]\n",
      "SSE: 235118.399748  SST: 56311.660444  R2 3.17530575186 R2_adj:  [3.2140428657291431, 2.9454648009079354, 3.2138135488638162, 3.1354019084094387, 3.1429015704020444, 3.1478303898519195, 3.1570784925328863, 3.2139145295690339, 3.2137524738057803, 3.1644786814448262, 3.1330110086554996, 3.0556513790658788, 3.1512708905079085, 3.0959977302831367, 3.2141778458250272, 3.2120779110960545, 3.2142102963544414, 3.2131673961775222, 3.2141162319671843, 3.1753666623680381]\n",
      "SSE: 235181.24834  SST: 56311.660444  R2 3.17642183672 R2_adj:  [3.2140428657291431, 2.9454648009079354, 3.2138135488638162, 3.1354019084094387, 3.1429015704020444, 3.1478303898519195, 3.1570784925328863, 3.2139145295690339, 3.2137524738057803, 3.1644786814448262, 3.1330110086554996, 3.0556513790658788, 3.1512708905079085, 3.0959977302831367, 3.2141778458250272, 3.2120779110960545, 3.2142102963544414, 3.2131673961775222, 3.2141162319671843, 3.1753666623680381, 3.1764827784796088]\n",
      "SSE: 236990.081921  SST: 56311.660444  R2 3.20854366666 R2_adj:  [3.2140428657291431, 2.9454648009079354, 3.2138135488638162, 3.1354019084094387, 3.1429015704020444, 3.1478303898519195, 3.1570784925328863, 3.2139145295690339, 3.2137524738057803, 3.1644786814448262, 3.1330110086554996, 3.0556513790658788, 3.1512708905079085, 3.0959977302831367, 3.2141778458250272, 3.2120779110960545, 3.2142102963544414, 3.2131673961775222, 3.2141162319671843, 3.1753666623680381, 3.1764827784796088, 3.2086055078619404]\n",
      "SSE: 237284.40245  SST: 56311.660444  R2 3.21377030225 R2_adj:  [3.2140428657291431, 2.9454648009079354, 3.2138135488638162, 3.1354019084094387, 3.1429015704020444, 3.1478303898519195, 3.1570784925328863, 3.2139145295690339, 3.2137524738057803, 3.1644786814448262, 3.1330110086554996, 3.0556513790658788, 3.1512708905079085, 3.0959977302831367, 3.2141778458250272, 3.2120779110960545, 3.2142102963544414, 3.2131673961775222, 3.2141162319671843, 3.1753666623680381, 3.1764827784796088, 3.2086055078619404, 3.2138322898064557]\n",
      "SSE: 235158.064706  SST: 56311.660444  R2 3.17601013452 R2_adj:  [3.2140428657291431, 2.9454648009079354, 3.2138135488638162, 3.1354019084094387, 3.1429015704020444, 3.1478303898519195, 3.1570784925328863, 3.2139145295690339, 3.2137524738057803, 3.1644786814448262, 3.1330110086554996, 3.0556513790658788, 3.1512708905079085, 3.0959977302831367, 3.2141778458250272, 3.2120779110960545, 3.2142102963544414, 3.2131673961775222, 3.2141162319671843, 3.1753666623680381, 3.1764827784796088, 3.2086055078619404, 3.2138322898064557, 3.1760710647491703]\n",
      "-------------------------------------------------\n",
      "Feature chosen:  PRI_lep_phi (index : 18 )\n",
      "SSE: 237295.973049  SST: 56311.660444  R2 3.21397577657 R2_adj:  [3.2140466263443717]\n",
      "SSE: 222171.469364  SST: 56311.660444  R2 2.94539013079 R2_adj:  [3.2140466263443717, 2.9454523855118704]\n",
      "SSE: 237283.058769  SST: 56311.660444  R2 3.21374644075 R2_adj:  [3.2140466263443717, 2.9454523855118704, 3.2138172831869456]\n",
      "SSE: 232867.040681  SST: 56311.660444  R2 3.13532541654 R2_adj:  [3.2140466263443717, 2.9454523855118704, 3.2138172831869456, 3.1353937494100537]\n",
      "SSE: 233290.058069  SST: 56311.660444  R2 3.14283749101 R2_adj:  [3.2140466263443717, 2.9454523855118704, 3.2138172831869456, 3.1353937494100537, 3.1429060642818603]\n",
      "SSE: 233567.124646  SST: 56311.660444  R2 3.14775772556 R2_adj:  [3.2140466263443717, 2.9454523855118704, 3.2138172831869456, 3.1353937494100537, 3.1429060642818603, 3.1478264562802281]\n",
      "SSE: 234088.324383  SST: 56311.660444  R2 3.15701335278 R2_adj:  [3.2140466263443717, 2.9454523855118704, 3.2138172831869456, 3.1353937494100537, 3.1429060642818603, 3.1478264562802281, 3.1570823796970817]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SSE: 237288.759559  SST: 56311.660444  R2 3.21384767716 R2_adj:  [3.2140466263443717, 2.9454523855118704, 3.2138172831869456, 3.1353937494100537, 3.1429060642818603, 3.1478264562802281, 3.1570823796970817, 3.2139185228384366]\n",
      "SSE: 237279.687876  SST: 56311.660444  R2 3.21368657938 R2_adj:  [3.2140466263443717, 2.9454523855118704, 3.2138172831869456, 3.1353937494100537, 3.1429060642818603, 3.1478264562802281, 3.1570823796970817, 3.2139185228384366, 3.2137574199027394]\n",
      "SSE: 234504.731214  SST: 56311.660444  R2 3.16440803495 R2_adj:  [3.2140466263443717, 2.9454523855118704, 3.2138172831869456, 3.1353937494100537, 3.1429060642818603, 3.1478264562802281, 3.1570823796970817, 3.2139185228384366, 3.2137574199027394, 3.1644772984987726]\n",
      "SSE: 232733.806149  SST: 56311.660444  R2 3.13295939622 R2_adj:  [3.2140466263443717, 2.9454523855118704, 3.2138172831869456, 3.1353937494100537, 3.1429060642818603, 3.1478264562802281, 3.1570823796970817, 3.2139185228384366, 3.2137574199027394, 3.1644772984987726, 3.1330276533754216]\n",
      "SSE: 228376.854858  SST: 56311.660444  R2 3.05558729857 R2_adj:  [3.2140466263443717, 2.9454523855118704, 3.2138172831869456, 3.1353937494100537, 3.1429060642818603, 3.1478264562802281, 3.1570823796970817, 3.2139185228384366, 3.2137574199027394, 3.1644772984987726, 3.1330276533754216, 3.0556530797319548]\n",
      "SSE: 233761.418373  SST: 56311.660444  R2 3.15120805406 R2_adj:  [3.2140466263443717, 2.9454523855118704, 3.2138172831869456, 3.1353937494100537, 3.1429060642818603, 3.1478264562802281, 3.1570823796970817, 3.2139185228384366, 3.2137574199027394, 3.1644772984987726, 3.1330276533754216, 3.0556530797319548, 3.1512768951938566]\n",
      "SSE: 230649.455117  SST: 56311.660444  R2 3.09594484159 R2_adj:  [3.2140466263443717, 2.9454523855118704, 3.2138172831869456, 3.1353937494100537, 3.1429060642818603, 3.1478264562802281, 3.1570823796970817, 3.2139185228384366, 3.2137574199027394, 3.1644772984987726, 3.1330276533754216, 3.0556530797319548, 3.1512768951938566, 3.0960119142403344]\n",
      "SSE: 237304.597656  SST: 56311.660444  R2 3.21412893501 R2_adj:  [3.2140466263443717, 2.9454523855118704, 3.2138172831869456, 3.1353937494100537, 3.1429060642818603, 3.1478264562802281, 3.1570823796970817, 3.2139185228384366, 3.2137574199027394, 3.1644772984987726, 3.1330276533754216, 3.0556530797319548, 3.1512768951938566, 3.0960119142403344, 3.2141997896906194]\n",
      "SSE: 237185.380122  SST: 56311.660444  R2 3.21201183293 R2_adj:  [3.2140466263443717, 2.9454523855118704, 3.2138172831869456, 3.1353937494100537, 3.1429060642818603, 3.1478264562802281, 3.1570823796970817, 3.2139185228384366, 3.2137574199027394, 3.1644772984987726, 3.1330276533754216, 3.0556530797319548, 3.1512768951938566, 3.0960119142403344, 3.2141997896906194, 3.2120826198613774]\n",
      "SSE: 237246.653752  SST: 56311.660444  R2 3.21309994912 R2_adj:  [3.2140466263443717, 2.9454523855118704, 3.2138172831869456, 3.1353937494100537, 3.1429060642818603, 3.1478264562802281, 3.1570823796970817, 3.2139185228384366, 3.2137574199027394, 3.1644772984987726, 3.1330276533754216, 3.0556530797319548, 3.1512768951938566, 3.0960119142403344, 3.2141997896906194, 3.2120826198613774, 3.2131707708703425]\n",
      "SSE: 237299.847224  SST: 56311.660444  R2 3.21404457537 R2_adj:  [3.2140466263443717, 2.9454523855118704, 3.2138172831869456, 3.1353937494100537, 3.1429060642818603, 3.1478264562802281, 3.1570823796970817, 3.2139185228384366, 3.2137574199027394, 3.1644772984987726, 3.1330276533754216, 3.0556530797319548, 3.1512768951938566, 3.0960119142403344, 3.2141997896906194, 3.2120826198613774, 3.2131707708703425, 3.2141154273449777]\n",
      "SSE: 235117.33772  SST: 56311.660444  R2 3.17528689203 R2_adj:  [3.2140466263443717, 2.9454523855118704, 3.2138172831869456, 3.1353937494100537, 3.1429060642818603, 3.1478264562802281, 3.1570823796970817, 3.2139185228384366, 3.2137574199027394, 3.1644772984987726, 3.1330276533754216, 3.0556530797319548, 3.1512768951938566, 3.0960119142403344, 3.2141997896906194, 3.2120826198613774, 3.2131707708703425, 3.2141154273449777, 3.1753565037187736]\n",
      "SSE: 235180.956602  SST: 56311.660444  R2 3.17641665594 R2_adj:  [3.2140466263443717, 2.9454523855118704, 3.2138172831869456, 3.1353937494100537, 3.1429060642818603, 3.1478264562802281, 3.1570823796970817, 3.2139185228384366, 3.2137574199027394, 3.1644772984987726, 3.1330276533754216, 3.0556530797319548, 3.1512768951938566, 3.0960119142403344, 3.2141997896906194, 3.2120826198613774, 3.2131707708703425, 3.2141154273449777, 3.1753565037187736, 3.1764863037777364]\n",
      "SSE: 236989.618246  SST: 56311.660444  R2 3.20853543258 R2_adj:  [3.2140466263443717, 2.9454523855118704, 3.2138172831869456, 3.1353937494100537, 3.1429060642818603, 3.1478264562802281, 3.1570823796970817, 3.2139185228384366, 3.2137574199027394, 3.1644772984987726, 3.1330276533754216, 3.0556530797319548, 3.1512768951938566, 3.0960119142403344, 3.2141997896906194, 3.2120826198613774, 3.2131707708703425, 3.2141154273449777, 3.1753565037187736, 3.1764863037777364, 3.2086061082594339]\n",
      "SSE: 237284.159271  SST: 56311.660444  R2 3.21376598382 R2_adj:  [3.2140466263443717, 2.9454523855118704, 3.2138172831869456, 3.1353937494100537, 3.1429060642818603, 3.1478264562802281, 3.1570823796970817, 3.2139185228384366, 3.2137574199027394, 3.1644772984987726, 3.1330276533754216, 3.0556530797319548, 3.1512768951938566, 3.0960119142403344, 3.2141997896906194, 3.2120826198613774, 3.2131707708703425, 3.2141154273449777, 3.1753565037187736, 3.1764863037777364, 3.2086061082594339, 3.213836826881733]\n",
      "SSE: 235157.460929  SST: 56311.660444  R2 3.17599941247 R2_adj:  [3.2140466263443717, 2.9454523855118704, 3.2138172831869456, 3.1353937494100537, 3.1429060642818603, 3.1478264562802281, 3.1570823796970817, 3.2139185228384366, 3.2137574199027394, 3.1644772984987726, 3.1330276533754216, 3.0556530797319548, 3.1512768951938566, 3.0960119142403344, 3.2141997896906194, 3.2120826198613774, 3.2131707708703425, 3.2141154273449777, 3.1753565037187736, 3.1764863037777364, 3.2086061082594339, 3.213836826881733, 3.1760690469599977]\n"
     ]
    }
   ],
   "source": [
    "# Start of STEP-WISE algorithm \n",
    "all_candidates = input_data\n",
    "\n",
    "n = all_candidates.shape[0] #needed for the R^2 adjusted\n",
    "num = all_candidates.shape[1]\n",
    "H = np.ones((n,1)) #offset\n",
    "\n",
    "#Initialization only with offsets (lack of info)\n",
    "X = H\n",
    "k = 0 #needed for the R^2 adjusted\n",
    "\n",
    "w0, loss = ridge_regression(Y,X,0)  # start with lambda = 0  \n",
    "y = predict_labels(w0, X)\n",
    "\n",
    "sse = loss*2*n\n",
    "sst = np.sum((Y - Y.mean())**2)  #lack of information\n",
    "R2 = np.abs((sst-sse)/sst)\n",
    "R2adj_0 = R2 - (k/(n-k-1)*(1-R2))\n",
    "\n",
    "#fix the R2adj_max\n",
    "R2adj_max = R2adj_0\n",
    "print(\"R2adj_0= \", R2adj_0)\n",
    "ind_max = 0  # this index will show us which is the best feature chosen\n",
    "del(X)\n",
    "idx_features = []\n",
    "best_R2adj = []\n",
    "\n",
    "# ridge regression parameters\n",
    "arg_rr = dict()\n",
    "arg_rr['method'] = 'rr'\n",
    "arg_rr['loss'] = 'rmse'\n",
    "arg_rr['degree'] = 1\n",
    "arg_rr['k_fold'] = 10\n",
    "\n",
    "# optimization parameters\n",
    "lambda_min = -10 \n",
    "lambda_max = 1\n",
    "lambda_steps = 10\n",
    "\n",
    "for j in range(num):\n",
    "    R2_adj = []\n",
    "    for i in range(all_candidates.shape[1]):\n",
    "        \n",
    "        X = np.concatenate((H,all_candidates[:,i].reshape(n,1)), axis=1)\n",
    "        \n",
    "        ##########################################CROSS VALIDATION##########################################\n",
    "        \n",
    "        ws, loss_tr, loss, lambda_opt = optimize_lambda(Y, X, lambda_min, lambda_max, lambda_steps, arg_rr)\n",
    "        \n",
    "        ####################################################################################################\n",
    "        \n",
    "        #ws = w_tr_tot[np.argmin(loss_te_tot)]\n",
    "        #loss = np.min(loss_te_tot)\n",
    "        \n",
    "        k = len(ws) -1 # k is the number of regressor I use -> -1 because I don't consider the offset\n",
    "        \n",
    "        SSE = loss*2*n\n",
    "        SST = np.sum((Y- Y.mean())**2)\n",
    "        R2 = np.abs((SST-SSE)/SST)\n",
    "        R2_adj.append(R2 - (k/(n-k-1)*(1-R2)))\n",
    "        \n",
    "        print(\"SSE:\", SSE, \" SST:\", SST, \" R2\", R2, \"R2_adj: \", R2_adj)\n",
    "        \n",
    "    R2adj_chosen = np.max(R2_adj)\n",
    "    best_R2adj.append(R2adj_chosen)\n",
    "    idx_chosen = np.argmax(R2_adj)\n",
    "    \n",
    "    if R2adj_chosen > R2adj_max:\n",
    "        R2adj_max = R2adj_chosen\n",
    "        ind_max = idx_chosen\n",
    "        \n",
    "        H = np.concatenate((H, all_candidates[:,ind_max].reshape(n,1)), axis = 1)\n",
    "        \n",
    "        all_candidates = np.delete(all_candidates,ind_max,1)\n",
    "        print('-------------------------------------------------')\n",
    "        print('Feature chosen: ', features[ind_max][1], '(index :', features[ind_max][0], ')')\n",
    "        idx_features.append(features[ind_max][0])\n",
    "        del(features[ind_max])\n",
    "        \n",
    "        del(X)\n",
    "        \n",
    "    else:\n",
    "        break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results_r2_stepwise(best_R2adj[:len(best_R2adj)-1], idx_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "R2adj_0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) (C) Use of the probability of the 2 events (R2 Tjur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Realloc FEATURES\n",
    "features = []\n",
    "for i in range(len(all_features)):\n",
    "    features.append((i,all_features[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Start of STEP-WISE algorithm \n",
    "all_candidates = input_data\n",
    "\n",
    "n = all_candidates.shape[0] #needed for the R^2 adjusted\n",
    "num = all_candidates.shape[1]\n",
    "H = np.ones((n,1)) #offset\n",
    "\n",
    "#Initialization only with offsets (lack of info)\n",
    "X = H\n",
    "k = 0 #needed for the R^2 adjusted\n",
    "\n",
    "w0, loss = ridge_regression(Y,X,0)  \n",
    "y = predict_labels(w0, X)\n",
    "ind_back, ind_sig = idx_2labels(y, [0,1])\n",
    "\n",
    "y_ = X.dot(w0)\n",
    "R2 = 0\n",
    "R2adj_0 = R2 - (k/(n-k-1)*(1-R2))\n",
    "\n",
    "#fix the R2adj_max\n",
    "R2adj_max = R2adj_0\n",
    "ind_max = 0  # this index will show us which is the best feature chosen\n",
    "del(X)\n",
    "idx_features = []\n",
    "best_R2adj = []\n",
    "\n",
    "for j in range(num):\n",
    "    R2_adj = []\n",
    "    for i in range(all_candidates.shape[1]):\n",
    "        \n",
    "        X = np.concatenate((H,all_candidates[:,i].reshape(n,1)), axis=1)\n",
    "        #CROSS VALIDATION\n",
    "        w_tr_tot, loss_tr_tot, loss_te_tot = cross_validation_rr(Y,X)\n",
    "        ws = w_tr_tot[np.argmin(loss_te_tot)]\n",
    "        \n",
    "        k = len(ws) -1 # k is the number of regressor I use -> -1 because I don't consider the offset\n",
    "        \n",
    "        y = predict_labels(ws,X)          \n",
    "        ind_back, ind_sig = idx_2labels(y, [-1,1])\n",
    "        \n",
    "        if len(ind_sig) == 0 or len(ind_back) ==0:\n",
    "            print('No signal detected')\n",
    "            R2_adj.append(0)\n",
    "            \n",
    "        else: \n",
    "            \n",
    "            y_ = X.dot(ws)\n",
    "\n",
    "            R2 = np.abs((np.mean(y_[ind_sig]) - np.mean(y_[ind_back])))\n",
    "            R2_adj.append(R2 - (k/(n-k-1)*(1-R2)))\n",
    "            \n",
    "        \n",
    "    R2adj_chosen = np.max(R2_adj)\n",
    "    best_R2adj.append(R2adj_chosen)\n",
    "    idx_chosen = np.argmax(R2_adj)\n",
    "\n",
    "    if R2adj_chosen > R2adj_max:\n",
    "        R2adj_max = R2adj_chosen\n",
    "        ind_max = idx_chosen\n",
    "\n",
    "        #idx_features.append(np.where(all_candidates[:,ind_max] == input_data))\n",
    "        H = np.concatenate((H, all_candidates[:,ind_max].reshape(n,1)), axis = 1)\n",
    "\n",
    "        all_candidates = np.delete(all_candidates,ind_max,1)\n",
    "        print('-------------------------------------------------')\n",
    "        print('Feature chosen: ', features[ind_max][1], '(index :', features[ind_max][0], ')')\n",
    "        idx_features.append(features[ind_max][0])\n",
    "        del(features[ind_max])\n",
    "\n",
    "        del(X)\n",
    "\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results_r2_stepwise(best_R2adj[:len(best_R2adj)-1], idx_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) (C) Use of the likelihood (McFadden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Realloc FEATURES\n",
    "features = []\n",
    "for i in range(len(all_features)):\n",
    "    features.append((i,all_features[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Start of STEP-WISE algorithm \n",
    "all_candidates = input_data\n",
    "\n",
    "n = all_candidates.shape[0] #needed for the R^2 adjusted\n",
    "num = all_candidates.shape[1]\n",
    "H = np.ones((n,1)) #offset\n",
    "\n",
    "#Initialization only with offsets (lack of info)\n",
    "X = H\n",
    "k = 0 #needed for the R^2 adjusted\n",
    "\n",
    "w0, loss = ridge_regression(Y,X,0)  # lambda set to 0 \n",
    "y = predict_labels(w0, X)\n",
    "loglike0 = np.sum(np.log(1+np.exp(X.dot(w0))) - y*(X.dot(w0)))\n",
    "\n",
    "R2 = 0        # For the definition of McFadden 1-1 = 0\n",
    "R2adj_0 = 0\n",
    "\n",
    "#fix the R2adj_max\n",
    "\n",
    "R2adj_max = R2adj_0\n",
    "ind_max = 0  # this index will show us which is the best feature chosen\n",
    "del(X)\n",
    "idx_features = []\n",
    "best_R2adj = []\n",
    "\n",
    "for j in range(num):\n",
    "    R2_adj = []\n",
    "    for i in range(all_candidates.shape[1]):\n",
    "        \n",
    "        X = np.concatenate((H,all_candidates[:,i].reshape(n,1)), axis=1)\n",
    "        #CROSS VALIDATION\n",
    "        w_tr_tot, loss_tr_tot, loss_te_tot = cross_validation_rr(Y,X)\n",
    "        ws = w_tr_tot[np.argmin(loss_te_tot)]\n",
    "        \n",
    "        k = len(ws) -1 # k is the number of regressor I use -> -1 because I don't consider the offset\n",
    "        \n",
    "        y = predict_labels(ws,X)   \n",
    "        \n",
    "        loglike = np.sum(np.log(1+np.exp(X.dot(ws))) - y*(X.dot(ws)))\n",
    "        \n",
    "        R2 = 1-(loglike/loglike0)\n",
    "        R2_adj.append(R2 - (k/(n-k-1)*(1-R2)))\n",
    "        \n",
    "    R2adj_chosen = np.max(R2_adj)\n",
    "    best_R2adj.append(R2adj_chosen)\n",
    "    idx_chosen = np.argmax(R2_adj)\n",
    "    \n",
    "    if R2adj_chosen > R2adj_max:\n",
    "        R2adj_max = R2adj_chosen\n",
    "        ind_max = idx_chosen\n",
    "        \n",
    "        H = np.concatenate((H, all_candidates[:,ind_max].reshape(n,1)), axis = 1)\n",
    "        \n",
    "        all_candidates = np.delete(all_candidates,ind_max,1)\n",
    "        print('-------------------------------------------------')\n",
    "        print('Feature chosen: ', features[ind_max][1], '(index :', features[ind_max][0], ')')\n",
    "        idx_features.append(features[ind_max][0])\n",
    "        del(features[ind_max])\n",
    "        \n",
    "        del(X)\n",
    "        \n",
    "    else:\n",
    "        break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results_r2_stepwise(best_R2adj[:len(best_R2adj)-1], idx_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No cross validation (hyperparameter fixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initialization\n",
    "max_iters = 100\n",
    "threshold = 1e-8\n",
    "gamma = 0\n",
    "method = 'gd'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use of the likelihood (McFadden)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I used only this method because it's the most reasonable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Realloc FEATURES\n",
    "features = []\n",
    "for i in range(len(all_features)):\n",
    "    features.append((i,all_features[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Start of STEP-WISE algorithm \n",
    "all_candidates = input_data\n",
    "\n",
    "n = all_candidates.shape[0] #needed for the R^2 adjusted\n",
    "num = all_candidates.shape[1]\n",
    "H = np.ones((n,1)) #offset\n",
    "\n",
    "#Initialization only with offsets (lack of info)\n",
    "X = H\n",
    "k = 0 #needed for the R^2 adjusted\n",
    "\n",
    "initial_w = np.zeros(X.shape[1])\n",
    "\n",
    "w0, loss = logistic_regression(Y,X, initial_w, max_iters, gamma, method)\n",
    "y = predict_labels(w0[-1], X)\n",
    "loglike0 = np.sum(np.log(1+np.exp(X.dot(w0))) - y*(X.dot(w0)))\n",
    "\n",
    "R2 = 0        # For the definition of McFadden 1-1 = 0\n",
    "R2adj_0 = 0\n",
    "\n",
    "#fix the R2adj_max\n",
    "\n",
    "R2adj_max = R2adj_0\n",
    "ind_max = 0  # this index will show us which is the best feature chosen\n",
    "del(X)\n",
    "idx_features = []\n",
    "best_R2adj = []\n",
    "\n",
    "for j in range(num):\n",
    "    R2_adj = []\n",
    "    for i in range(all_candidates.shape[1]):\n",
    "        \n",
    "        X = np.concatenate((H,all_candidates[:,i].reshape(n,1)), axis=1)\n",
    "        \n",
    "        initial_w = np.zeros(X.shape[1])\n",
    "        ws, loss = logistic_regression(Y,X, initial_w, max_iters, gamma, method)\n",
    "        \n",
    "        k = len(ws) -1 # k is the number of regressor I use -> -1 because I don't consider the offset\n",
    "        \n",
    "        y = predict_labels(ws[-1], X)\n",
    "        loglike = compute_loglikelihood_reg(y, X, ws)\n",
    "        \n",
    "        R2 = 1-(loglike/loglike0)\n",
    "        R2_adj.append(R2 - (k/(n-k-1)*(1-R2)))\n",
    "        \n",
    "    R2adj_chosen = np.max(R2_adj)\n",
    "    best_R2adj.append(R2adj_chosen)\n",
    "    idx_chosen = np.argmax(R2_adj)\n",
    "    \n",
    "    if R2adj_chosen > R2adj_max:\n",
    "        R2adj_max = R2adj_chosen\n",
    "        ind_max = idx_chosen\n",
    "        \n",
    "        H = np.concatenate((H, all_candidates[:,ind_max].reshape(n,1)), axis = 1)\n",
    "        \n",
    "        all_candidates = np.delete(all_candidates,ind_max,1)\n",
    "        print('-------------------------------------------------')\n",
    "        print('Feature chosen: ', features[ind_max][1], '(index :', features[ind_max][0], ')')\n",
    "        idx_features.append(features[ind_max][0])\n",
    "        del(features[ind_max])\n",
    "        \n",
    "        del(X)\n",
    "        \n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results_r2_stepwise(best_R2adj[:len(best_R2adj)-1], idx_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With cross correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use of the likelihood (McFadden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Realloc FEATURES\n",
    "features = []\n",
    "for i in range(len(all_features)):\n",
    "    features.append((i,all_features[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Start of STEP-WISE algorithm \n",
    "all_candidates = input_data\n",
    "\n",
    "n = all_candidates.shape[0] #needed for the R^2 adjusted\n",
    "num = all_candidates.shape[1]\n",
    "H = np.ones((n,1)) #offset\n",
    "\n",
    "#Initialization only with offsets (lack of info)\n",
    "X = H\n",
    "k = 0 #needed for the R^2 adjusted\n",
    "\n",
    "w0, loss = logistic_regression(Y,X, initial_w, max_iters, gamma, method)\n",
    "y = predict_labels(w0, X)\n",
    "loglike0 = np.sum(np.log(1+np.exp(X.dot(w0))) - y*(X.dot(w0)))\n",
    "\n",
    "R2 = 0        # For the definition of McFadden 1-1 = 0\n",
    "R2adj_0 = 0\n",
    "\n",
    "#fix the R2adj_max\n",
    "\n",
    "R2adj_max = R2adj_0\n",
    "ind_max = 0  # this index will show us which is the best feature chosen\n",
    "del(X)\n",
    "idx_features = []\n",
    "best_R2adj = []\n",
    "\n",
    "for j in range(num):\n",
    "    R2_adj = []\n",
    "    for i in range(all_candidates.shape[1]):\n",
    "        \n",
    "        X = np.concatenate((H,all_candidates[:,i].reshape(n,1)), axis=1)\n",
    "        #CROSS VALIDATION\n",
    "        w_tr_tot, loss_tr_tot, loss_te_tot = cross_validation_lr(Y,X)\n",
    "        ws = w_tr_tot[np.argmin(loss_te_tot)]\n",
    "        \n",
    "        y = predict_labels(ws,X)   \n",
    "        \n",
    "        loglike = np.sum(np.log(1+np.exp(X.dot(ws))) - y*(X.dot(ws)))\n",
    "        \n",
    "        R2 = 1-(loglike/loglike0)\n",
    "        R2_adj.append(R2 - (k/(n-k-1)*(1-R2)))\n",
    "        \n",
    "    R2adj_chosen = np.max(R2_adj)\n",
    "    best_R2adj.append(R2adj_chosen)\n",
    "    idx_chosen = np.argmax(R2_adj)\n",
    "    \n",
    "    if R2adj_chosen > R2adj_max:\n",
    "        R2adj_max = R2adj_chosen\n",
    "        ind_max = idx_chosen\n",
    "        \n",
    "        H = np.concatenate((H, all_candidates[:,ind_max].reshape(n,1)), axis = 1)\n",
    "        \n",
    "        all_candidates = np.delete(all_candidates,ind_max,1)\n",
    "        print('-------------------------------------------------')\n",
    "        print('Feature chosen: ', features[ind_max][1], '(index :', features[ind_max][0], ')')\n",
    "        idx_features.append(features[ind_max][0])\n",
    "        del(features[ind_max])\n",
    "        \n",
    "        del(X)\n",
    "        \n",
    "    else:\n",
    "        break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results_r2_stepwise(best_R2adj[:len(best_R2adj)-1], idx_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

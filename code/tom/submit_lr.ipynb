{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# change path if necessary\n",
    "import sys\n",
    "my_path = r'D:\\Documents\\etudes\\epfl\\MA1\\cours\\MachineLearning\\Project1' # to be adapated\n",
    "sys.path.insert(0,my_path + r'\\code\\COMMON')\n",
    "\n",
    "# imports\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from implementations import *\n",
    "from labels import idx_2labels\n",
    "from costs import *\n",
    "from optimize_hyperparams import *\n",
    "from cross_validation import *\n",
    "from step_wise import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from proj1_helpers import load_csv_data \n",
    "\n",
    "# load raw data\n",
    "y_raw, input_data_raw, ids = load_csv_data(my_path + r'\\data\\train.csv', sub_sample=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-999 are replaced by the mean value of the feature\n"
     ]
    }
   ],
   "source": [
    "from outliers import handle_outliers\n",
    "\n",
    "# handle outliers\n",
    "X_raw, y = handle_outliers(input_data_raw, y_raw, -999, 'mean')\n",
    "\n",
    "# set y in {0,1} instead of {-1,1}\n",
    "y[np.where(y==-1)]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get feature names \n",
    "all_features_raw = list(np.genfromtxt(my_path + r'/data/train.csv', delimiter=\",\", dtype=str, max_rows = 1)[2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------\n",
      "Features have been set to the power(s): [1]\n",
      "16 Features of the momentum have been added\n",
      "4 logarithmic features have been added.\n",
      "(250000, 50)\n"
     ]
    }
   ],
   "source": [
    "from extend_features import extend_features\n",
    "\n",
    "# feature degree\n",
    "degree = 1\n",
    "\n",
    "# extend feature set\n",
    "all_candidates, features = extend_features(X_raw, all_features_raw, degree, is_add_log = True)\n",
    "print(all_candidates.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# feature selection\n",
    "indx = [1, 13, 4, 46, 0, 11, 44, 43, 7, 2, 16, 48, 10, 6, 49, 22, 45, 12, 19, 23, 32, 24, 17, 14, 39, 42, 30, 31, 47, 38, 20]\n",
    "indx = indx[:17]\n",
    "\n",
    "# training set\n",
    "X = all_candidates[:, indx]\n",
    "\n",
    "# build polynomial basis function\n",
    "degree_opt = 5\n",
    "phi = build_poly(X, degree_opt)\n",
    "        \n",
    "# standardization\n",
    "phi_tmp,_,_ =  standardize(phi[:,1:]) \n",
    "phi[:,1:] = phi_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model parameters\n",
    "gamma = 1e-6\n",
    "method = 'gd'\n",
    "threshold = 500\n",
    "max_iters = 10000\n",
    "initial_w = np.zeros(phi.shape[1])\n",
    "\n",
    "# logistic regression\n",
    "w_tot, loss_tot = logistic_regression(y, phi, initial_w, max_iters, gamma, method, threshold, debug_mode=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tempfile import TemporaryFile\n",
    "\n",
    "# save w_opt\n",
    "outfile = TemporaryFile()\n",
    "np.save('w_opt_lr_17_features_degree_5', w_tot[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from proj1_helpers import load_csv_data \n",
    "\n",
    "# load \n",
    "path_data_test = r'C:\\Users\\Tom\\Desktop'\n",
    "y_raw_te, input_data_raw_te, ids_te = load_csv_data(path_data_test + r'\\test.csv', sub_sample=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get feature names \n",
    "all_features_raw = list(np.genfromtxt(my_path + r'/data/train.csv', delimiter=\",\", dtype=str, max_rows = 1)[2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-999 are replaced by the mean value of the feature\n"
     ]
    }
   ],
   "source": [
    "# handle outliers\n",
    "input_data_raw_te, _ = handle_outliers(input_data_raw_te, y_raw_te, -999, 'mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------\n",
      "Features have been set to the power(s): [1]\n",
      "16 Features of the momentum have been added\n",
      "4 logarithmic features have been added.\n"
     ]
    }
   ],
   "source": [
    "from extend_features import extend_features\n",
    "\n",
    "# feature degree\n",
    "degree = 1\n",
    "\n",
    "# extend feature set\n",
    "X_te, _ = extend_features(input_data_raw_te, all_features_raw, degree, is_add_log = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(568238, 50)\n",
      "(568238, 17)\n"
     ]
    }
   ],
   "source": [
    "# feature selection\n",
    "indx = [1, 13, 4, 46, 0, 11, 44, 43, 7, 2, 16, 48, 10, 6, 49, 22, 45, 12, 19, 23, 32, 24, 17, 14, 39, 42, 30, 31, 47, 38, 20]\n",
    "indx = indx[:17]\n",
    "\n",
    "# training set\n",
    "print(X_te.shape)\n",
    "X_te = X_te[:, indx]\n",
    "print(X_te.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# build polynomial basis function\n",
    "degree_opt = 5\n",
    "phi = build_poly(X_te, degree_opt)\n",
    "        \n",
    "# standardization\n",
    "phi_tmp,_,_ =  standardize(phi[:,1:]) \n",
    "phi[:,1:] = phi_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(86,)\n",
      "85\n"
     ]
    }
   ],
   "source": [
    "# load optimal weights\n",
    "w_opt = np.load('w_opt_lr_17_features_degree_5.npy')\n",
    "print(w_opt.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Predict labels in testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from proj1_helpers import predict_labels_log\n",
    "\n",
    "# predict labels\n",
    "y_pred = predict_labels_log(w_opt,phi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a submission csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# replace 0 in labels per -1\n",
    "y_pred[np.where(y_pred==0)] = -1\n",
    "\n",
    "# create the csv file\n",
    "create_csv_submission(ids_te, y_pred, \"sub29_10_3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

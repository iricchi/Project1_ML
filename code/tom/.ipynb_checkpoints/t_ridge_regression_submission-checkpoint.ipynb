{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# add path\n",
    "import sys\n",
    "my_path = r'D:\\Documents\\etudes\\epfl\\MA1\\cours\\MachineLearning\\Project1'\n",
    "sys.path.insert(0,my_path + r'\\code\\COMMON')\n",
    "\n",
    "# import \n",
    "import numpy as np\n",
    "from implementations import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from proj1_helpers import load_csv_data \n",
    "\n",
    "# load \n",
    "y_raw_tr, input_data_raw_tr, ids_tr = load_csv_data(my_path + r'\\data\\train.csv', sub_sample=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handle outliers in training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-999 are replaced by the median value of the feature\n"
     ]
    }
   ],
   "source": [
    "from outliers import handle_outliers\n",
    "\n",
    "# outliers\n",
    "X_tr, y_tr = handle_outliers(input_data_raw_tr, y_raw_tr, -999, 'median')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standardize training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from standard import standardize\n",
    "\n",
    "# standardize\n",
    "X_tr, mean_x_tr, std_x_tr = standardize(X_tr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from build_poly import build_poly\n",
    "\n",
    "# choose features\n",
    "ind_features = [1, 13, 6, 11, 7, 2, 16, 10, 12, 21, 19, 5, 9, 23, 0, 26, 3, 22, 4, 18, 28]\n",
    "\n",
    "# degree of polynomial basis function\n",
    "degree = 4\n",
    "\n",
    "# lambda\n",
    "lambda_ = 1.6e-12\n",
    "\n",
    "# build the function\n",
    "phi_tr = build_poly(X_tr[:,ind_features], degree)\n",
    "\n",
    "# ridge regression\n",
    "w_tr, loss_tr = ridge_regression(y_tr, phi_tr, lambda_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from proj1_helpers import load_csv_data \n",
    "\n",
    "# load \n",
    "path_data_test = r'C:\\Users\\Tom\\Desktop'\n",
    "y_raw_te, input_data_raw_te, ids_te = load_csv_data(path_data_test + r'\\test.csv', sub_sample=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handle outliers in testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-999 are replaced by the median value of the feature\n",
      "[  1.05080000e+02   4.64670000e+01   7.37400000e+01   3.84720000e+01\n",
      "  -9.99000000e+02  -9.99000000e+02  -9.99000000e+02   2.49200000e+00\n",
      "   1.24130000e+01   1.20666000e+02   1.28200000e+00  -3.56000000e-01\n",
      "  -9.99000000e+02   3.17655000e+01  -2.20000000e-02  -4.20000000e-02\n",
      "   4.05530000e+01  -3.80000000e-02   9.70000000e-02   3.47540000e+01\n",
      "  -1.60000000e-02   1.79940000e+02   1.00000000e+00   3.89680000e+01\n",
      "  -1.86200000e+00  -2.11000000e+00  -9.99000000e+02  -9.99000000e+02\n",
      "  -9.99000000e+02   4.05040000e+01]\n"
     ]
    }
   ],
   "source": [
    "from outliers import handle_outliers\n",
    "\n",
    "# outliers\n",
    "X_te, y_te = handle_outliers(input_data_raw_te, y_raw_te, -999, 'median')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standardize testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from standard import standardize\n",
    "\n",
    "# standardize\n",
    "X_te, mean_x_te, std_x_te = standardize(X_te)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from proj1_helpers import predict_labels\n",
    "\n",
    "# build the function\n",
    "phi_te = build_poly(X_te[:,ind_features], degree)\n",
    "\n",
    "# predict\n",
    "y_pred = predict_labels(w_tr, phi_te)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create cvs submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from proj1_helpers import *\n",
    "\n",
    "# create cvs submission\n",
    "create_csv_submission(ids_te, y_pred, \"18_10_sub\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-999    2    3]\n",
      " [   4    5    6]\n",
      " [-999    8    9]]\n",
      "(array([0, 2], dtype=int64),)\n",
      "[[4 5 6]]\n"
     ]
    }
   ],
   "source": [
    "x_test = np.array([[-999,2,3],[4,5,6],[-999,8,9]])\n",
    "print(x_test)\n",
    "print(np.where(x_test[:,0] == -999))\n",
    "x_test = np.delete(x_test, np.where(x_test[:,0] == -999), 0)\n",
    "print(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples with -999 are removed from the dataset \n",
      "(array([[4, 5, 6]]), array([0]))\n"
     ]
    }
   ],
   "source": [
    "x_test = np.array([[-999,2,3],[4,5,6],[-999,8,9]])\n",
    "y_test= [1,0,1]\n",
    "print(handle_outliers(x_test, y_test, -999, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# add path\n",
    "import sys\n",
    "my_path = r'D:\\Documents\\etudes\\epfl\\MA1\\cours\\MachineLearning\\Project1'\n",
    "sys.path.insert(0,my_path + r'\\code\\COMMON')\n",
    "\n",
    "# import \n",
    "import numpy as np\n",
    "from implementations import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from proj1_helpers import load_csv_data \n",
    "\n",
    "# load \n",
    "y_raw, input_data_raw, ids = load_csv_data(my_path + r'\\data\\train.csv', sub_sample=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handle outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from outliers import handle_outliers\n",
    "\n",
    "# outliers\n",
    "X, y = handle_outliers(input_data_raw, y_raw, -999, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standardize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from standard import standardize\n",
    "\n",
    "# standardize\n",
    "X, mean_x, std_x = standardize(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature names and index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DER_mass_MMC ( index: 0 )\n",
      "DER_mass_transverse_met_lep ( index: 1 )\n",
      "DER_mass_vis ( index: 2 )\n",
      "DER_pt_h ( index: 3 )\n",
      "DER_deltaeta_jet_jet ( index: 4 )\n",
      "DER_mass_jet_jet ( index: 5 )\n",
      "DER_prodeta_jet_jet ( index: 6 )\n",
      "DER_deltar_tau_lep ( index: 7 )\n",
      "DER_pt_tot ( index: 8 )\n",
      "DER_sum_pt ( index: 9 )\n",
      "DER_pt_ratio_lep_tau ( index: 10 )\n",
      "DER_met_phi_centrality ( index: 11 )\n",
      "DER_lep_eta_centrality ( index: 12 )\n",
      "PRI_tau_pt ( index: 13 )\n",
      "PRI_tau_eta ( index: 14 )\n",
      "PRI_tau_phi ( index: 15 )\n",
      "PRI_lep_pt ( index: 16 )\n",
      "PRI_lep_eta ( index: 17 )\n",
      "PRI_lep_phi ( index: 18 )\n",
      "PRI_met ( index: 19 )\n",
      "PRI_met_phi ( index: 20 )\n",
      "PRI_met_sumet ( index: 21 )\n",
      "PRI_jet_num ( index: 22 )\n",
      "PRI_jet_leading_pt ( index: 23 )\n",
      "PRI_jet_leading_eta ( index: 24 )\n",
      "PRI_jet_leading_phi ( index: 25 )\n",
      "PRI_jet_subleading_pt ( index: 26 )\n",
      "PRI_jet_subleading_eta ( index: 27 )\n",
      "PRI_jet_subleading_phi ( index: 28 )\n",
      "PRI_jet_all_pt ( index: 29 )\n"
     ]
    }
   ],
   "source": [
    "# names of the features \n",
    "featureNames = np.genfromtxt(my_path + r'\\data\\train.csv', delimiter=\",\", dtype=str, max_rows = 1)[2:]\n",
    "\n",
    "for ind, name in enumerate(featureNames):\n",
    "    print(name, '( index:', ind, ')')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split data into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training samples: 54491\n",
      "testing samples: 13623\n"
     ]
    }
   ],
   "source": [
    "from split_data import split_data\n",
    "\n",
    "# ratio (training)\n",
    "ratio = 0.8\n",
    "seed = 1\n",
    "\n",
    "# split\n",
    "X_tr, y_tr, X_te, y_te = split_data(X, y, ratio, seed)\n",
    "\n",
    "print('training samples:', X_tr.shape[0])\n",
    "print('testing samples:', X_te.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'Build_Poly'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-61197cfa174c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mBuild_Poly\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbuild_poly\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# choose features\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mind_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m13\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m6\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m11\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m7\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m16\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m12\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m21\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m19\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m9\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m23\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m26\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m22\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m18\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m28\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'Build_Poly'"
     ]
    }
   ],
   "source": [
    "from Build_Poly import build_poly\n",
    "\n",
    "# choose features\n",
    "ind_features = [1, 13, 6, 11, 7, 2, 16, 10, 12, 21, 19, 5, 9, 23, 0, 26, 3, 22, 4, 18, 28]\n",
    "\n",
    "# degree of polynomial basis function\n",
    "degree = 2\n",
    "\n",
    "# build the function\n",
    "phi_tr = build_poly(X_tr[:,ind_features], degree)\n",
    "\n",
    "# initialize weights\n",
    "initial_w = np.zeros(len(ind_features))\n",
    "\n",
    "# lambda\n",
    "lambda_rr = 0.1\n",
    "\n",
    "# least squares GD\n",
    "w_rr_all, loss_rr_all = ridge_regression(y_tr, phi_tr, lambda_)\n",
    "\n",
    "# take last weights\n",
    "w_rr = w_rr_all[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels:  68114\n",
      "classification error:  30.756808338838727\n"
     ]
    }
   ],
   "source": [
    "from proj1_helpers import predict_labels\n",
    "\n",
    "# predict\n",
    "y_pred = predict_labels(w_ls, X_te[:,ind_features])\n",
    "\n",
    "# class error\n",
    "class_error = len(np.argwhere(y_te-y_pred))/len(y_te)*100\n",
    "\n",
    "print(\"labels: \", y.shape[0])\n",
    "print(\"classification error: \", class_error)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

logistic regression

1) step wise
gamma = 1e-5, threshold = 5000
r² = [0.11273281838983562, 0.13891171406280725, 0.16044656266104906, 0.17098170445217648, 0.18969137276638318, 0.19923923688581474, 0.20503261297336955, 0.20982969592001646, 0.21558054481540401, 0.21998992737793899, 0.23255300835750659, 0.23873631621611638, 0.24390953115037492, 0.24697388372327883, 0.25059802760472738, 0.25313193657063432, 0.25720677615235077, 0.26008892160878061, 0.26110522276796772, 0.26299198381858441, 0.26387512765672694, 0.26391869818602426, 0.26394064950932167, 0.26398060570185783, 0.26402147371485107, 0.26404535870678475, 0.2651776337384083, 0.26577549296097336, 0.26669283364303698, 0.26670398696534497, 0.26671337323997568]
number of features chosen = 31 
index = [1, 13, 4, 46, 0, 11, 44, 43, 7, 2, 16, 48, 10, 6, 49, 22, 45, 12, 19, 23, 32, 24, 17, 14, 39, 42, 30, 31, 47, 38, 20]

2) degree optimization
extract the 10 first features [1, 13, 4, 46, 0, 11, 44, 43, 7, 2]
gamma = 1e-5, threshold = 250, max_iters = 1000
tested degrees = [ 1  2  3  4  5  6  7  8  9 10] 



w_opt saved in folder TOM as 'w_opt_lr.npy' or 'w_opt_lr_17.npy'